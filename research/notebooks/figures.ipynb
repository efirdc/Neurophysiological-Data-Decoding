{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b41918ab-5303-4718-8b8f-cee6777d0c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cefir\\anaconda3\\envs\\Neurophysiological-Data-Decoding\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Cefir\\anaconda3\\envs\\Neurophysiological-Data-Decoding\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\Cefir\\anaconda3\\envs\\Neurophysiological-Data-Decoding\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "C:\\Users\\Cefir\\anaconda3\\envs\\Neurophysiological-Data-Decoding\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "C:\\Users\\Cefir\\anaconda3\\envs\\Neurophysiological-Data-Decoding\\lib\\site-packages\\numpy\\.libs\\libopenblas.xwydx2ikjw2nmtwsfyngfuwkqu3lytcz.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchio as tio\n",
    "import h5py\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from einops import rearrange\n",
    "from scipy import ndimage\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "dir2 = os.path.abspath('..')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path:\n",
    "    sys.path.append(dir1)\n",
    "    \n",
    "from pipeline.utils import index_unsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8cc50fc-6d2c-472a-8409-280ce78c5328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison of embedding only decoding and resblock cascade\n",
    "\n",
    "dataset_path = Path('D:\\\\Datasets\\\\NSD\\\\')\n",
    "\n",
    "path1 = Path('D:\\\\Datasets\\\\NSD\\\\derivatives\\\\results\\\\ViT-B=32\\\\embedding\\\\standard\\\\subj01\\\\images\\\\batch-0')\n",
    "path2 = Path('D:\\\\Datasets\\\\NSD\\\\derivatives\\\\results\\\\ViT-B=32\\\\group-1\\\\subj01\\\\aee0d0f6\\\\images')\n",
    "out_path = Path('D:\\\\Datasets\\\\NSD\\\\derivatives\\\\results\\\\ViT-B=32\\\\group-1\\\\subj01\\\\aee0d0f6\\\\derived2')\n",
    "out_path.mkdir(exist_ok=True)\n",
    "\n",
    "def get_stim_id(p, pos):\n",
    "    return int(p.name.split('_')[pos].split('-')[-1])\n",
    "\n",
    "image_paths1 = [p for p in path1.iterdir() if p.name != 'desktop.ini']\n",
    "image_paths1.sort(key=partial(get_stim_id, pos=3))\n",
    "image_paths2 = [p for p in path2.iterdir() if p.name != 'desktop.ini']\n",
    "image_paths2.sort(key=partial(get_stim_id, pos=0))\n",
    "\n",
    "stimuli_path = dataset_path / 'nsddata_stimuli' / 'stimuli' / 'nsd' / 'nsd_stimuli.hdf5'\n",
    "stimulus_images = h5py.File(stimuli_path, 'r')['imgBrick']\n",
    "\n",
    "stimulus_ids = [get_stim_id(p, pos=1) for p in image_paths2]\n",
    "X = index_unsorted(stimulus_images, stimulus_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "969baa12-6db1-439e-9615-c95e341c9c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 425, 425, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de82734b-d299-4e4c-b059-92735bba46e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147, 4, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "all_recon = []\n",
    "for i in range(X.shape[0] // 3):\n",
    "    x_real = X[i * 3]\n",
    "    x_recon1 = np.stack([np.array(Image.open(image_paths1[i * 3 + j])) for j in range(3)])\n",
    "    x_recon2 = np.stack([np.array(Image.open(image_paths2[i * 3 + j])) for j in range(3)])\n",
    "    x_real = np.array(Image.fromarray(x_real).resize((224, 224)))[None]\n",
    "    all_recon.append(np.concatenate([x_real, x_recon2]))\n",
    "    #all_recon.append(np.concatenate([np.zeros_like(x_real), x_recon2]))\n",
    "all_recon = np.stack(all_recon)\n",
    "print(all_recon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ca81104-2de3-4081-b000-6988a2f1855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pad = 5\n",
    "pad_images = [np.zeros_like(all_recon[0])[None] for i in range(num_pad)]\n",
    "all_recon = np.concatenate([all_recon, *pad_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a92856b-fce4-49bb-83f8-6ccc4b86dadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#out_images = rearrange(all_recon, 'n r h w c -> n h (w r) c'\n",
    "for i, out_img in enumerate(rearrange(all_recon, '(n1 n2) r h w c -> n1 (r h) (n2 w) c', n2=8)):\n",
    "    Image.fromarray(out_img).save(out_path / f'recon{i}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ba66d6-2037-4628-befb-a9247c1a2aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "recon_path = Path('X:\\\\drive_data\\\\images\\\\single_resblock')\n",
    "cascade_path = Path('X:\\\\drive_data\\\\optimization_results\\\\vqgan_imagenet_f16_1024\\\\cascade\\\\29000da3\\\\images')\n",
    "\n",
    "image_ids = ['1443537.022563', '1943899.024131', '2437971.005013', '2882301.014188']\n",
    "\n",
    "all_images = []\n",
    "for stim_id in image_ids:\n",
    "    image_paths = [p for p in recon_path.iterdir() if stim_id in p.name]\n",
    "    image_paths.sort(key=lambda p: int(p.name.split('_')[0].split('-')[1]))\n",
    "    images = np.stack([np.array(Image.open(p)) for p in image_paths])\n",
    "    all_images.append(images)\n",
    "all_images = np.stack(all_images)\n",
    "\n",
    "cascades = []\n",
    "for stim_id in image_ids:\n",
    "    cascade_img = np.array(Image.open([p for p in cascade_path.iterdir() if stim_id in p.name][0]))\n",
    "    cascades.append(cascade_img)\n",
    "cascades = np.stack(cascades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cb793b-7b90-4dff-9e53-fee47886096f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb65032-aab3-442d-b4c8-bf54a71fc357",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "out_img = rearrange(all_images[:, [0, 3, 6, 9, 11]], 'n r h w c -> (n h) (r w) c')\n",
    "plt.imshow(out_img)\n",
    "plt.show()\n",
    "out_path = Path('G:\\\\Github Repositories\\\\Google Drive\\\\School\\\\2021 Fall\\\\CMPUT 652\\\\Project\\\\images')\n",
    "Image.fromarray(out_img).save(out_path / 'resblock_comparison.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9386d05-829b-4af5-a23c-7dfea7e8be2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_img = rearrange(cascades, 'n h w c -> (n h) w c')\n",
    "plt.imshow(out_img)\n",
    "plt.show()\n",
    "out_path = Path('G:\\\\Github Repositories\\\\Google Drive\\\\School\\\\2021 Fall\\\\CMPUT 652\\\\Project\\\\images')\n",
    "Image.fromarray(out_img).save(out_path / 'cascade_comparison.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c81a85-e5c0-4ca0-9973-f5f28404edc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path('D:\\\\Datasets\\\\NSD\\\\')\n",
    "derivatives_path = dataset_path / 'derivatives'\n",
    "betas_path = dataset_path / 'nsddata_betas' / 'ppdata'\n",
    "ppdata_path = dataset_path / 'nsddata' / 'ppdata'\n",
    "stimulu_path = dataset_path / 'nsddata_stimuli' / 'stimuli' / 'nsd' / 'nsd_stimuli.hdf5'\n",
    "stimulus_images = h5py.File(stimulu_path, 'r')['imgBrick']\n",
    "subjects = {f'subj0{i}': {} for i in range(1, 9)}\n",
    "\n",
    "for subject_name, subject_data in subjects.items():\n",
    "    responses_file_path = ppdata_path / subject_name / 'behav' / 'responses.tsv'\n",
    "    subject_data['responses'] = pd.read_csv(responses_file_path, sep='\\t',)\n",
    "    \n",
    "    # The last 3 sessions are currently held-out for the algonauts challenge\n",
    "    # remove them for now.\n",
    "    session_ids = subject_data['responses']['SESSION']\n",
    "    held_out_mask = session_ids > (np.max(session_ids) - 3)\n",
    "    subject_data['responses'] = subject_data['responses'][~held_out_mask]\n",
    "\n",
    "subject_name = 'subj01'\n",
    "\n",
    "split_name = 'split-01'\n",
    "split = h5py.File(derivatives_path / 'data_splits' / f'{split_name}.hdf5')\n",
    "subject_split = split[subject_name]\n",
    "\n",
    "test_response_mask = subject_split['test_response_mask'][:].astype(bool)\n",
    "validation_response_mask = subject_split['validation_response_mask'][:].astype(bool)\n",
    "training_response_mask = ~(test_response_mask | validation_response_mask)\n",
    "\n",
    "responses = subjects[subject_name]['responses']\n",
    "response_stimulus_ids = responses['73KID'].to_numpy()\n",
    "\n",
    "\n",
    "def select_fold_images(stimulus_images, response_mask, response_stimulus_ids):\n",
    "    response_ids = np.where(response_mask)[0]\n",
    "    stimulus_ids = response_stimulus_ids[response_ids] - 1\n",
    "    \n",
    "    argsort_ids = np.argsort(stimulus_ids)\n",
    "    unique_results = np.unique(stimulus_ids, return_counts=True)\n",
    "    unique_stimulus_ids, unique_stimulus_counts = unique_results\n",
    "    \n",
    "    X_averaged = stimulus_images[unique_stimulus_ids]\n",
    "    X = np.repeat(X_averaged, unique_stimulus_counts, axis=0)\n",
    "    \n",
    "    return X, X_averaged\n",
    "\n",
    "X_val, X_val_avg = select_fold_images(stimulus_images, validation_response_mask, response_stimulus_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f960a9f2-a084-4c03-a922-cc9709547eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_results_path = Path('D:\\\\Datasets\\\\NSD\\\\derivatives\\\\results\\\\ViT-B=32\\\\embedding\\\\standard\\\\subj01\\\\images')\n",
    "in_path = clip_results_path / 'batch-0'\n",
    "out_path = clip_results_path / 'derived'\n",
    "def get_stim_id(p):\n",
    "    return int(p.name.split('_')[3].split('-')[-1])\n",
    "\n",
    "image_paths = list(in_path.iterdir())\n",
    "image_paths.sort(key=get_stim_id)\n",
    "\n",
    "all_recon = []\n",
    "for i in range(200):\n",
    "    x_real = X_val[i * 3]\n",
    "    x_recon = np.stack([np.array(Image.open(image_paths[i * 3 + j])) for j in range(3)])\n",
    "    x_real = np.array(Image.fromarray(x_real).resize((224, 224)))\n",
    "    x = np.concatenate([x_real[None], x_recon])\n",
    "    all_recon.append(x)\n",
    "all_recon = np.stack(all_recon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45cbf83-a2cb-43a8-b874-794faca5353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(all_recon[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904031a4-9cd6-4c20-8196-39a9cf586917",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_recon.shape\n",
    "#out_images = rearrange(all_recon, 'n r h w c -> n h (w r) c'\n",
    "for i, out_img in enumerate(rearrange(all_recon, '(n1 n2) r h w c -> n1 (r h) (n2 w) c', n2=8)):\n",
    "    Image.fromarray(out_img).save(out_path / f'recon{i}.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Neurophysiological-Data-Decoding",
   "language": "python",
   "name": "neurophysiological-data-decoding"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
