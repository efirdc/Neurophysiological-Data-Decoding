{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1586e8a2-0820-4d0a-9c5a-00a7a1b7e491",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchio as tio\n",
    "import h5py\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "dir2 = os.path.abspath('..')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: \n",
    "    sys.path.append(dir1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7ac2d6-5f97-484d-959c-a5da6afd4d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "dataset_path = Path('D:\\\\Datasets\\\\NSD')\n",
    "stimulu_path = dataset_path / 'nsddata_stimuli' / 'stimuli' / 'nsd' / 'nsd_stimuli.hdf5'\n",
    "stimulus_images = h5py.File(stimulu_path, 'r')['imgBrick']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee79454-c16e-4429-b38d-507c3d97316c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a clip model\n",
    "import clip\n",
    "\n",
    "print(clip.available_models())\n",
    "model_name = 'ViT-B/32'\n",
    "model, preprocess = clip.load(model_name, device=device)\n",
    "model = model.visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f0dace-6360-4629-8aa0-8afc04da0cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laod a torchvision model\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms as T\n",
    "\n",
    "model_name = 'vgg19_bn'\n",
    "model = models.vgg19_bn(pretrained=True)\n",
    "model.to(device)\n",
    "normalize = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "preprocess = T.Compose([T.Resize(256), T.CenterCrop(224), T.ToTensor(), normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98ace34-9594-4572-817a-e4d591224247",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(model.named_modules()).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afd7696-ba8f-427d-af9f-1d88649f038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature visualizer\n",
    "from PIL import Image\n",
    "from functools import partial\n",
    "\n",
    "def vis_features(x):\n",
    "    if not isinstance(x, torch.Tensor):\n",
    "        print(type(x))\n",
    "        return\n",
    "    x = x.float().cpu()\n",
    "    print(x.shape, x.dtype)\n",
    "    if len(x.shape) != 4:\n",
    "        return\n",
    "    N, C, W, H = x.shape\n",
    "    \n",
    "    print(x.mean(), x.std())\n",
    "\n",
    "    @interact(i=(0, N-1), c=(0, C-1))\n",
    "    def plot_feature_map(i, c):\n",
    "        fig = plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(x[i, c].cpu(), cmap=\"gray\")\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "modules = dict(model.named_modules())\n",
    "#print([(node, modules[node].__class__.__name__) for node in nodes if node in modules])\n",
    "N = stimulus_images.shape[0]\n",
    "@interact(module_name=modules.keys(), stimulus_id=range(N))\n",
    "def select_module(module_name, stimulus_id):\n",
    "    image_data = stimulus_images[stimulus_id]\n",
    "    image = Image.fromarray(image_data)\n",
    "    x = preprocess(image).unsqueeze(0).to(device).to(torch.float16)\n",
    "    \n",
    "    features = {}\n",
    "    def forward_hook(module_name, module, x_in, x_out):\n",
    "        features[module_name] = x_out.clone()\n",
    "    \n",
    "    module = modules[module_name]\n",
    "    hook_handle = module.register_forward_hook(partial(forward_hook, module_name))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model(x)\n",
    "    \n",
    "    vis_features(features[module_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cffdbe-864c-46c0-9bc1-3401cbf00c07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Label vgg nodes\n",
    "\n",
    "layer = 1\n",
    "counts = {'conv':0, 'bn': 0, 'relu': 0}\n",
    "out = {}\n",
    "for node in nodes:\n",
    "    if not node.startswith('features'):\n",
    "        continue\n",
    "    num = int(node.split('.')[1])\n",
    "    \n",
    "    module = modules[node]\n",
    "    module_name = module.__class__.__name__\n",
    "    short_module_name = {'Conv2d': 'conv', 'BatchNorm2d': 'bn', 'ReLU': 'relu', 'MaxPool2d': 'pool'}[module_name]\n",
    "    if short_module_name == \"pool\":\n",
    "        layer += 1\n",
    "        counts = {k: 0 for k in counts.keys()}\n",
    "        continue\n",
    "    counts[short_module_name] += 1\n",
    "    \n",
    "    out[node] = f'layer{layer}.{short_module_name}.{counts[short_module_name]}'\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0573f41-96f2-44e6-aae8-38ca5de113b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "[node for node in nodes if node.endswith('add')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08bb13b-4eeb-4eef-a6e1-e8fc3447a17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_nodes = [\n",
    "    'layer1.2.add',\n",
    "    'layer2.3.add',\n",
    "    'layer3.5.add',\n",
    "    'layer4.2.add',\n",
    "    'attnpool.getitem_6',\n",
    "    'attnpool.getitem_8',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73e3d21-738b-4351-a9cc-76ca36b5c3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_nodes = {\n",
    "    'features.10': 'layer2.conv.2',\n",
    "    'features.11': 'layer2.bn.2',\n",
    "    'features.12': 'layer2.relu.2',\n",
    "    'features.23': 'layer3.conv.4',\n",
    "    'features.24': 'layer3.bn.4',\n",
    "    'features.25': 'layer3.relu.4',\n",
    "    'features.36': 'layer4.conv.4',\n",
    "    'features.37': 'layer4.bn.4',\n",
    "    'features.38': 'layer4.relu.4',\n",
    "    'features.49': 'layer5.conv.4',\n",
    "    'features.50': 'layer5.bn.4',\n",
    "    'features.51': 'layer5.relu.4',\n",
    "    'classifier.0': 'classifier.0',\n",
    "    'classifier.3': 'classifier.3',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db54ea6e-957e-49f5-967a-e77c242d4a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_modules = {\n",
    "    **{f'transformer.resblocks.{i}': f'transformer.resblocks.{i}' for i in range(12)},\n",
    "    '': 'embedding'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aaebf8-6baa-46ca-b058-86ec2fed9255",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_modules = {\n",
    "    '': 'embedding'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d608910b-9314-4232-89eb-d35959cafcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e48921-51ed-4d7a-b79b-56c987c43aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "from functools import partial\n",
    "from typing import Sequence, Dict\n",
    "\n",
    "derivatives_path = dataset_path / 'derivatives' / 'stimulus_embeddings'\n",
    "modules = dict(model.named_modules())\n",
    "\n",
    "with h5py.File(derivatives_path / f\"{model_name.replace('/', '=')}-embeddings.hdf5\", \"a\") as f:\n",
    "    N = stimulus_images.shape[0]\n",
    "    \n",
    "    for stimulus_id in tqdm(range(N)):\n",
    "        image_data = stimulus_images[stimulus_id]\n",
    "        image = Image.fromarray(image_data)\n",
    "        x = preprocess(image).unsqueeze(0).to(device).to(torch.float16)\n",
    "\n",
    "        features = {}\n",
    "        def forward_hook(module_name, module, x_in, x_out):\n",
    "            if x_out.shape[0] == 1:\n",
    "                x_out = x_out[0]\n",
    "            features[module_name] = x_out.clone().cpu().numpy()\n",
    "        \n",
    "        hook_handles = []\n",
    "        if isinstance(save_modules, Sequence):\n",
    "            for module_name in save_modules:\n",
    "                module = modules[module_name]\n",
    "                hook_handle = module.register_forward_hook(partial(forward_hook, module_name))\n",
    "                hook_handles.append(hook_handle)\n",
    "        elif isinstance(save_modules, Dict):\n",
    "            for module_name, feature_name in save_modules.items():\n",
    "                module = modules[module_name]\n",
    "                hook_handle = module.register_forward_hook(partial(forward_hook, feature_name))\n",
    "                hook_handles.append(hook_handle)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model(x)\n",
    "            \n",
    "        for hook_handle in hook_handles:\n",
    "            hook_handle.remove()\n",
    "        \n",
    "        for feature_name, feature in features.items():\n",
    "            f.require_dataset(feature_name, (N, *feature.shape), feature.dtype)\n",
    "            f[feature_name][stimulus_id] = feature\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Neurophysiological-Data-Decoding",
   "language": "python",
   "name": "neurophysiological-data-decoding"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
