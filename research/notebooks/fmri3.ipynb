{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d32ecc06-4f84-477e-ac9a-55e57d5e5c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchio as tio\n",
    "import h5py\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "dir2 = os.path.abspath('..')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: \n",
    "    sys.path.append(dir1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4de60a67-ae95-45d2-8318-cdf8d2a17392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def require_dataset(group, name, data):\n",
    "    group.require_dataset(name, shape=data.shape, dtype=data.dtype)\n",
    "    group[name][:] = data\n",
    "    \n",
    "dataset_path = Path(\"X:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\\")\n",
    "derivatives_path = dataset_path / 'derivatives'\n",
    "\n",
    "ssd_dataset_path = Path(\"D:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\\")\n",
    "ssd_derivatives_path = ssd_dataset_path / 'derivatives'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8f4b5f-edfa-4e3f-8ff2-e98d2c35bdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from research.data.kamitani_2019 import Kamitani2019, RawKamitani2019, Kamitani2019H5\n",
    "from pathlib import Path\n",
    "\n",
    "#root = \"X:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\\"\n",
    "#h5_path = Path(root) / \"derivatives\" / \"kamitani2019.hdf5\"\n",
    "features_name = 'ViT-B=32'\n",
    "#features_path = Path(root) / \"derivatives\" / \"features\" / f\"{features_name}-features.hdf5\"\n",
    "dataset = Kamitani2019H5(\n",
    "    ssd_derivatives_path / 'kamitani2019.hdf5', \n",
    "    subjects=['sub-02'], \n",
    "    func_sessions=['natural_training'], \n",
    "    window=(1, 9),\n",
    "    #window_kernel=[.25, .25, .25, .25],\n",
    "    #transform=tio.CropOrPad(target_shape=(72, 88, 74)),\n",
    "    #drop_out_of_window_events=True,\n",
    "    normalization='voxel_linear_trend',\n",
    "    features_path=derivatives_path / \"features\" / f\"{features_name}-features.hdf5\",\n",
    "    feature_keys=['embedding'],\n",
    "    #folds=[0, 1, 2, 3],\n",
    "    #split='train'\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed4e9fb-9541-474c-bc52-86ef772828a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f4b2f8-8da1-4071-8099-146739190e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(i=(0, len(dataset)-1))\n",
    "def show_event(i):\n",
    "    event = dataset[i]\n",
    "    \n",
    "    if 'features' in event:\n",
    "        for k, v in event['features'].items():\n",
    "            print(k, v.shape, v.numel())\n",
    "    \n",
    "    print(event['onset'], event['stimulus_id'], event['run_id'])\n",
    "    data = event['data']\n",
    "    print(data.shape, data.dtype)\n",
    "    \n",
    "    T, H, W, D = data.shape\n",
    "    @interact(d=(0, D-1), t=(0, T-1), derivative=False)\n",
    "    def show_volume(d, t, derivative):\n",
    "        fig = plt.figure(figsize=(12, 12))\n",
    "        x = data[t, :, :, d]\n",
    "        #x = np.isinf(x)\n",
    "        plt.imshow(x, cmap='bwr', vmin=-3, vmax=3)\n",
    "        plt.show()\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a002c8e-1c24-4ed4-863a-45a9115296e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "root = \"X:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\\"\n",
    "\n",
    "def require_dataset(group, name, data):\n",
    "    group.require_dataset(name, shape=data.shape, dtype=data.dtype)\n",
    "    group[name][:] = data\n",
    "\n",
    "with h5py.File(Path(root) / 'derivatives' / 'feature-selection-maps.hdf5', 'a') as f:\n",
    "    for subject in f.values():\n",
    "        for session in subject.values():\n",
    "            for cache in session.values():\n",
    "                for model in cache.values():\n",
    "                    for feature in model.values():\n",
    "                        for selection_mode in feature.values():\n",
    "                            print(selection_mode.name)\n",
    "                                                         \n",
    "                            data = selection_mode['scores'][:]\n",
    "                            sorted_indices_flat = selection_mode['sorted_indices_flat'][:]\n",
    "                            H, W, D = data.shape\n",
    "                            grid = np.zeros(shape=(3, H, W, D), dtype=int)\n",
    "                            grid[0] = np.arange(H)[:, None, None]\n",
    "                            grid[1] = np.arange(W)[None, :, None]\n",
    "                            grid[2] = np.arange(D)[None, None, :]\n",
    "                            grid_flat = grid.reshape(3, H * W * D)\n",
    "                            sorted_indices = grid_flat[:, sorted_indices_flat]\n",
    "                            \n",
    "                            require_dataset(selection_mode, 'sorted_indices', sorted_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380eb03e-61d2-4936-bf49-470003f88fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_maps = h5py.File(Path(root) / 'derivatives' / 'feature-selection-maps.hdf5', 'r')\n",
    "\n",
    "@interact(subject=feature_selection_maps.items())\n",
    "def select_subject(subject):\n",
    "    @interact(session=subject.items())\n",
    "    def select_session(session):\n",
    "        \n",
    "        @interact(cache=session.items())\n",
    "        def select_cache(cache):\n",
    "            \n",
    "            @interact(model=cache.items())\n",
    "            def select_model(model):\n",
    "                @interact(feature=model.items())\n",
    "                def select_feature(feature):\n",
    "                    @interact(mode=feature.items(), select_top=False, select_k=(0, 15000))\n",
    "                    def select_mode(mode, select_top, select_k):\n",
    "\n",
    "                        print(mode.items())\n",
    "                        data = mode['scores'][:]\n",
    "                        sorted_indices_flat = mode['sorted_indices_flat'][:]\n",
    "                        H, W, D = data.shape\n",
    "                        grid = np.zeros(shape=(3, H, W, D), dtype=int)\n",
    "                        grid[0] = np.arange(H)[:, None, None]\n",
    "                        grid[1] = np.arange(W)[None, :, None]\n",
    "                        grid[2] = np.arange(D)[None, None, :]\n",
    "                        grid_flat = grid.reshape(3, H * W * D)\n",
    "                        sorted_indices = grid_flat[:, sorted_indices_flat]\n",
    "                        \n",
    "                        if select_top:\n",
    "                            data[:] = 0.\n",
    "                            top_k = sorted_indices[:, -select_k:]\n",
    "                            i, j, k = list(top_k)\n",
    "                            data[i, j, k] = 1.\n",
    "                            \n",
    "                            #original_shape = data.shape\n",
    "                            #data = data.flatten()\n",
    "                            #data[top_k] = 1.\n",
    "                            #data = data.reshape(*original_shape)\n",
    "                        \n",
    "                        H, W, D = data.shape\n",
    "                        @interact(d=(0, D-1))\n",
    "                        def show_volume(d):\n",
    "                            fig = plt.figure(figsize=(12, 12))\n",
    "                            x = data[:, :, d]\n",
    "                            plt.imshow(x, vmin=0.05, vmax=0.3)\n",
    "                            plt.show()\n",
    "                            plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d62f7e-d094-458a-997f-770bacdee6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torchio as tio\n",
    "\n",
    "rois_path = Path('X:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\derivatives\\\\rois\\\\')\n",
    "for subject_name in ('sub-01', 'sub-02', 'sub-03'):\n",
    "    print(subject_name)\n",
    "    \n",
    "    kamitani_rois_path = rois_path / subject_name / 'kamitani' \n",
    "    rois = [tio.LabelMap(roi_path) for roi_path in kamitani_rois_path.iterdir()]\n",
    "    roi_names = [p.name.split('.')[0].split('_') for p in kamitani_rois_path.iterdir()]\n",
    "    roi_names = [f'{name[2]}_{name[3]}' for name in roi_names]\n",
    "    \n",
    "    for roi in rois:\n",
    "        roi.load()\n",
    "        \n",
    "    data = torch.stack([roi.data.flatten().bool() for roi in rois])\n",
    "    overlap = (data[None, :] & data[:, None]).sum(axis=2)\n",
    "    \n",
    "    #print(overlap)\n",
    "    #plt.imshow(overlap)\n",
    "    #plt.show()\n",
    "    \n",
    "    union = torch.cat([roi.data for roi in rois]).sum(dim=0, keepdim=True)\n",
    "    union[union > 0] = 1\n",
    "    union = union.to(torch.int32)\n",
    "    union_image = tio.LabelMap(tensor=union, affine=rois[0].affine)\n",
    "    union_image.save(rois_path / subject_name / 'derivatives' / f'{subject_name}_mask_VC.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bce019-1f03-45bc-ab37-54bb173ea041",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cache a preprocessing option\n",
    "\n",
    "import gc\n",
    "from copy import deepcopy\n",
    "from research.data.kamitani_2019 import Kamitani2019, RawKamitani2019, Kamitani2019H5\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "cache_name = 'window-0-16'\n",
    "#cache_name = 'average-4'\n",
    "\n",
    "subjects = ['sub-01', 'sub-02', 'sub-03']\n",
    "sessions = ['natural_test']\n",
    "\n",
    "target_shape = (72, 88, 74)\n",
    "preprocessing_params = dict(\n",
    "    window=(0, 9),\n",
    "    #window_kernel=[1. / 4.] * 4,\n",
    "    #transform=tio.CropOrPad(target_shape=target_shape),\n",
    "    drop_out_of_window_events=False,\n",
    "    normalization='voxel_linear_trend',\n",
    ")\n",
    "\n",
    "with h5py.File(ssd_derivatives_path / 'kamitani2019-cached.hdf5', 'a') as f:\n",
    "    for subject in subjects:\n",
    "        print(subject)\n",
    "        \n",
    "        for session in sessions:\n",
    "            print(session)\n",
    "            h5_path = ssd_derivatives_path / \"kamitani2019.hdf5\"\n",
    "            dataset = Kamitani2019H5(h5_path, subjects=[subject], func_sessions=[session], **preprocessing_params)\n",
    "            N = len(dataset)\n",
    "            \n",
    "            group = f.require_group(f'{subject}/{session}/{cache_name}')\n",
    "            sample_event = dataset[0]\n",
    "            group.attrs['affine'] = sample_event['affine']\n",
    "            target_shape = (*sample_event['data'].shape,)\n",
    "        \n",
    "            data = group.require_dataset('data', shape=(N, *target_shape), dtype='f4')\n",
    "            for k, v in preprocessing_params.items():\n",
    "                group.attrs[k] = str(v)\n",
    "            \n",
    "            out_data = {\n",
    "                k: [] for k in \n",
    "                ['stimulus_id', 'onset', 'run_id', 'in_window']\n",
    "            }\n",
    "            \n",
    "            for i in tqdm(range(len(dataset))):\n",
    "                event = dataset[i]\n",
    "                for k, v in out_data.items():\n",
    "                    v.append(deepcopy(event[k]))\n",
    "                data[i] = event['data']\n",
    "\n",
    "            for k, v in out_data.items():\n",
    "                v = np.stack(v)\n",
    "                if k == 'stimulus_id':\n",
    "                    v = v.astype(np.dtype('S'))\n",
    "                print(k, v.dtype, v.shape)\n",
    "                require_dataset(group, k, v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5b046c-5760-42a9-becb-247bf79d31a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbaabfa-435b-45ad-9813-88d5d6b736e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_data = h5py.File(ssd_derivatives_path / 'kamitani2019-cached.hdf5', 'r')\n",
    "\n",
    "session_name = 'natural_training'\n",
    "cache_name = 'window-0-16'\n",
    "\n",
    "def pearsonr_torch(X, Y, cast_dtype=torch.float64):\n",
    "    in_dtype = X.dtype\n",
    "    X = X.to(cast_dtype)\n",
    "    Y = Y.to(cast_dtype)\n",
    "    \n",
    "    X = X - X.mean(dim=0, keepdim=True)\n",
    "    Y = Y - Y.mean(dim=0, keepdim=True)\n",
    "    \n",
    "    X = X / torch.norm(X, dim=0, keepdim=True)\n",
    "    Y = Y / torch.norm(Y, dim=0, keepdim=True)\n",
    "    \n",
    "    r = torch.einsum('b...,b...->...', X, Y).to(in_dtype)\n",
    "    return r\n",
    "\n",
    "with h5py.File(derivatives_path / 'noise-ceilings.hdf5', 'a') as f:\n",
    "    for subject_name, subject in fmri_data.items():\n",
    "        cache = subject[session_name][cache_name]\n",
    "        affine = cache.attrs['affine']\n",
    "        group = f.require_group(f'{subject_name}/{session_name}/{cache_name}')\n",
    "        group.attrs['affine'] = affine\n",
    "        \n",
    "        # stimulus_id is already sorted\n",
    "        stimulus_id = cache['stimulus_id'][:]\n",
    "        stimulus_indices = torch.arange(stimulus_id.shape[0])\n",
    "        unique_stimulus_id, unique_indicies, unique_inverse, unique_counts = np.unique(\n",
    "            stimulus_id, \n",
    "            return_index=True, \n",
    "            return_inverse=True,\n",
    "            return_counts=True\n",
    "        )\n",
    "        splits = torch.split(stimulus_indices, list(unique_counts))\n",
    "        split_half_1_indices = torch.cat([split[:2] for split in splits])\n",
    "        split_half_2_indices = torch.cat([split[2:4] for split in splits])\n",
    "        \n",
    "        X = cache['data']\n",
    "        \n",
    "        load_time = 0\n",
    "        compute_time = 0\n",
    "        store_time = 0\n",
    "\n",
    "        for i in tqdm(range(X.shape[2])):\n",
    "            t = time.time()\n",
    "            X_slice = torch.from_numpy(X[:, :, i])\n",
    "            load_time += time.time() - t\n",
    "\n",
    "            t = time.time()\n",
    "            X_slice_half_1 = X_slice[split_half_1_indices]\n",
    "            X_slice_half_2 = X_slice[split_half_2_indices]\n",
    "            r = torch.stack([\n",
    "                pearsonr_torch(X_slice_half_1[:, j].cuda(), X_slice_half_2[:, j].cuda()).cpu()\n",
    "                for j in range(X_slice.shape[1])\n",
    "            ])\n",
    "            r[r < 0.] = 0.\n",
    "            r = np.sqrt(2 * r / (r + 1.))\n",
    "            \n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            compute_time += time.time() - t\n",
    "\n",
    "            keys = (subject_name, session_name, cache_name, 'split_half', 'pearsonr')\n",
    "            key = '/'.join(keys)\n",
    "            parameters_dataset = f.require_dataset(key, X.shape[1:], dtype=np.float32)\n",
    "            t = time.time()\n",
    "            parameters_dataset[:, i] = r\n",
    "            store_time += time.time() - t\n",
    "\n",
    "            if i % 25 == 0:\n",
    "                n = (i + 1)\n",
    "                print(f'load_time={load_time / n}, compute_time={compute_time / n}, store_time={store_time / n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd90e85-4394-4d0d-bf11-75af68db375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save encoder results\n",
    "\n",
    "from pathlib import Path\n",
    "import torchio as tio\n",
    "from functools import partial\n",
    "import nibabel as nib\n",
    "\n",
    "out_path = derivatives_path / 'correlation_maps'\n",
    "with h5py.File(derivatives_path / 'noise-ceilings.hdf5', 'a') as f:\n",
    "    for subject_name, subject in f.items():\n",
    "        subject_out_path = out_path / subject_name\n",
    "        subject_out_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for session_name, session in subject.items():\n",
    "            for cache_name, cache in session.items():\n",
    "                affine = cache.attrs['affine']\n",
    "                for noise_ceiling_name, noise_ceiling in cache.items():\n",
    "                    for measure_name, measure in noise_ceiling.items():\n",
    "                    \n",
    "                        keys = (subject_name, session_name, cache_name, \n",
    "                                noise_ceiling_name, measure_name)\n",
    "                        print(*keys)\n",
    "\n",
    "                        save_file_name = f'{\"__\".join(keys)}.nii.gz'\n",
    "\n",
    "                        data = measure['scores'][:]\n",
    "                        sorted_indices_flat = np.argsort(data, axis=None)\n",
    "\n",
    "                        T, H, W, D = data.shape\n",
    "                        grid = np.zeros(shape=(4, T, H, W, D), dtype=int)\n",
    "                        grid[0] = np.arange(T)[:, None, None, None]\n",
    "                        grid[1] = np.arange(H)[None, :, None, None]\n",
    "                        grid[2] = np.arange(W)[None, None, :, None]\n",
    "                        grid[3] = np.arange(D)[None, None, None, :]\n",
    "                        grid_flat = grid.reshape(4, T * H * W * D)\n",
    "                        sorted_indices = grid_flat[:, sorted_indices_flat]\n",
    "\n",
    "                        image = nib.Nifti1Image(torch.tensor(data).permute(1, 2, 3, 0).numpy(), affine)\n",
    "                        nib.save(image, subject_out_path / save_file_name)\n",
    "\n",
    "                        require_dataset(measure, 'sorted_indices_flat', sorted_indices_flat)\n",
    "                        require_dataset(measure, 'sorted_indices', sorted_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad229d5-7f39-42b6-8cf6-8aec7e62b775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit encoders\n",
    "\n",
    "from pathlib import Path\n",
    "from tq\n",
    ".notebook import tqdm\n",
    "from itertools import product\n",
    "from research.data.kamitani_2019 import fix_stimulus_id\n",
    "import time\n",
    "from functools import partial\n",
    "from einops import rearrange\n",
    "import gc\n",
    "\n",
    "def least_squares(A, B, batch_size=1,):\n",
    "    A_batch_dimensions = A.shape[:-2]\n",
    "    B_batch_dimensions = B.shape[:-2]\n",
    "    \n",
    "    A = rearrange(A, '... m n -> (...) m n')\n",
    "    B = rearrange(B, '... m k -> (...) m k')\n",
    "    \n",
    "    solution = torch.stack([\n",
    "        torch.cat([\n",
    "            torch.linalg.lstsq(a, b).solution.cpu()\n",
    "            for b in tqdm(torch.split(B, batch_size))\n",
    "        ])\n",
    "        for a in tqdm(torch.split(A, batch_size))\n",
    "    ])\n",
    "    solution = solution.reshape(*A_batch_dimensions, *B_batch_dimensions, A.shape[-1], B.shape[-1])\n",
    "    return solution\n",
    "\n",
    "\n",
    "def ridge_regression(A, B, alpha=None, batch_size=1,):\n",
    "    A_batch_dimensions = A.shape[:-2]\n",
    "    B_batch_dimensions = B.shape[:-2]\n",
    "    \n",
    "    A = rearrange(A, '... m n -> (...) m n')\n",
    "    B = rearrange(B, '... m k -> (...) m k')\n",
    "    \n",
    "    def fit(X, Y):\n",
    "        lhs = torch.einsum('... i j, ... i k -> ... j k', X, X)\n",
    "        rhs = torch.einsum('... i j, ... i k -> ... j k', X, Y)\n",
    "        if alpha is None:\n",
    "            return torch.linalg.lstsq(lhs, rhs)\n",
    "        else:\n",
    "            ridge = alpha * torch.eye(lhs.shape[0], device=lhs.device)\n",
    "            return torch.linalg.lstsq(lhs + ridge, rhs)\n",
    "    \n",
    "    solution = torch.stack([\n",
    "        torch.cat([\n",
    "            fit(a, b).solution.cpu()\n",
    "            for b in torch.split(B, batch_size)\n",
    "        ])\n",
    "        for a in torch.split(A, batch_size)\n",
    "    ])\n",
    "    solution = solution.reshape(*A_batch_dimensions, *B_batch_dimensions, A.shape[-1], B.shape[-1])\n",
    "    return solution\n",
    "\n",
    "fmri_data = h5py.File(ssd_derivatives_path / 'kamitani2019-cached.hdf5', 'r')\n",
    "\n",
    "fit_sessions = ['natural_train']\n",
    "\n",
    "cache_name = 'window-0-16'\n",
    "run_features = {\n",
    "    #'bigbigan-resnet50': ['z_mean'],\n",
    "    'ViT-B=32': ['embedding',],# *(f'transformer.resblocks.{i}' for i in range(12))],\n",
    "    #'biggan-128': ['z', 'y_embedding'],\n",
    "    #'vqgan': ['vqgan-f16-1024-pre_quant'],\n",
    "}\n",
    "\n",
    "fit_encoders = {\n",
    "    f'ridge_alpha={alpha}': partial(ridge_regression, alpha=alpha)\n",
    "    for alpha in [0.1, 1., 10.]\n",
    "}\n",
    "\n",
    "seed = 0\n",
    "max_features = 512\n",
    "\n",
    "with h5py.File(derivatives_path / 'feature-encoder-parameters.hdf5', 'a') as f:\n",
    "    for subject_name, subject in fmri_data.items():\n",
    "        for session_name, session in subject.items():\n",
    "            if session_name not in fit_sessions:\n",
    "                continue\n",
    "                \n",
    "            if cache_name not in session:\n",
    "                print(f'{cache_name} not found for session {session_name}, subject {subject_name}')\n",
    "                continue\n",
    "            \n",
    "            cache = session[cache_name]\n",
    "            affine = cache.attrs['affine']\n",
    "            group = f.require_group(f'{subject_name}/{session_name}/{cache_name}')\n",
    "            group.attrs['affine'] = affine\n",
    "            X = cache['data']\n",
    "\n",
    "            for model_name, feature_names in run_features.items():\n",
    "                model_features = h5py.File(derivatives_path / 'features' / f'{model_name}-features.hdf5', 'r')\n",
    "                stimulus_ids = session[f'{cache_name}/stimulus_id'][:]\n",
    "                stimulus_ids = [s.decode('utf-8') for s in stimulus_ids]\n",
    "                stimulus_ids = [fix_stimulus_id(s, model_features.keys()) for s in stimulus_ids]\n",
    "                \n",
    "                features = {}\n",
    "                for feature_name in feature_names:\n",
    "                    print(subject_name, model_name, feature_name)\n",
    "                    Y = np.stack([model_features[f'{stimulus_id}/{feature_name}'][:]\n",
    "                                  for stimulus_id in stimulus_ids])\n",
    "                    Y = torch.from_numpy(Y)\n",
    "                    Y = Y.flatten(start_dim=1)\n",
    "                    if Y.shape[1] > max_features:\n",
    "                        np.random.seed(seed)\n",
    "                        choice = np.random.choice(max_features, size=max_features)\n",
    "                        Y = Y[:, choice]\n",
    "                    features[feature_name] = Y\n",
    "\n",
    "                load_time = 0\n",
    "                compute_time = 0\n",
    "                store_time = 0\n",
    "                \n",
    "                for i in tqdm(range(X.shape[2])):\n",
    "                    t = time.time()\n",
    "                    X_slice = torch.from_numpy(X[:, :, i])\n",
    "                    load_time += time.time() - t\n",
    "                    \n",
    "                    for feature_name in feature_names:\n",
    "                        Y = features[feature_name]\n",
    "                        \n",
    "                        for encoder_name, encoder_func in fit_encoders.items():\n",
    "                            t = time.time()\n",
    "                            solution = encoder_func(Y.float().cuda(), rearrange(X_slice, 'n t ... -> ... n t').cuda(), batch_size=50)\n",
    "                            solution = rearrange(solution, '... t -> t ...')\n",
    "                            gc.collect()\n",
    "                            torch.cuda.empty_cache()\n",
    "                            \n",
    "                            compute_time += time.time() - t\n",
    "\n",
    "                            keys = (subject_name, session_name, cache_name, model_name, feature_name, encoder_name, 'parameters')\n",
    "                            key = '/'.join(keys)\n",
    "                            parameters_dataset = f.require_dataset(key, (*X.shape[1:], solution.shape[-1]), dtype=np.float32)\n",
    "                            t = time.time()\n",
    "                            parameters_dataset[:, i] = solution\n",
    "                            store_time += time.time() - t\n",
    "\n",
    "                    if i % 25 == 0:\n",
    "                        n = (i + 1)\n",
    "                        print(f'load_time={load_time / n}, compute_time={compute_time / n}, store_time={store_time / n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf2fc06-67e6-4d75-bb65-959018a426d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run encoders\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from itertools import product\n",
    "from research.data.kamitani_2019 import fix_stimulus_id\n",
    "import time\n",
    "from functools import partial\n",
    "from einops import rearrange\n",
    "import gc\n",
    "\n",
    "def pearsonr_torch(X, Y, cast_dtype=torch.float64):\n",
    "    in_dtype = X.dtype\n",
    "    X = X.to(cast_dtype)\n",
    "    Y = Y.to(cast_dtype)\n",
    "    \n",
    "    X = X - X.mean(dim=0, keepdim=True)\n",
    "    Y = Y - Y.mean(dim=0, keepdim=True)\n",
    "    \n",
    "    X = X / torch.norm(X, dim=0, keepdim=True)\n",
    "    Y = Y / torch.norm(Y, dim=0, keepdim=True)\n",
    "    \n",
    "    r = torch.einsum('b...,b...->...', X, Y).to(in_dtype)\n",
    "    return r\n",
    "\n",
    "fmri_data = h5py.File(ssd_derivatives_path / 'kamitani2019-cached.hdf5', 'r')\n",
    "encoder_parameters = h5py.File(derivatives_path / 'feature-encoder-parameters.hdf5', 'r')\n",
    "\n",
    "cache_name = 'window-0-16'\n",
    "run_features = {\n",
    "    #'bigbigan-resnet50': ['z_mean'],\n",
    "    'ViT-B=32': ['embedding',],# *(f'transformer.resblocks.{i}' for i in range(12))],\n",
    "    #'biggan-128': ['z', 'y_embedding'],\n",
    "    #'vqgan': ['vqgan-f16-1024-pre_quant'],\n",
    "}\n",
    "\n",
    "subject_names = ['sub-03']\n",
    "fit_session_name = 'natural_training'\n",
    "run_session_names = ['natural_training', 'natural_test']\n",
    "\n",
    "seed = 0\n",
    "max_features = 512\n",
    "\n",
    "with h5py.File(derivatives_path / 'feature-encoder-results.hdf5', 'a') as f:\n",
    "    for subject_name in subject_names:\n",
    "\n",
    "        fit_session_params = encoder_parameters[f'{subject_name}/{fit_session_name}/{cache_name}']\n",
    "        for run_session_name in run_session_names:\n",
    "            run_session_cache = fmri_data[f'{subject_name}/{run_session_name}/{cache_name}']\n",
    "\n",
    "            affine = run_session_cache.attrs['affine']\n",
    "            group = f.require_group(f'{subject_name}/{fit_session_name}/{run_session_name}/{cache_name}')\n",
    "            group.attrs['affine'] = affine\n",
    "            X = run_session_cache['data']\n",
    "\n",
    "            for model_name, feature_names in run_features.items():\n",
    "                model_features = h5py.File(derivatives_path / 'features' / f'{model_name}-features.hdf5', 'r')\n",
    "                stimulus_ids = run_session_cache['stimulus_id'][:]\n",
    "                stimulus_ids = [s.decode('utf-8') for s in stimulus_ids]\n",
    "                stimulus_ids = [fix_stimulus_id(s, model_features.keys()) for s in stimulus_ids]\n",
    "\n",
    "                features = {}\n",
    "                parameters = {}\n",
    "                for feature_name in feature_names:\n",
    "                    print(subject_name, model_name, feature_name)\n",
    "                    Y = np.stack([model_features[f'{stimulus_id}/{feature_name}'][:]\n",
    "                                  for stimulus_id in stimulus_ids])\n",
    "                    Y = torch.from_numpy(Y)\n",
    "                    Y = Y.flatten(start_dim=1)\n",
    "                    if Y.shape[1] > max_features:\n",
    "                        np.random.seed(seed)\n",
    "                        choice = np.random.choice(max_features, size=max_features)\n",
    "                        Y = Y[:, choice]\n",
    "                    features[feature_name] = Y\n",
    "                    parameters[feature_name] = fit_session_params[model_name][feature_name]\n",
    "\n",
    "                load_time = 0\n",
    "                compute_time = 0\n",
    "                store_time = 0\n",
    "\n",
    "                for i in tqdm(range(X.shape[2])):\n",
    "                    t = time.time()\n",
    "                    X_slice = torch.from_numpy(X[:, :, i])\n",
    "                    load_time += time.time() - t\n",
    "\n",
    "                    for feature_name in feature_names:\n",
    "                        gc.collect()\n",
    "                        torch.cuda.empty_cache()\n",
    "\n",
    "                        Y = features[feature_name]\n",
    "                        for encoder_name, encoder_parameters in parameters[feature_name].items():\n",
    "                            params_slice = torch.from_numpy(encoder_parameters['parameters'][:, i])\n",
    "\n",
    "                            t = time.time()\n",
    "                            X_slice_pred = torch.einsum('thde, ne -> nthd', params_slice.cuda(), Y.cuda().float()).cpu()\n",
    "                            r = torch.stack([\n",
    "                                pearsonr_torch(X_slice[:, j].cuda(), X_slice_pred[:, j].cuda()).cpu()\n",
    "                                for j in range(X_slice.shape[1])\n",
    "                            ])\n",
    "                            compute_time += time.time() - t\n",
    "\n",
    "                            keys = (model_name, feature_name, encoder_name, 'pearsonr', 'scores')\n",
    "                            key = '/'.join(keys)\n",
    "                            dataset = group.require_dataset(key, X.shape[1:], dtype=np.float32)\n",
    "                            t = time.time()\n",
    "                            dataset[:, i] = r\n",
    "                            store_time += time.time() - t\n",
    "\n",
    "                    if i % 25 == 0:\n",
    "                        n = (i + 1)\n",
    "                        print(f'load_time={load_time / n}, compute_time={compute_time / n}, store_time={store_time / n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f440df-f744-4dbc-a5d8-e120dd135467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save encoder results\n",
    "\n",
    "from pathlib import Path\n",
    "import torchio as tio\n",
    "from functools import partial\n",
    "import nibabel as nib\n",
    "\n",
    "\n",
    "out_path = derivatives_path / 'correlation_maps'\n",
    "with h5py.File(derivatives_path / 'feature-encoder-results.hdf5', 'a') as f:\n",
    "    for subject_name, subject in f.items():\n",
    "        subject_out_path = out_path / subject_name\n",
    "        subject_out_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for fit_session_name, fit_session in subject.items():\n",
    "            for run_session_name, run_session in fit_session.items():\n",
    "                for cache_name, cache in run_session.items():\n",
    "                    affine = cache.attrs['affine']\n",
    "                    for model_name, model in cache.items():\n",
    "                        for feature_name, feature in model.items():\n",
    "                            for prediction_name, prediction in feature.items():\n",
    "                                for encoder_name, encoder in prediction.items():\n",
    "                                    keys = (subject_name, fit_session_name, run_session_name,\n",
    "                                            cache_name, model_name, feature_name, prediction_name, \n",
    "                                            encoder_name, evaluation_name)\n",
    "                                    print(*keys)\n",
    "\n",
    "                                    save_file_name = f'{\"__\".join(keys)}.nii.gz'\n",
    "\n",
    "                                    data = encoder['scores'][:]\n",
    "                                    sorted_indices_flat = np.argsort(data, axis=None)\n",
    "\n",
    "                                    T, H, W, D = data.shape\n",
    "                                    grid = np.zeros(shape=(4, T, H, W, D), dtype=int)\n",
    "                                    grid[0] = np.arange(T)[:, None, None, None]\n",
    "                                    grid[1] = np.arange(H)[None, :, None, None]\n",
    "                                    grid[2] = np.arange(W)[None, None, :, None]\n",
    "                                    grid[3] = np.arange(D)[None, None, None, :]\n",
    "                                    grid_flat = grid.reshape(4, T * H * W * D)\n",
    "                                    sorted_indices = grid_flat[:, sorted_indices_flat]\n",
    "\n",
    "                                    image = nib.Nifti1Image(torch.tensor(data).permute(1, 2, 3, 0).numpy(), affine)\n",
    "                                    nib.save(image, subject_out_path / save_file_name)\n",
    "\n",
    "                                    require_dataset(prediction, 'sorted_indices_flat', sorted_indices_flat)\n",
    "                                    require_dataset(prediction, 'sorted_indices', sorted_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651e1713-2d40-4e2b-9b8a-f6ac01c4d8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f006358-3bd3-4e96-9bca-7b740b1d77fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_data['sub-01/natural_training/window-0-16/data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f605e15a-3ce5-41aa-ac93-a95b43282b26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create correlation maps\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import product\n",
    "from research.data.kamitani_2019 import fix_stimulus_id\n",
    "import time\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def pearsonr_torch(X, Y):\n",
    "    X = X.to(torch.float64)\n",
    "    Y = Y.to(torch.float64)\n",
    "    \n",
    "    X = X - X.mean(dim=0, keepdim=True)\n",
    "    Y = Y - Y.mean(dim=0, keepdim=True)\n",
    "    \n",
    "    X = X / torch.norm(X, dim=0, keepdim=True)\n",
    "    Y = Y / torch.norm(Y, dim=0, keepdim=True)\n",
    "    \n",
    "    X_num_correlation_dims = len(X.shape) - 1\n",
    "    Y_num_correlation_dims = len(Y.shape) - 1\n",
    "    for i in range(Y_num_correlation_dims):\n",
    "        X = X[..., None]\n",
    "    for i in range(X_num_correlation_dims):\n",
    "        Y = Y[:, None]\n",
    "    \n",
    "    return torch.einsum('b...i,b...i->...i', X, Y)\n",
    "\n",
    "\n",
    "fmri_data = h5py.File(ssd_derivatives_path / 'kamitani2019-cached.hdf5', 'r')\n",
    "\n",
    "cache_name = 'window-0-16'\n",
    "run_features = {\n",
    "    #'bigbigan-resnet50': ['z_mean'],\n",
    "    'ViT-B=32': ['embedding', *(f'transformer.resblocks.{i}' for i in range(12))],\n",
    "    #'biggan-128': ['z', 'y_embedding'],\n",
    "    #'vqgan': ['vqgan-f16-1024-pre_quant'],\n",
    "}\n",
    "\n",
    "def norm(data):\n",
    "    data = torch.norm(data, dim=-1)\n",
    "    return data\n",
    "\n",
    "def mean_top_k(data, k):\n",
    "    data = torch.abs(data)\n",
    "    data = torch.sort(data)[0]\n",
    "    data = data[..., -k:].mean(dim=-1)\n",
    "    return data\n",
    "\n",
    "def max_feature(data):\n",
    "    data = torch.abs(data)\n",
    "    data = torch.max(data, dim=-1)\n",
    "    return data\n",
    "\n",
    "selection_modes = {\n",
    "    #'max': max_feature,\n",
    "    'mean-top-5': partial(mean_top_k, k=5),\n",
    "    'norm': norm,\n",
    "    #'mean-top-10': partial(mean_top_k, k=10),\n",
    "}\n",
    "\n",
    "seed = 0\n",
    "max_features = 512\n",
    "\n",
    "with h5py.File(ssd_derivatives_path / 'feature-selection-maps.hdf5', 'a') as f:\n",
    "    for subject_name, subject in fmri_data.items():\n",
    "        for session_name, session in subject.items():\n",
    "            if cache_name not in session:\n",
    "                continue\n",
    "                print(f'{cache_name} not found for session {session_name}, subject {subject_name}')\n",
    "            cache = session[cache_name]\n",
    "            affine = cache.attrs['affine']\n",
    "            group = f.require_group(f'{subject_name}/{session_name}/{cache_name}')\n",
    "            group.attrs['affine'] = affine\n",
    "            X = cache['data']\n",
    "\n",
    "            for model_name, feature_names in run_features.items():\n",
    "                model_features = h5py.File(derivatives_path / 'features' / f'{model_name}-features.hdf5', 'r')\n",
    "                stimulus_ids = session[f'{cache_name}/stimulus_id'][:]\n",
    "                stimulus_ids = [s.decode('utf-8') for s in stimulus_ids]\n",
    "                stimulus_ids = [fix_stimulus_id(s, model_features.keys()) for s in stimulus_ids]\n",
    "                \n",
    "                features = {}\n",
    "                for feature_name in feature_names:\n",
    "                    print(subject_name, model_name, feature_name)\n",
    "                    Y = np.stack([model_features[f'{stimulus_id}/{feature_name}'][:]\n",
    "                                  for stimulus_id in stimulus_ids])\n",
    "                    Y = torch.from_numpy(Y).cuda()\n",
    "                    Y = Y.flatten(start_dim=1)\n",
    "                    if Y.shape[1] > max_features:\n",
    "                        np.random.seed(seed)\n",
    "                        choice = np.random.choice(max_features, size=max_features)\n",
    "                        Y = Y[:, choice]\n",
    "                    features[feature_name] = Y\n",
    "\n",
    "                load_time = 0\n",
    "                compute_time = 0\n",
    "                store_time = 0\n",
    "                \n",
    "                for i in tqdm(range(X.shape[2])):\n",
    "                    t = time.time()\n",
    "                    X_slice = torch.from_numpy(X[:, :, i]).cuda()\n",
    "                    load_time += time.time() - t\n",
    "                    \n",
    "                    for feature_name in feature_names:\n",
    "                        Y = features[feature_name]\n",
    "                        \n",
    "                        t = time.time()\n",
    "                        r = torch.stack([\n",
    "                            pearsonr_torch(X_slice[:, j], Y)\n",
    "                            for j in range(X_slice.shape[1])\n",
    "                        ])\n",
    "                        compute_time += time.time() - t\n",
    "                        \n",
    "                        for selection_mode, selection_func in selection_modes.items():\n",
    "                            keys = (subject_name, session_name, cache_name, model_name, feature_name, selection_mode, 'scores')\n",
    "                            key = '/'.join(keys)\n",
    "                            selection_map = f.require_dataset(key, X.shape[1:], dtype=np.float32)\n",
    "                            score = selection_func(r)\n",
    "                            t = time.time()\n",
    "                            selection_map[:, i] = score.cpu()\n",
    "                            store_time += time.time() - t\n",
    "\n",
    "                    if i % 25 == 0:\n",
    "                        n = (i + 1)\n",
    "                        print(f'load_time={load_time / n}, compute_time={compute_time / n}, store_time={store_time / n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5741a5-7daf-4b91-bd94-8ed4d23da7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547bd8f3-ee40-4eaf-913c-a72daa5c8a06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save correlation maps\n",
    "from pathlib import Path\n",
    "import torchio as tio\n",
    "from functools import partial\n",
    "import nibabel as nib\n",
    "\n",
    "\n",
    "def mean_top_k(data, k):\n",
    "    data = np.abs(data)\n",
    "    data = np.sort(data)\n",
    "    data = data[:, :, :, -k:].mean(axis=-1)\n",
    "    return data\n",
    "\n",
    "def max_feature(data):\n",
    "    data = np.abs(data)\n",
    "    data = np.max(data, axis=3)\n",
    "    return data\n",
    "\n",
    "selection_modes = {\n",
    "    'max': max_feature,\n",
    "    'mean-top-5': partial(mean_top_k, k=5),\n",
    "    'mean-top-10': partial(mean_top_k, k=10),\n",
    "}\n",
    "models = ['vqgan']\n",
    "\n",
    "out_path = Path('X:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\derivatives\\\\correlation_maps')\n",
    "correlation_maps = h5py.File('X:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\derivatives\\\\feature-correlation-maps.hdf5', 'r')\n",
    "\n",
    "with h5py.File('X:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\derivatives\\\\feature-selection-maps.hdf5', 'a') as f:\n",
    "    for subject_name, subject in correlation_maps.items():\n",
    "        subject_out_path = out_path / subject_name\n",
    "        subject_out_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for session_name, session in subject.items():\n",
    "            for cache_name, cache in session.items():\n",
    "                affine = cache.attrs['affine']\n",
    "                for model_name, model in cache.items():\n",
    "                    if model_name not in models:\n",
    "                        continue\n",
    "\n",
    "                    for feature_name, feature_correlation_map in model.items():\n",
    "                        for selection_mode, selection_func in selection_modes.items():\n",
    "                            keys = (subject_name, session_name, cache_name, model_name, feature_name, selection_mode)\n",
    "                            print(*keys)\n",
    "\n",
    "                            save_file_name = f'{\"__\".join(keys)}.nii.gz'\n",
    "\n",
    "                            data = feature_correlation_map[:]\n",
    "                            data = selection_func(data)\n",
    "                            sorted_indices_flat = np.argsort(data, axis=None)\n",
    "                            \n",
    "                            H, W, D = data.shape\n",
    "                            grid = np.zeros(shape=(4, T, H, W, D), dtype=int)\n",
    "                            grid[0] = np.arange(T)[:, None, None, None]\n",
    "                            grid[1] = np.arange(H)[None, :, None, None]\n",
    "                            grid[2] = np.arange(W)[None, None, :, None]\n",
    "                            grid[3] = np.arange(D)[None, None, None, :]\n",
    "                            grid_flat = grid.reshape(4, T * H * W * D)\n",
    "                            sorted_indices = grid_flat[:, sorted_indices_flat]\n",
    "\n",
    "                            image = nib.Nifti1Image(torch.tensor(data).permute(1, 2, 3, 0).numpy(), affine)\n",
    "                            nib.save(image, subject_out_path / save_file_name)\n",
    "                            \n",
    "                            group = f.require_group('/'.join(keys))\n",
    "                            require_dataset(group, 'scores', data)\n",
    "                            require_dataset(group, 'sorted_indices_flat', sorted_indices_flat)\n",
    "                            require_dataset(group, 'sorted_indices', sorted_indices)\n",
    "\n",
    "correlation_maps.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b03feb10-c9a2-469b-92e7-c5f1f449245b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-01 natural_test window-0-16 ViT-B=32 embedding mean-top-5\n",
      "sub-01 natural_test window-0-16 ViT-B=32 embedding norm\n",
      "sub-01 natural_test window-0-16 ViT-B=32 transformer.resblocks.0 mean-top-5\n",
      "sub-01 natural_test window-0-16 ViT-B=32 transformer.resblocks.0 norm\n",
      "sub-01 natural_test window-0-16 ViT-B=32 transformer.resblocks.1 mean-top-5\n",
      "sub-01 natural_test window-0-16 ViT-B=32 transformer.resblocks.1 norm\n",
      "sub-01 natural_test window-0-16 ViT-B=32 transformer.resblocks.10 mean-top-5\n",
      "sub-01 natural_test window-0-16 ViT-B=32 transformer.resblocks.10 norm\n",
      "sub-01 natural_test window-0-16 ViT-B=32 transformer.resblocks.11 mean-top-5\n",
      "sub-01 natural_test window-0-16 ViT-B=32 transformer.resblocks.11 norm\n",
      "sub-01 natural_test window-0-16 ViT-B=32 transformer.resblocks.2 mean-top-5\n",
      "sub-01 natural_test window-0-16 ViT-B=32 transformer.resblocks.2 norm\n",
      "sub-01 natural_test window-0-16 ViT-B=32 transformer.resblocks.3 mean-top-5\n",
      "sub-01 natural_test window-0-16 ViT-B=32 transformer.resblocks.3 norm\n",
      "sub-01 natural_test window-0-16 ViT-B=32 transformer.resblocks.4 mean-top-5\n",
      "sub-01 natural_test window-0-16 ViT-B=32 transformer.resblocks.4 norm\n",
      "sub-01 natural_test window-0-16 ViT-B=32 transformer.resblocks.5 mean-top-5\n",
      "sub-01 natural_test window-0-16 ViT-B=32 transformer.resblocks.5 norm\n",
      "sub-01 natural_test window-0-16 ViT-B=32 transformer.resblocks.6 mean-top-5\n",
      "sub-01 natural_test window-0-16 ViT-B=32 transformer.resblocks.6 norm\n",
      "sub-01 natural_test window-0-16 ViT-B=32 transformer.resblocks.7 mean-top-5\n",
      "sub-01 natural_test window-0-16 ViT-B=32 transformer.resblocks.7 norm\n",
      "sub-01 natural_test window-0-16 ViT-B=32 transformer.resblocks.8 mean-top-5\n",
      "sub-01 natural_test window-0-16 ViT-B=32 transformer.resblocks.8 norm\n",
      "sub-01 natural_test window-0-16 ViT-B=32 transformer.resblocks.9 mean-top-5\n",
      "sub-01 natural_test window-0-16 ViT-B=32 transformer.resblocks.9 norm\n",
      "sub-01 natural_training window-0-16 ViT-B=32 embedding mean-top-5\n",
      "sub-01 natural_training window-0-16 ViT-B=32 embedding norm\n",
      "sub-01 natural_training window-0-16 ViT-B=32 transformer.resblocks.0 mean-top-5\n",
      "sub-01 natural_training window-0-16 ViT-B=32 transformer.resblocks.0 norm\n",
      "sub-01 natural_training window-0-16 ViT-B=32 transformer.resblocks.1 mean-top-5\n",
      "sub-01 natural_training window-0-16 ViT-B=32 transformer.resblocks.1 norm\n",
      "sub-01 natural_training window-0-16 ViT-B=32 transformer.resblocks.10 mean-top-5\n",
      "sub-01 natural_training window-0-16 ViT-B=32 transformer.resblocks.10 norm\n",
      "sub-01 natural_training window-0-16 ViT-B=32 transformer.resblocks.11 mean-top-5\n",
      "sub-01 natural_training window-0-16 ViT-B=32 transformer.resblocks.11 norm\n",
      "sub-01 natural_training window-0-16 ViT-B=32 transformer.resblocks.2 mean-top-5\n",
      "sub-01 natural_training window-0-16 ViT-B=32 transformer.resblocks.2 norm\n",
      "sub-01 natural_training window-0-16 ViT-B=32 transformer.resblocks.3 mean-top-5\n",
      "sub-01 natural_training window-0-16 ViT-B=32 transformer.resblocks.3 norm\n",
      "sub-01 natural_training window-0-16 ViT-B=32 transformer.resblocks.4 mean-top-5\n",
      "sub-01 natural_training window-0-16 ViT-B=32 transformer.resblocks.4 norm\n",
      "sub-01 natural_training window-0-16 ViT-B=32 transformer.resblocks.5 mean-top-5\n",
      "sub-01 natural_training window-0-16 ViT-B=32 transformer.resblocks.5 norm\n",
      "sub-01 natural_training window-0-16 ViT-B=32 transformer.resblocks.6 mean-top-5\n",
      "sub-01 natural_training window-0-16 ViT-B=32 transformer.resblocks.6 norm\n",
      "sub-01 natural_training window-0-16 ViT-B=32 transformer.resblocks.7 mean-top-5\n",
      "sub-01 natural_training window-0-16 ViT-B=32 transformer.resblocks.7 norm\n",
      "sub-01 natural_training window-0-16 ViT-B=32 transformer.resblocks.8 mean-top-5\n",
      "sub-01 natural_training window-0-16 ViT-B=32 transformer.resblocks.8 norm\n",
      "sub-01 natural_training window-0-16 ViT-B=32 transformer.resblocks.9 mean-top-5\n",
      "sub-01 natural_training window-0-16 ViT-B=32 transformer.resblocks.9 norm\n",
      "sub-02 natural_test window-0-16 ViT-B=32 embedding mean-top-5\n",
      "sub-02 natural_test window-0-16 ViT-B=32 embedding norm\n",
      "sub-02 natural_test window-0-16 ViT-B=32 transformer.resblocks.0 mean-top-5\n",
      "sub-02 natural_test window-0-16 ViT-B=32 transformer.resblocks.0 norm\n",
      "sub-02 natural_test window-0-16 ViT-B=32 transformer.resblocks.1 mean-top-5\n",
      "sub-02 natural_test window-0-16 ViT-B=32 transformer.resblocks.1 norm\n",
      "sub-02 natural_test window-0-16 ViT-B=32 transformer.resblocks.10 mean-top-5\n",
      "sub-02 natural_test window-0-16 ViT-B=32 transformer.resblocks.10 norm\n",
      "sub-02 natural_test window-0-16 ViT-B=32 transformer.resblocks.11 mean-top-5\n",
      "sub-02 natural_test window-0-16 ViT-B=32 transformer.resblocks.11 norm\n",
      "sub-02 natural_test window-0-16 ViT-B=32 transformer.resblocks.2 mean-top-5\n",
      "sub-02 natural_test window-0-16 ViT-B=32 transformer.resblocks.2 norm\n",
      "sub-02 natural_test window-0-16 ViT-B=32 transformer.resblocks.3 mean-top-5\n",
      "sub-02 natural_test window-0-16 ViT-B=32 transformer.resblocks.3 norm\n",
      "sub-02 natural_test window-0-16 ViT-B=32 transformer.resblocks.4 mean-top-5\n",
      "sub-02 natural_test window-0-16 ViT-B=32 transformer.resblocks.4 norm\n",
      "sub-02 natural_test window-0-16 ViT-B=32 transformer.resblocks.5 mean-top-5\n",
      "sub-02 natural_test window-0-16 ViT-B=32 transformer.resblocks.5 norm\n",
      "sub-02 natural_test window-0-16 ViT-B=32 transformer.resblocks.6 mean-top-5\n",
      "sub-02 natural_test window-0-16 ViT-B=32 transformer.resblocks.6 norm\n",
      "sub-02 natural_test window-0-16 ViT-B=32 transformer.resblocks.7 mean-top-5\n",
      "sub-02 natural_test window-0-16 ViT-B=32 transformer.resblocks.7 norm\n",
      "sub-02 natural_test window-0-16 ViT-B=32 transformer.resblocks.8 mean-top-5\n",
      "sub-02 natural_test window-0-16 ViT-B=32 transformer.resblocks.8 norm\n",
      "sub-02 natural_test window-0-16 ViT-B=32 transformer.resblocks.9 mean-top-5\n",
      "sub-02 natural_test window-0-16 ViT-B=32 transformer.resblocks.9 norm\n",
      "sub-02 natural_training window-0-16 ViT-B=32 embedding mean-top-5\n",
      "sub-02 natural_training window-0-16 ViT-B=32 embedding norm\n",
      "sub-02 natural_training window-0-16 ViT-B=32 transformer.resblocks.0 mean-top-5\n",
      "sub-02 natural_training window-0-16 ViT-B=32 transformer.resblocks.0 norm\n",
      "sub-02 natural_training window-0-16 ViT-B=32 transformer.resblocks.1 mean-top-5\n",
      "sub-02 natural_training window-0-16 ViT-B=32 transformer.resblocks.1 norm\n",
      "sub-02 natural_training window-0-16 ViT-B=32 transformer.resblocks.10 mean-top-5\n",
      "sub-02 natural_training window-0-16 ViT-B=32 transformer.resblocks.10 norm\n",
      "sub-02 natural_training window-0-16 ViT-B=32 transformer.resblocks.11 mean-top-5\n",
      "sub-02 natural_training window-0-16 ViT-B=32 transformer.resblocks.11 norm\n",
      "sub-02 natural_training window-0-16 ViT-B=32 transformer.resblocks.2 mean-top-5\n",
      "sub-02 natural_training window-0-16 ViT-B=32 transformer.resblocks.2 norm\n",
      "sub-02 natural_training window-0-16 ViT-B=32 transformer.resblocks.3 mean-top-5\n",
      "sub-02 natural_training window-0-16 ViT-B=32 transformer.resblocks.3 norm\n",
      "sub-02 natural_training window-0-16 ViT-B=32 transformer.resblocks.4 mean-top-5\n",
      "sub-02 natural_training window-0-16 ViT-B=32 transformer.resblocks.4 norm\n",
      "sub-02 natural_training window-0-16 ViT-B=32 transformer.resblocks.5 mean-top-5\n",
      "sub-02 natural_training window-0-16 ViT-B=32 transformer.resblocks.5 norm\n",
      "sub-02 natural_training window-0-16 ViT-B=32 transformer.resblocks.6 mean-top-5\n",
      "sub-02 natural_training window-0-16 ViT-B=32 transformer.resblocks.6 norm\n",
      "sub-02 natural_training window-0-16 ViT-B=32 transformer.resblocks.7 mean-top-5\n",
      "sub-02 natural_training window-0-16 ViT-B=32 transformer.resblocks.7 norm\n",
      "sub-02 natural_training window-0-16 ViT-B=32 transformer.resblocks.8 mean-top-5\n",
      "sub-02 natural_training window-0-16 ViT-B=32 transformer.resblocks.8 norm\n",
      "sub-02 natural_training window-0-16 ViT-B=32 transformer.resblocks.9 mean-top-5\n",
      "sub-02 natural_training window-0-16 ViT-B=32 transformer.resblocks.9 norm\n",
      "sub-03 natural_test window-0-16 ViT-B=32 embedding mean-top-5\n",
      "sub-03 natural_test window-0-16 ViT-B=32 embedding norm\n",
      "sub-03 natural_test window-0-16 ViT-B=32 transformer.resblocks.0 mean-top-5\n",
      "sub-03 natural_test window-0-16 ViT-B=32 transformer.resblocks.0 norm\n",
      "sub-03 natural_test window-0-16 ViT-B=32 transformer.resblocks.1 mean-top-5\n",
      "sub-03 natural_test window-0-16 ViT-B=32 transformer.resblocks.1 norm\n",
      "sub-03 natural_test window-0-16 ViT-B=32 transformer.resblocks.10 mean-top-5\n",
      "sub-03 natural_test window-0-16 ViT-B=32 transformer.resblocks.10 norm\n",
      "sub-03 natural_test window-0-16 ViT-B=32 transformer.resblocks.11 mean-top-5\n",
      "sub-03 natural_test window-0-16 ViT-B=32 transformer.resblocks.11 norm\n",
      "sub-03 natural_test window-0-16 ViT-B=32 transformer.resblocks.2 mean-top-5\n",
      "sub-03 natural_test window-0-16 ViT-B=32 transformer.resblocks.2 norm\n",
      "sub-03 natural_test window-0-16 ViT-B=32 transformer.resblocks.3 mean-top-5\n",
      "sub-03 natural_test window-0-16 ViT-B=32 transformer.resblocks.3 norm\n",
      "sub-03 natural_test window-0-16 ViT-B=32 transformer.resblocks.4 mean-top-5\n",
      "sub-03 natural_test window-0-16 ViT-B=32 transformer.resblocks.4 norm\n",
      "sub-03 natural_test window-0-16 ViT-B=32 transformer.resblocks.5 mean-top-5\n",
      "sub-03 natural_test window-0-16 ViT-B=32 transformer.resblocks.5 norm\n",
      "sub-03 natural_test window-0-16 ViT-B=32 transformer.resblocks.6 mean-top-5\n",
      "sub-03 natural_test window-0-16 ViT-B=32 transformer.resblocks.6 norm\n",
      "sub-03 natural_test window-0-16 ViT-B=32 transformer.resblocks.7 mean-top-5\n",
      "sub-03 natural_test window-0-16 ViT-B=32 transformer.resblocks.7 norm\n",
      "sub-03 natural_test window-0-16 ViT-B=32 transformer.resblocks.8 mean-top-5\n",
      "sub-03 natural_test window-0-16 ViT-B=32 transformer.resblocks.8 norm\n",
      "sub-03 natural_test window-0-16 ViT-B=32 transformer.resblocks.9 mean-top-5\n",
      "sub-03 natural_test window-0-16 ViT-B=32 transformer.resblocks.9 norm\n",
      "sub-03 natural_training window-0-16 ViT-B=32 embedding mean-top-5\n",
      "sub-03 natural_training window-0-16 ViT-B=32 embedding norm\n",
      "sub-03 natural_training window-0-16 ViT-B=32 transformer.resblocks.0 mean-top-5\n",
      "sub-03 natural_training window-0-16 ViT-B=32 transformer.resblocks.0 norm\n",
      "sub-03 natural_training window-0-16 ViT-B=32 transformer.resblocks.1 mean-top-5\n",
      "sub-03 natural_training window-0-16 ViT-B=32 transformer.resblocks.1 norm\n",
      "sub-03 natural_training window-0-16 ViT-B=32 transformer.resblocks.10 mean-top-5\n",
      "sub-03 natural_training window-0-16 ViT-B=32 transformer.resblocks.10 norm\n",
      "sub-03 natural_training window-0-16 ViT-B=32 transformer.resblocks.11 mean-top-5\n",
      "sub-03 natural_training window-0-16 ViT-B=32 transformer.resblocks.11 norm\n",
      "sub-03 natural_training window-0-16 ViT-B=32 transformer.resblocks.2 mean-top-5\n",
      "sub-03 natural_training window-0-16 ViT-B=32 transformer.resblocks.2 norm\n",
      "sub-03 natural_training window-0-16 ViT-B=32 transformer.resblocks.3 mean-top-5\n",
      "sub-03 natural_training window-0-16 ViT-B=32 transformer.resblocks.3 norm\n",
      "sub-03 natural_training window-0-16 ViT-B=32 transformer.resblocks.4 mean-top-5\n",
      "sub-03 natural_training window-0-16 ViT-B=32 transformer.resblocks.4 norm\n",
      "sub-03 natural_training window-0-16 ViT-B=32 transformer.resblocks.5 mean-top-5\n",
      "sub-03 natural_training window-0-16 ViT-B=32 transformer.resblocks.5 norm\n",
      "sub-03 natural_training window-0-16 ViT-B=32 transformer.resblocks.6 mean-top-5\n",
      "sub-03 natural_training window-0-16 ViT-B=32 transformer.resblocks.6 norm\n",
      "sub-03 natural_training window-0-16 ViT-B=32 transformer.resblocks.7 mean-top-5\n",
      "sub-03 natural_training window-0-16 ViT-B=32 transformer.resblocks.7 norm\n",
      "sub-03 natural_training window-0-16 ViT-B=32 transformer.resblocks.8 mean-top-5\n",
      "sub-03 natural_training window-0-16 ViT-B=32 transformer.resblocks.8 norm\n",
      "sub-03 natural_training window-0-16 ViT-B=32 transformer.resblocks.9 mean-top-5\n",
      "sub-03 natural_training window-0-16 ViT-B=32 transformer.resblocks.9 norm\n"
     ]
    }
   ],
   "source": [
    "# Save correlation maps\n",
    "from pathlib import Path\n",
    "import torchio as tio\n",
    "from functools import partial\n",
    "import nibabel as nib\n",
    "\n",
    "cache_name = 'window-0-16'\n",
    "run_features = {\n",
    "    #'bigbigan-resnet50': ['z_mean'],\n",
    "    'ViT-B=32': [*(f'transformer.resblocks.{i}' for i in range(12)), 'embedding'],\n",
    "    #'biggan-128': ['z', 'y_embedding'],\n",
    "    #'vqgan': ['vqgan-f16-1024-pre_quant'],\n",
    "}\n",
    "\n",
    "out_path = derivatives_path / 'correlation_maps'\n",
    "\n",
    "with h5py.File(ssd_derivatives_path / 'feature-selection-maps.hdf5', 'a') as f:\n",
    "    for subject_name, subject in f.items():\n",
    "        subject_out_path = out_path / subject_name\n",
    "        subject_out_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for session_name, session in subject.items():\n",
    "            if cache_name not in session:\n",
    "                continue\n",
    "            cache = session[cache_name]\n",
    "            affine = cache.attrs['affine']\n",
    "            for model_name, model in cache.items():\n",
    "                if model_name not in list(run_features.keys()):\n",
    "                    continue\n",
    "\n",
    "                for feature_name, feature in model.items():\n",
    "                    for selection_mode, selection_map in feature.items():\n",
    "                        keys = (subject_name, session_name, cache_name, model_name, feature_name, selection_mode)\n",
    "                        print(*keys)\n",
    "                        \n",
    "                        save_file_name = f'{\"__\".join(keys)}.nii.gz'\n",
    "\n",
    "                        data = selection_map['scores'][:]\n",
    "                        sorted_indices_flat = np.argsort(data, axis=None)\n",
    "\n",
    "                        T, H, W, D = data.shape\n",
    "                        grid = np.zeros(shape=(4, T, H, W, D), dtype=int)\n",
    "                        grid[0] = np.arange(T)[:, None, None, None]\n",
    "                        grid[1] = np.arange(H)[None, :, None, None]\n",
    "                        grid[2] = np.arange(W)[None, None, :, None]\n",
    "                        grid[3] = np.arange(D)[None, None, None, :]\n",
    "                        grid_flat = grid.reshape(4, T * H * W * D)\n",
    "                        sorted_indices = grid_flat[:, sorted_indices_flat]\n",
    "                        \n",
    "\n",
    "                        image = nib.Nifti1Image(torch.tensor(data).permute(1, 2, 3, 0).numpy(), affine)\n",
    "                        nib.save(image, subject_out_path / save_file_name)\n",
    "\n",
    "                        group = f.require_group('/'.join(keys))\n",
    "                        require_dataset(group, 'scores', data)\n",
    "                        require_dataset(group, 'sorted_indices_flat', sorted_indices_flat)\n",
    "                        require_dataset(group, 'sorted_indices', sorted_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909df512-8ad2-43bc-9899-d867720706dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cache_name = 'window-4-6-8-10'\n",
    "selection_mode = 'mean-top-5'\n",
    "stack_name = 'depth-sequence'\n",
    "times = [4, 6, 8, 10]\n",
    "model_name = 'ViT-B=32'\n",
    "feature_names = [*(f'transformer.resblocks.{i}' for i in range(12)), 'embedding']\n",
    "\n",
    "out_path = derivatives_path / 'correlation_maps'\n",
    "\n",
    "with h5py.File(derivatives_path / 'feature-selection-maps.hdf5', 'r') as f:\n",
    "    for subject_name, subject in f.items():\n",
    "        subject_out_path = out_path / subject_name\n",
    "        subject_out_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for session_name, session in subject.items():\n",
    "            if cache_name not in session:\n",
    "                continue\n",
    "\n",
    "            cache = session[cache_name]\n",
    "            model = cache[model_name]\n",
    "            affine = cache.attrs['affine']\n",
    "            for i, time in enumerate(times):\n",
    "                data = np.stack([\n",
    "                    model[feature_name][selection_mode]['scores'][i]\n",
    "                    for feature_name in feature_names\n",
    "                ])\n",
    "                \n",
    "                keys = (subject_name, session_name, cache_name, model_name, feature_name, selection_mode,\n",
    "                       stack_name, f'time-{time}')\n",
    "                \n",
    "                save_file_name = f'{\"__\".join(keys)}.nii.gz'\n",
    "                \n",
    "                image = nib.Nifti1Image(torch.tensor(data).permute(1, 2, 3, 0).numpy(), affine)\n",
    "                nib.save(image, subject_out_path / save_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d53f2b0-0261-4dca-8cc1-7ce417b7cfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_path = 'X:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\derivatives\\\\feature-correlation-maps.hdf5'\n",
    "new_path = 'X:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\derivatives\\\\feature-correlation-maps-new.hdf5'\n",
    "\n",
    "with h5py.File(old_path, 'r') as old_f:\n",
    "    with h5py.File(new_path, 'a') as new_f:\n",
    "        for subject_name, subject in old_f.items():\n",
    "            for session_name, session in subject.items():\n",
    "                for cache_name, cache in session.items():\n",
    "                    if 'affine' not in cache.attrs:\n",
    "                        continue\n",
    "                    new_f[cache.name].attrs['affine'] = cache.attrs['affine']\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484e9d74-b967-4e12-87ed-d27e189b62d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(data, axis=None)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d730466d-ab90-45d3-a94c-c84a53a65d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "h5_path = Path(\"X:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\\") / \"derivatives\" / \"kamitani2019.hdf5\"\n",
    "\n",
    "stimulus_id_map_path = Path(\"X:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\\") / \"derivatives\" / 'kamitani-preprocessed' / 'stimulus_NaturalImageTest.tsv'\n",
    "\n",
    "stimulus_id_map = pd.read_csv(stimulus_id_map_path, \n",
    "                              sep='\\t', \n",
    "                              names=['_1', 'stimulus_id', 'index', '_2'], \n",
    "                              dtype={'stimulus_id': str, 'index': int})\n",
    "\n",
    "stimulus_ids = list(stimulus_id_map['stimulus_id'])\n",
    "ids = list(stimulus_id_map['index'])\n",
    "\n",
    "with h5py.File(h5_path, 'a') as f:\n",
    "    del f.attrs['test_stimulus_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571bb857-7a00-4ecf-97c7-cb6176152da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached = h5py.File(derivatives_path / 'kamitani2019-cached.hdf5', 'r')\n",
    "    \n",
    "with h5py.File(derivatives_path / 'kamitani2019-cached-new.hdf5', 'a') as cached_new:\n",
    "    \n",
    "    def copy_data(k, v):\n",
    "        #print(k, v)\n",
    "        if isinstance(v, h5py.Group):\n",
    "            new_v = cached_new.require_group(k)\n",
    "            for attr_name, attr in v.attrs.items():\n",
    "                new_v.attrs[attr_name] = attr\n",
    "    \n",
    "        if isinstance(v, h5py.Dataset):\n",
    "            print(v.name, v.shape, v.dtype)\n",
    "            if v.name.endswith('data'):\n",
    "                shape = v.shape\n",
    "                N = v.shape[0]\n",
    "                H, W, D = v.shape[-3:]\n",
    "                \n",
    "                new_v = cached_new.require_dataset(k, shape=(N, 1, H, W, D), dtype='float32')\n",
    "                for i in tqdm(range(N)):\n",
    "                    data = v[i]\n",
    "                    if len(data.shape) == 4:\n",
    "                        data = data[0]\n",
    "                    new_v[i, 0] = data\n",
    "                    \n",
    "            else:\n",
    "                require_dataset(cached_new, k, v[:])\n",
    "    \n",
    "    cached.visititems(copy_data)\n",
    "    \n",
    "cached.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14735c0-d363-4a98-9cbe-b7da2d359255",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(stimulus_id, dtype=np.dtype('S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bfd601-a08a-4f75-a71a-43ab8891aa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('X:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\derivatives\\\\kamitani2019-cached.hdf5', 'a') as f:\n",
    "    group = f[f'{subject}/{session}/{cache_name}']\n",
    "    print(group)\n",
    "    group.require_dataset("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6230d78c-b742-48f7-8a89-edafbb75c17e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "with h5py.File('X:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\derivatives\\\\kamitani2019.hdf5', 'a') as f:\n",
    "    f.visit(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2348a91e-1382-468a-b4a0-a62d055f3288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "with h5py.File('X:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\derivatives\\\\kamitani2019.hdf5', 'a') as f:\n",
    "    for subject in f.values():\n",
    "        print(subject)\n",
    "        for session_name, session in subject.items():\n",
    "            if session_name =='anatomy':\n",
    "                continue\n",
    "            \n",
    "            run_names = session.keys()\n",
    "            session.create_group('runs')\n",
    "            \n",
    "            for run_name in run_names:\n",
    "                session.move(run_name, f'runs/{run_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94400b03-d2a7-43de-bd06-a6ea6d37c76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean and SD across volume and voxels\n",
    "\n",
    "import h5py\n",
    "\n",
    "break\n",
    "with h5py.File('X:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\derivatives\\\\kamitani2019.hdf5', 'a') as f:\n",
    "    for subject in f.values():\n",
    "        print(subject)\n",
    "        for session_name, session in subject.items():\n",
    "            if session_name =='anatomy':\n",
    "                continue\n",
    "\n",
    "            for run in session.values():\n",
    "                data = run['data'][:]\n",
    "                \n",
    "                H, W, D, T = data.shape\n",
    "                \n",
    "                data = torch.from_numpy(data).cuda()\n",
    "                \n",
    "                voxel_mean = data.mean(dim=3).cpu().numpy()\n",
    "                voxel_std = data.std(dim=3).cpu().numpy()\n",
    "                \n",
    "                volume_mean = data.mean(dim=(0, 1, 2)).cpu().numpy()\n",
    "                volume_std = data.mean(dim=(0, 1, 2)).cpu().numpy()\n",
    "                \n",
    "                run_mean = data.mean().cpu().item()\n",
    "                run_std = data.std().cpu().item()\n",
    "                \n",
    "                require_dataset(run, 'voxel_mean', voxel_mean)\n",
    "                require_dataset(run, 'voxel_std', voxel_std)\n",
    "                require_dataset(run, 'volume_mean', volume_mean)\n",
    "                require_dataset(run, 'volume_std', volume_std)\n",
    "                \n",
    "                run.attrs['run_mean'] = run_mean\n",
    "                run.attrs['run_std'] = run_std\n",
    "                \n",
    "                print(run)\n",
    "                \n",
    "                #break\n",
    "            #break\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4c9534-6826-4436-81c8-df3b80d70f61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute linear trends across voxels\n",
    "\n",
    "with h5py.File('X:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\derivatives\\\\kamitani2019.hdf5', 'a') as f:\n",
    "    for subject in f.values():\n",
    "        print(subject)\n",
    "        for session_name, session in subject.items():\n",
    "            if session_name =='anatomy':\n",
    "                continue\n",
    "\n",
    "            for run in session.values():\n",
    "                print(run)\n",
    "                \n",
    "                data = torch.from_numpy(run['data'][:]).cuda()\n",
    "                voxel_mean = torch.from_numpy(run['voxel_mean'][:]).cuda()\n",
    "                Y = data[..., None]\n",
    "\n",
    "                W, H, D, T = data.shape\n",
    "\n",
    "                X = torch.zeros_like(data)\n",
    "                X[:, :, :, torch.arange(T)] = torch.arange(T).float().cuda()\n",
    "                X = torch.stack([X, torch.ones_like(X)], dim=-1)\n",
    "\n",
    "                solution, residuals, rank, singular_values = torch.linalg.lstsq(X, Y)\n",
    "                solution = solution.squeeze().cpu().numpy()\n",
    "                residuals = residuals.squeeze().cpu().numpy()\n",
    "                \n",
    "                slope = solution[..., 0]\n",
    "                intercept = solution[..., 1]\n",
    "                \n",
    "                require_dataset(run, 'voxel_linear_trend_slope', slope)\n",
    "                require_dataset(run, 'voxel_linear_trend_intercept', intercept)\n",
    "                require_dataset(run, 'voxel_linear_trend_residual', residuals)\n",
    "                \n",
    "                #break\n",
    "            #break\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565cb620-7c62-49cc-ac24-007971050a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute linear trends across voxels\n",
    "\n",
    "with h5py.File('X:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\derivatives\\\\kamitani2019.hdf5', 'a') as f:\n",
    "    for subject in f.values():\n",
    "        print(subject)\n",
    "        for session_name, session in subject.items():\n",
    "            if session_name =='anatomy':\n",
    "                continue\n",
    "\n",
    "            for run in session.values():\n",
    "                print(run)\n",
    "                \n",
    "                data = torch.from_numpy(run['data'][:]).cuda()\n",
    "                voxel_mean = torch.from_numpy(run['voxel_mean'][:]).cuda()\n",
    "                Y = data[..., None]\n",
    "\n",
    "                W, H, D, T = data.shape\n",
    "\n",
    "                X = torch.zeros_like(data)\n",
    "                X[:, :, :, torch.arange(T)] = torch.arange(T).float().cuda()\n",
    "                X = torch.stack([X, torch.ones_like(X)], dim=-1)\n",
    "                \n",
    "                slope = torch.from_numpy(run['voxel_linear_trend_slope'][:]).cuda()\n",
    "                intercept = torch.from_numpy(run['voxel_linear_trend_intercept'][:]).cuda()\n",
    "                solution = torch.stack([slope, intercept], dim=-1)[..., None]\n",
    "                residual = (X @ solution - Y)\n",
    "                std = residual.std(dim=3).squeeze().cpu().numpy()\n",
    "                #print(std.shape)\n",
    "                \n",
    "                #break\n",
    "                \n",
    "                #require_dataset(run, 'voxel_linear_trend_slope', slope)\n",
    "                #require_dataset(run, 'voxel_linear_trend_intercept', intercept)\n",
    "                require_dataset(run, 'voxel_linear_trend_std', std)\n",
    "                \n",
    "                #break\n",
    "            #break\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a042f53e-9bde-46d2-819e-1fea57724eb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "with h5py.File('X:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\derivatives\\\\kamitani2019.hdf5', 'a') as f:\n",
    "    for subject in f.values():\n",
    "        print(subject)\n",
    "        for session_name, session in subject.items():\n",
    "            if session_name == 'anatomy':\n",
    "                continue\n",
    "\n",
    "            for run in session.values():\n",
    "                print(run)\n",
    "                \n",
    "                volume_mean = run['volume_mean'][:]\n",
    "                T = volume_mean.shape[0]\n",
    "                Y = torch.from_numpy(volume_mean[:, None])\n",
    "                X = torch.arange(T).float()\n",
    "                X = torch.stack([X, torch.ones_like(X)], dim=-1)\n",
    "                \n",
    "                solution, residuals, rank, singular_values = torch.linalg.lstsq(X, Y)\n",
    "                solution = solution.squeeze().cpu().numpy()\n",
    "                residuals = residuals.squeeze().cpu().numpy()\n",
    "                \n",
    "                std = (X @ solution - Y).std()\n",
    "                \n",
    "                slope = solution[..., 0]\n",
    "                intercept = solution[..., 1]\n",
    "                \n",
    "                require_dataset(run, 'volume_linear_trend_slope', np.array([slope]))\n",
    "                require_dataset(run, 'volume_linear_trend_intercept', np.array([intercept]))\n",
    "                require_dataset(run, 'volume_linear_trend_std', np.array([std]))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc86cd2-cce2-4f10-b659-179d79dffc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix computation of std for volume linear trend removal\n",
    "import h5py\n",
    "\n",
    "with h5py.File('X:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\derivatives\\\\kamitani2019.hdf5', 'a') as f:\n",
    "    for subject in f.values():\n",
    "        print(subject)\n",
    "        for session_name, session in subject.items():\n",
    "            if session_name == 'anatomy':\n",
    "                continue\n",
    "\n",
    "            for run in session.values():\n",
    "                print(run)\n",
    "                \n",
    "                data = torch.from_numpy(run['data'][:]).cuda()\n",
    "                T = data.shape[3]\n",
    "                intercept = torch.from_numpy(run['volume_linear_trend_intercept'][:])\n",
    "                slope = torch.from_numpy(run['volume_linear_trend_slope'][:])\n",
    "                old_std = torch.from_numpy(run['volume_linear_trend_std'][:])[None, None, None, :]\n",
    "\n",
    "                X = torch.cat([slope, intercept])\n",
    "                t = torch.arange(T)\n",
    "                A = torch.stack([t, torch.ones_like(t)], dim=-1).float()\n",
    "                mean = (A @ X)[None, None, None, :]\n",
    "                std = (data - mean.cuda()).std().item()\n",
    "                print(std, old_std.squeeze())\n",
    "                \n",
    "                del run['volume_linear_trend_std']\n",
    "                require_dataset(run, 'volume_linear_trend_std', np.array([std]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
