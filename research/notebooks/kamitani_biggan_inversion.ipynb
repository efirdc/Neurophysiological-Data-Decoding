{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c856b684-b56d-486e-9ed2-3506b7d43a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchio as tio\n",
    "import h5py\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dir2 = os.path.abspath('..')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: \n",
    "    sys.path.append(dir1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e10753e2-767f-487c-b632-25f29f36231a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# classify stimulus images with a imagenet model\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "\n",
    "root = 'X:\\\\Datasets\\\\Deep-Image-Reconstruction'\n",
    "stimulus_images = h5py.File(Path(root) / \"derivatives\" / \"stimulus_images.hdf5\", \"r\")\n",
    "\n",
    "model = models.resnet152(pretrained=True)\n",
    "model.eval()\n",
    "model.cuda()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a322c52f-52f7-4e18-a8e5-028e3045fa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize(224),\n",
    "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "y_pred = []\n",
    "for stimulus_id in stimulus_images.keys():\n",
    "    x = stimulus_images[stimulus_id]['data'][:]\n",
    "    x = torch.from_numpy(x).float() / 255\n",
    "    x = x.permute(2, 0, 1)\n",
    "    x = transform(x)\n",
    "    x = x.cuda()[None]\n",
    "    with torch.no_grad():\n",
    "        y = model(x)\n",
    "    y_pred.append(y)\n",
    "y_pred = torch.cat(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cd95208-da0b-4a61-80bf-4bc17493f033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get wordnet averages\n",
    "\n",
    "averages = {}\n",
    "for i, stimulus_id in enumerate(stimulus_images.keys()):\n",
    "    y = y_pred[i]\n",
    "    if '.' in stimulus_id:\n",
    "        wordnet_id = stimulus_id.split('.')[0]\n",
    "        if wordnet_id not in averages:\n",
    "            averages[wordnet_id] = [y]\n",
    "        else:\n",
    "            averages[wordnet_id].append(y)\n",
    "    else:\n",
    "        averages[stimulus_id] = [y]\n",
    "\n",
    "averages = {k: torch.stack(v).mean(axis=0) for k, v in averages.items()}\n",
    "\n",
    "y_pred_averaged = []\n",
    "for stimulus_id in stimulus_images.keys():\n",
    "    if '.' in stimulus_id:\n",
    "        wordnet_id = stimulus_id.split('.')[0]\n",
    "        y_pred_averaged.append(averages[wordnet_id])\n",
    "    else:\n",
    "        y_pred_averaged.append(averages[stimulus_id])\n",
    "y_pred_averaged = torch.stack(y_pred_averaged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9862147-0b9c-487d-ba62-1110ff63171a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "131707095998445db7d8a83bf6d1aa32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=649, description='i', max=1299), Checkbox(value=False, description='averâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at results\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from research.imagenet_classes import imagenet_classes\n",
    "\n",
    "@interact(i=(0, 1299), average=False)\n",
    "def compare(i, average):\n",
    "    stimulus_id = list(stimulus_images.keys())[i]\n",
    "    x = stimulus_images[stimulus_id]['data'][:]\n",
    "    y = y_pred_averaged if average else y_pred\n",
    "    y = F.softmax(y, dim=1)\n",
    "    y = y[i]\n",
    "    plt.imshow(x)\n",
    "    \n",
    "    top_5 = [i.item() for i in list(y.argsort()[-5:].cpu())]\n",
    "    top_5.reverse()\n",
    "    results = {imagenet_classes[i]: y[i].cpu().item() for i in top_5}\n",
    "    results = {k.split(',')[0]: round(v, 3) for k, v in results.items()}\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83f703e2-ee5e-48df-af02-7cd41b48de19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make x_train for inversion dataset\n",
    "\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "from scipy import ndimage\n",
    "from PIL import Image\n",
    "\n",
    "root = 'X:\\\\Datasets\\\\Deep-Image-Reconstruction'\n",
    "stimulus_images = h5py.File(Path(root) / \"derivatives\" / \"stimulus_images.hdf5\", \"r\")\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize(224),\n",
    "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "xtrain = []\n",
    "for stimulus_id in stimulus_images.keys():\n",
    "    x = stimulus_images[stimulus_id]['data'][:]\n",
    "    x = T.ToPILImage()(x)\n",
    "    x = T.Resize(256)(x)\n",
    "    xtrain.append(np.array(x))\n",
    "xtrain = np.stack(xtrain)\n",
    "xtrain = torch.from_numpy(xtrain)\n",
    "xtrain = xtrain.permute(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2f00799-785a-4ff0-94e3-6db0630a0a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_averaged.mean(dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a80ffad-8117-4a83-9810-9706534962ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import h5py\n",
    "\n",
    "out_dir = Path('G:\\\\Github Repositories\\\\exploiting-gan-internal-capacity\\\\inverses')\n",
    "\n",
    "with h5py.File(out_dir / 'kamitani_stimulus256.hdf5', 'w') as f:\n",
    "    ytrain = F.softmax(y_pred_averaged, dim=1)\n",
    "    f.create_dataset('xtrain', data=xtrain)\n",
    "    f.create_dataset('ytrain', data=ytrain.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac539d03-20f9-42d7-9b90-3823dec118ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_averaged.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Neurophysiological-Data-Decoding",
   "language": "python",
   "name": "neurophysiological-data-decoding"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
