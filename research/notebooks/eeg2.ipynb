{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hairy-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "\n",
    "dir2 = os.path.abspath('..')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: \n",
    "    sys.path.append(dir1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dimensional-carpet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from X:\\Datasets\\EEG\\Things-EEG1\\sub-34\\data\\sub-34\\eeg\\sub-34_task-rsvp_eeg.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 3576359  =      0.000 ...  3576.359 secs...\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 6601 samples (6.601 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.1 - 1e+02 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.10\n",
      "- Lower transition bandwidth: 0.10 Hz (-6 dB cutoff frequency: 0.05 Hz)\n",
      "- Upper passband edge: 100.00 Hz\n",
      "- Upper transition bandwidth: 25.00 Hz (-6 dB cutoff frequency: 112.50 Hz)\n",
      "- Filter length: 33001 samples (33.001 sec)\n",
      "\n",
      "Used Annotations descriptions: ['Event/E  1']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "24648 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "from research.data import *\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "things_dataset = ThingsDataset(\n",
    "    root=\"X:\\\\Datasets\\\\EEG\\\\Things-concepts-and-images\\\\\",\n",
    "    transform=transform,\n",
    "    supplementary_path=\"X:\\\\Datasets\\\\EEG\\\\Things-supplementary\\\\\",\n",
    "    latent_name=\"bigbigan-resnet50\",\n",
    ")\n",
    "\n",
    "things_eeg_dataset = ThingsEEG(\n",
    "    things_dataset, \n",
    "    things_eeg_path=\"X:\\\\Datasets\\\\EEG\\\\Things-EEG1\\\\\",\n",
    "    #source=\"eeglab\",\n",
    "    window=(-0.1, 0.2),\n",
    "    #stimulus_window = (-10, 1),\n",
    "    include_participants=['sub-34'],\n",
    "    folds=(0,1,2,3,4,\"test\"),\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-prevention",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import Random\n",
    "from pipeline.compact_json_encoder import CompactJSONEncoder\n",
    "\n",
    "folds = {}\n",
    "participant_ids = list(things_eeg_dataset.participant_data['participant_id'])\n",
    "for i, participant_id in enumerate(participant_ids):\n",
    "    block_ids = list(range(12))\n",
    "    Random(i).shuffle(block_ids)\n",
    "    grouped_ids = zip(block_ids[:6], block_ids[6:])\n",
    "    folds[participant_id] = dict(zip(['0', '1', '2', '3', '4', 'test'], grouped_ids))\n",
    "\n",
    "out_path = \"X:\\\\Datasets\\\\EEG\\\\Things-supplementary\\\\eeg-split.json\"\n",
    "json_encoder = CompactJSONEncoder(indent=2)\n",
    "with Path(out_path).open(mode=\"w\") as f:\n",
    "    out_str = json_encoder.encode(folds)\n",
    "    f.write(out_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "genuine-result",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a8f8eb5ea14390b9671b92e5e5e99b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='participant_id', options=('sub-34',), value='sub-34'), Output()), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "@interact(participant_id=list(things_eeg_dataset.participants.keys()))\n",
    "def show(participant_id):\n",
    "    participant = things_eeg_dataset.participants[participant_id]\n",
    "    raw = participant['raw']\n",
    "\n",
    "    @interact(event_id=(0, len(participant['rsvp_events']) - 1))\n",
    "    def get_event(event_id):\n",
    "        epochs = participant['epochs']\n",
    "        event = participant['rsvp_events'].loc[event_id]\n",
    "        print(event)\n",
    "        #image = things_dataset[str(event['image_name'])]\n",
    "        #print(image['unique_image_name'])\n",
    "        epoch = epochs[event_id]\n",
    "        epoch.plot(n_channels=128)\n",
    "        \n",
    "    #raw.plot_psd(fmax=50)\n",
    "    #raw.plot(start=5, duration=1, n_channels=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dress-denial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-34\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(24648, 120)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "participant = list(things_eeg_dataset.participants.values())[0]\n",
    "print(participant['participant_id'])\n",
    "raw = participant['raw']\n",
    "epochs = participant['epochs']\n",
    "data = np.stack([epoch[:, :].astype(np.float32) for epoch in epochs])\n",
    "\n",
    "latents = np.stack([\n",
    "    things_dataset.images_map[image_name]['latents']['z_mean']\n",
    "    for image_name in participant['rsvp_events']['image_name']\n",
    "])\n",
    "latents.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-separate",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caroline-liverpool",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, C, T = data.shape\n",
    "X = data[:, :,]\n",
    "X = data.reshape(N, C * T)\n",
    "y = latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "widespread-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_indices, test_indices = train_test_split(np.arange(N), train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "southeast-politics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24648, 18900)\n",
      "0.6132345792143935 -2.2315217244778225\n",
      "Dropped 0 epochs: \n",
      "Channels marked as bad: none\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "print(X.shape)\n",
    "model = LinearRegression()\n",
    "#model = Ridge(alpha=1e-8)\n",
    "#model = MultiOutputRegressor(LinearSVR())\n",
    "#model = MLPRegressor(hidden_layer_sizes=(240,), verbose=True, learning_rate_init=1,)\n",
    "#model = MultiOutputRegressor(AdaBoostRegressor())\n",
    "#model = MultiOutputRegressor(SVR())\n",
    "\n",
    "model.fit(X[train_indices], y[train_indices])\n",
    "print(model.score(X[train_indices], y[train_indices]), model.score(X[test_indices], y[test_indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-single",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "distinct-personal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Cefir\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "import sys\n",
    "import IPython.display\n",
    "import PIL.Image\n",
    "from pprint import pformat\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "dir2 = os.path.abspath('..')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: \n",
    "    sys.path.append(dir1)\n",
    "    \n",
    "from research.scripts.bigbigan import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "constant-environment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signature: generate\n",
      "Inputs: {'z': <hub.ParsedTensorInfo shape=(?, 120) dtype=float32 is_sparse=False>}\n",
      "Outputs: {'default': <hub.ParsedTensorInfo shape=(?, 128, 128, 3) dtype=float32 is_sparse=False>,\n",
      " 'upsampled': <hub.ParsedTensorInfo shape=(?, 256, 256, 3) dtype=float32 is_sparse=False>}\n",
      "\n",
      "Signature: default\n",
      "Inputs: {'x': <hub.ParsedTensorInfo shape=(?, 256, 256, 3) dtype=float32 is_sparse=False>}\n",
      "Outputs: {'default': <hub.ParsedTensorInfo shape=(?, 120) dtype=float32 is_sparse=False>}\n",
      "\n",
      "Signature: encode\n",
      "Inputs: {'x': <hub.ParsedTensorInfo shape=(?, 256, 256, 3) dtype=float32 is_sparse=False>}\n",
      "Outputs: {'avepool_feat': <hub.ParsedTensorInfo shape=(?, 2048) dtype=float32 is_sparse=False>,\n",
      " 'bn_crelu_feat': <hub.ParsedTensorInfo shape=(?, 4096) dtype=float32 is_sparse=False>,\n",
      " 'default': <hub.ParsedTensorInfo shape=(?, 120) dtype=float32 is_sparse=False>,\n",
      " 'z_mean': <hub.ParsedTensorInfo shape=(?, 120) dtype=float32 is_sparse=False>,\n",
      " 'z_sample': <hub.ParsedTensorInfo shape=(?, 120) dtype=float32 is_sparse=False>,\n",
      " 'z_stdev': <hub.ParsedTensorInfo shape=(?, 120) dtype=float32 is_sparse=False>}\n",
      "\n",
      "Signature: discriminate\n",
      "Inputs: {'x': <hub.ParsedTensorInfo shape=(?, 128, 128, 3) dtype=float32 is_sparse=False>,\n",
      " 'z': <hub.ParsedTensorInfo shape=(?, 120) dtype=float32 is_sparse=False>}\n",
      "Outputs: {'score_x': <hub.ParsedTensorInfo shape=(?,) dtype=float32 is_sparse=False>,\n",
      " 'score_xz': <hub.ParsedTensorInfo shape=(?,) dtype=float32 is_sparse=False>,\n",
      " 'score_z': <hub.ParsedTensorInfo shape=(?,) dtype=float32 is_sparse=False>}\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "module_path = 'https://tfhub.dev/deepmind/bigbigan-resnet50/1'  # ResNet-50\n",
    "module = hub.Module(module_path)\n",
    "\n",
    "for signature in module.get_signature_names():\n",
    "    print('Signature:', signature)\n",
    "    print('Inputs:', pformat(module.get_input_info_dict(signature)))\n",
    "    print('Outputs:', pformat(module.get_output_info_dict(signature)))\n",
    "    print()\n",
    "    \n",
    "bigbigan = BigBiGAN(module)\n",
    "\n",
    "enc_ph = bigbigan.make_encoder_ph()\n",
    "gen_ph = bigbigan.make_generator_ph()\n",
    "gen_samples = bigbigan.generate(gen_ph, upsample=True)\n",
    "recon_x = bigbigan.reconstruct_x(enc_ph, upsample=True)\n",
    "enc_features = bigbigan.encode(enc_ph, return_all_features=True)\n",
    "disc_scores_enc = bigbigan.discriminate(*bigbigan.enc_pairs_for_disc(enc_ph))\n",
    "disc_scores_gen = bigbigan.discriminate(*bigbigan.gen_pairs_for_disc(gen_ph))\n",
    "losses = bigbigan.losses(enc_ph, gen_ph)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "wireless-spanking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ea8032a9bf64e3e8a0efa1c117767ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=10, description='batch_id', max=20), Output()), _dom_classes=('widget-in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(batch_id=(0, 20))\n",
    "def show(batch_id):\n",
    "    sample_ids = train_indices[batch_id * 16:(batch_id + 1) * 16]\n",
    "\n",
    "    feed_dict = {gen_ph: y[sample_ids]}\n",
    "    encoded_images = sess.run(gen_samples, feed_dict=feed_dict)\n",
    "\n",
    "    feed_dict = {gen_ph: model.predict(X[sample_ids])}\n",
    "    reconstructed_images = sess.run(gen_samples, feed_dict=feed_dict)\n",
    "\n",
    "    image_names = participant['rsvp_events'].loc[sample_ids]['image_name']\n",
    "    print(list(image_names))\n",
    "    stimulus_images = np.stack([\n",
    "        things_dataset[image_name]['data']\n",
    "        for image_name in image_names\n",
    "    ])\n",
    "    stimulus_images = np.moveaxis(stimulus_images, 1, -1) * 2 - 1\n",
    "    images = interleave(stimulus_images, encoded_images, reconstructed_images)\n",
    "    imshow(imgrid(image_to_uint8(images), cols=6))\n",
    "    #imshow(imgrid(image_to_uint8(target_images), cols=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-bubble",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(imgrid(image_to_uint8(np.moveaxis(images, 1, -1) * 2 - 1), cols=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
