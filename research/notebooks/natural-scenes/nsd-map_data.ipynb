{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa0b506e-eaaf-472a-8ed0-a8de8c35dcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import gc\n",
    "from typing import Tuple, Optional, Dict\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import h5py\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import nibabel as nib\n",
    "from einops import rearrange\n",
    "from scipy import ndimage\n",
    "from nsdcode.nsd_mapdata import NSDmapdata\n",
    "\n",
    "dir2 = os.path.abspath('../..')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: \n",
    "    sys.path.append(dir1)\n",
    "\n",
    "from research.data.natural_scenes import (\n",
    "    NaturalScenesDataset,\n",
    "    StimulusDataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6fe5fae-b759-480a-bfbe-30523450ba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsd_path = Path('D:\\\\Datasets\\\\NSD\\\\')\n",
    "nsd = NaturalScenesDataset(nsd_path)\n",
    "nsd_mapdata = NSDmapdata(nsd_path)\n",
    "freesurfer_path = nsd_path / 'nsddata/freesurfer'\n",
    "derivatives_path = nsd_path / 'derivatives'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "082598d8-eb5f-4b23-8a19-5dfcc22ac69d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aparc\n",
      "lh\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "830af10e64a14d1a80cf5b200ce6da32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rh\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c62a5f11aa4384b35b210764a92836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combine\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e2ac2d8ed441b596bc741a79dfff23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aparc.a2009s\n",
      "lh\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f728a4cfe414a2bbdeb00a2faccc9e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rh\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf562495e594c4f9022001cf5824280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combine\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f02ea5582274f25ae6eb89dd6d0bd72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aparc.DKTatlas\n",
      "lh\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b450e4d51e4dfba88fecedbe117bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rh\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe36bf1a6c24f758eac624e1326326c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combine\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b6d0d819b924500bc9b349a63a3cbce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Map cortical parcellations to volume spaces\n",
    "# Note: Had to make a slight change to nsdcode mapsurfacetovolume.py line 125:\n",
    "# for i, c_label in enumerate(all_labels):\n",
    "#     data_new[i, :] = data[data_q, :] == c_label\n",
    "\n",
    "annot_files = ['aparc', 'aparc.a2009s', 'aparc.DKTatlas']\n",
    "hemispheres = ['lh', 'rh', 'combine']\n",
    "\n",
    "for annot_file in annot_files:\n",
    "    print(annot_file)\n",
    "    \n",
    "    for hemi in hemispheres:\n",
    "        print(hemi)\n",
    "        \n",
    "        for i in tqdm(range(1, 9)):\n",
    "            subject_name = f'subj0{i}'\n",
    "            label_path = freesurfer_path / subject_name / 'label'\n",
    "            \n",
    "            def load_hemi(hemi):\n",
    "                hemi_path = label_path / f'{hemi}.{annot_file}.annot'\n",
    "                hemi_data, hemi_ctab, hemi_names = fio.read_annot(hemi_path)\n",
    "                hemi_data = hemi_data[:, None]\n",
    "                hemi_source_data = [hemi_data] * 3\n",
    "                hemi_source_space = [f'{hemi}.layerB1', f'{hemi}.layerB2', f'{hemi}.layerB3']\n",
    "                return hemi_source_data, hemi_source_space, hemi_ctab, hemi_names\n",
    "            \n",
    "            if hemi == 'combine':\n",
    "                file_name = f'{annot_file}.nii.gz'\n",
    "                lh_source_data, lh_source_space, lh_ctab, lh_names = load_hemi('lh')\n",
    "                rh_source_data, rh_source_space, rh_ctab, rh_names = load_hemi('rh')\n",
    "                source_data = lh_source_data + rh_source_data\n",
    "                source_space = lh_source_space + rh_source_space\n",
    "                ctab = lh_ctab \n",
    "                names = lh_names\n",
    "                ctab_file_name = f'{annot_file}.ctab'\n",
    "            else:\n",
    "                file_name = f'{hemi}.{annot_file}.nii.gz'\n",
    "                source_data, source_space, ctab, names = load_hemi(hemi)\n",
    "                ctab_file_name = f'{hemi}.{annot_file}.ctab'\n",
    "                \n",
    "            ctab_path = derivatives_path / 'labels' / subject_name\n",
    "            ctab_path.mkdir(exist_ok=True, parents=True)\n",
    "            with open(ctab_path / ctab_file_name, 'w') as f:\n",
    "                for j, name in enumerate(names):\n",
    "                    f.write(f'{j} {name.decode(\"utf-8\")}\\n')\n",
    "\n",
    "            target_space = 'anat0pt8'\n",
    "            output_path = derivatives_path / 'images' / subject_name / 'anat0pt8mm'\n",
    "            output_path.mkdir(exist_ok=True, parents=True)\n",
    "            output_file = output_path / file_name\n",
    "            nsd_mapdata.fit(\n",
    "                i, \n",
    "                source_space, \n",
    "                target_space, \n",
    "                source_data, \n",
    "                interptype='surfacewta', \n",
    "                badval=-1, \n",
    "                outputfile=output_file\n",
    "            )\n",
    "\n",
    "            source_data = str(output_file)\n",
    "            for target_space, space_name in [('func1pt8', 'func1pt8mm'), ('func1pt0', 'func1mm')]:\n",
    "                source_space = 'anat0pt8'\n",
    "                output_path = derivatives_path / 'images' / subject_name / space_name\n",
    "                output_path.mkdir(exist_ok=True, parents=True)\n",
    "                output_file = output_path / file_name\n",
    "                nsd_mapdata.fit(\n",
    "                    i,\n",
    "                    source_space,\n",
    "                    target_space,\n",
    "                    source_data,\n",
    "                    interptype='wta',\n",
    "                    badval=-1,\n",
    "                    outputfile=output_file\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ba3a7d9b-3be4-4d1a-8697-76546482f367",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d81b9801d944609bbbf00ce1d0d17a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n",
      "data array passed\n"
     ]
    }
   ],
   "source": [
    "# map HCP MNI cortical atlas to subject spaces\n",
    "\n",
    "hcp_path = derivatives_path / 'HCP-MMP1'\n",
    "hcp_cortices_file_path = hcp_path / 'HCP-MMP1_cortices' / 'HCP-MMP1_cortices_1mm.nii.gz'\n",
    "hcp_cortices_data = np.rint(nib.load(hcp_cortices_file_path).get_fdata()).astype(int)\n",
    "\n",
    "hcp_cortices_merged = hcp_cortices_data.copy()\n",
    "hcp_cortices_merged[hcp_cortices_merged >= 100] -= 100\n",
    "\n",
    "hcp_cortices_lh = hcp_cortices_data.copy()\n",
    "hcp_cortices_lh[hcp_cortices_lh >= 100] = 0\n",
    "\n",
    "hcp_cortices_rh = hcp_cortices_data.copy()\n",
    "hcp_cortices_rh[hcp_cortices_rh <= 100] = 0\n",
    "hcp_cortices_rh[hcp_cortices_rh >= 100] -= 100\n",
    "\n",
    "target_spaces = [\n",
    "    ('func1pt8', 'func1pt8mm'), \n",
    "    ('func1pt0', 'func1mm'), \n",
    "    ('anat0pt8', 'anat0pt8mm')\n",
    "]\n",
    "source_space = 'MNI'\n",
    "source_datas = [\n",
    "    (hcp_cortices_merged, 'HCP_MMP1_cortices.nii.gz'),\n",
    "    (hcp_cortices_lh, 'lh.HCP_MMP1_cortices.nii.gz'),\n",
    "    (hcp_cortices_rh, 'rh.HCP_MMP1_cortices.nii.gz')\n",
    "]\n",
    "\n",
    "for i in tqdm(range(1, 9)):\n",
    "    subject_name = f'subj0{i}'\n",
    "    \n",
    "    for target_space, space_name in target_spaces:\n",
    "        output_path = derivatives_path / 'images' / subject_name / space_name\n",
    "        output_path.mkdir(exist_ok=True, parents=True)\n",
    "        \n",
    "        for source_data, file_name in source_datas:\n",
    "            output_file = output_path / file_name\n",
    "            nsd_mapdata.fit(\n",
    "                i, \n",
    "                source_space, \n",
    "                target_space, \n",
    "                source_data,\n",
    "                interptype='nearest',\n",
    "                badval=0, \n",
    "                outputfile=str(output_file)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26297a92-cd30-4931-9dea-2da9824e5b27",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hcp_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[43mhcp_path\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHCP-MMP1.xml\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      4\u001b[0m     hcp_xml \u001b[38;5;241m=\u001b[39m BeautifulSoup(f\u001b[38;5;241m.\u001b[39mread(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(hcp_path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHCP-MMP1_cortices.xml\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hcp_path' is not defined"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a497d4c9-bc64-42c3-b34f-80ff28c645f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary_Visual ['V1']\n",
      "Early_Visual ['V2', 'V3', 'V4']\n",
      "Dorsal_Stream_Visual ['V6', 'V3A', 'V7', 'IPS1', 'V3B', 'V6A']\n",
      "Ventral_Stream_Visual ['V8', 'FFC', 'PIT', 'VMV1', 'VMV3', 'VMV2', 'VVC']\n",
      "MT+_Complex_and_Neighboring_Visual_Areas ['MST', 'LO1', 'LO2', 'MT', 'PH', 'V4t', 'FST', 'V3CD', 'LO3']\n",
      "Somatosensory_and_Motor ['4', '3b', '1', '2', '3a']\n",
      "Paracentral_Lobular_and_Mid_Cingulate ['5m', '5mv', '23c', '5L', '24dd', '24dv', 'SCEF', '6ma', '6mp']\n",
      "Premotor ['FEF', 'PEF', '55b', '6d', '6v', '6r', '6a']\n",
      "Posterior_Opercular ['43', 'OP4', 'OP1', 'OP2-3', 'FOP1']\n",
      "Early_Auditory ['A1', '52', 'RI', 'PFcm', 'PBelt', 'MBelt', 'LBelt']\n",
      "Auditory_Association ['TA2', 'STGa', 'A5', 'STSda', 'STSdp', 'STSvp', 'A4', 'STSva']\n",
      "Insular_and_Frontal_Opercular ['PoI2', 'FOP4', 'MI', 'Pir', 'AVI', 'AAIC', 'FOP3', 'FOP2', 'PoI1', 'Ig', 'FOP5', 'PI']\n",
      "Medial_Temporal ['EC', 'PreS', 'H', 'PeEc', 'PHA1', 'PHA3', 'TF', 'PHA2']\n",
      "Lateral_Temporal ['TGd', 'TE1a', 'TE1p', 'TE2a', 'TE2p', 'PHT', 'TGv', 'TE1m']\n",
      "Temporo-Parieto-Occipital_Junction ['PSL', 'STV', 'TPOJ1', 'TPOJ2', 'TPOJ3']\n",
      "Superior_Parietal ['7Pm', '7AL', '7Am', '7Pl', '7PC', 'LIPv', 'VIP', 'MIP', 'LIPd', 'AIP']\n",
      "Inferior_Parietal ['PFt', 'PGp', 'IP2', 'IP1', 'IP0', 'PFop', 'PF', 'PFm', 'PGi', 'PGs']\n",
      "Posterior_Cingulate ['RSC', 'POS2', 'PCV', '7m', 'POS1', '23d', 'v23ab', 'd23ab', '31pv', 'ProS', 'DVT', '31pd', '31a']\n",
      "Anterior_Cingulate_and_Medial_Prefrontal ['p24pr', '33pr', 'a24pr', 'p32pr', 'a24', 'd32', '8BM', 'p32', '10r', '9m', '10v', '25', 's32', 'pOFC', 'a32pr', 'p24']\n",
      "Orbital_and_Polar_Frontal ['47m', '10d', 'a10p', '10pp', '11l', '13l', 'OFC', '47s', 'p10p']\n",
      "Inferior_Frontal ['44', '45', '47l', 'a47r', 'IFJa', 'IFJp', 'IFSp', 'IFSa', 'p47r']\n",
      "Dorsolateral_Prefrontal ['SFL', '8Av', '8Ad', '8BL', '9p', '8C', 'p9-46v', '46', 'a9-46v', '9-46d', '9a', 'i6-8', 's6-8']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "hcp_path = derivatives_path / 'HCP-MMP1'\n",
    "\n",
    "with open(hcp_path / 'HCP-MMP1.xml') as f:\n",
    "    hcp_xml = BeautifulSoup(f.read(), 'xml')\n",
    "    \n",
    "with open(hcp_path / 'HCP-MMP1_cortices.xml') as f:\n",
    "    hcp_cortices_xml = BeautifulSoup(f.read(), 'xml')\n",
    "\n",
    "hcp_cortices_file_path = hcp_path / 'HCP-MMP1_cortices' / 'HCP-MMP1_cortices_2mm.nii.gz'\n",
    "hcp_cortices_data = np.rint(nib.load(hcp_cortices_file_path).get_fdata()).astype(int)\n",
    "hcp_cortices_merged = hcp_cortices_data.copy()\n",
    "hcp_cortices_merged[hcp_cortices_merged >= 100] -= 100\n",
    "\n",
    "hcp_file_path = hcp_path / 'HCP-MMP1' / 'HCP-MMP1_2mm.nii.gz'\n",
    "hcp_data = np.rint(nib.load(hcp_file_path).get_fdata()).astype(int)\n",
    "hcp_merged = hcp_data.copy()\n",
    "hcp_merged[hcp_merged >= 200] -= 200\n",
    "\n",
    "hcp_names = {\n",
    "    i: hcp_xml.find_all('label')[i].contents[0][:-2]\n",
    "    for i in np.unique(hcp_merged)[1:]\n",
    "}\n",
    "\n",
    "hcp_cortices_names = {\n",
    "    i: hcp_cortices_xml.find_all('label')[i].contents[0][:-2]\n",
    "    for i in np.unique(hcp_cortices_merged)[1:]\n",
    "}\n",
    "\n",
    "hcp_ids = np.unique(hcp_merged)[1:]\n",
    "hcp_cortices_ids = np.unique(hcp_cortices_merged)[1:]\n",
    "\n",
    "hcp_names = {\n",
    "    i: hcp_xml.find_all('label')[i].contents[0][:-2]\n",
    "    for i in hcp_ids\n",
    "}\n",
    "\n",
    "hcp_cortices_names = {\n",
    "    i: hcp_cortices_xml.find_all('label')[i].contents[0][:-2]\n",
    "    for i in hcp_cortices_ids\n",
    "}\n",
    "\n",
    "corticies_id_mapping = {}\n",
    "cortices_name_mapping = {}\n",
    "for i in hcp_cortices_ids:\n",
    "    intersection = np.unique((hcp_cortices_merged == i) * hcp_merged)[1:]\n",
    "    corticies_id_mapping[i] = intersection\n",
    "    \n",
    "    cortices_name = hcp_cortices_names[i]\n",
    "    cortices_name_mapping[cortices_name] = [hcp_names[j] for j in intersection]\n",
    "\n",
    "for k, v in cortices_name_mapping.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8fcb678-b366-482e-9dc3-b476ea9db9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "ctab_text = '\\n'.join([f'{name} {i}'for name, i in zip(corticies_id_mapping.keys(), cortices_name_mapping.keys())])\n",
    "ctab_text = '0 Unknown\\n' + ctab_text\n",
    "\n",
    "for subject in nsd.subjects.keys():\n",
    "    for hemi in ('', 'lh.', 'rh.'):\n",
    "        with open(derivatives_path / f'labels/{subject}/{hemi}HCP_MMP1_cortices.ctab', 'w') as f:\n",
    "            f.write(ctab_text)\n",
    "        \n",
    "        hcp_roi, _ = nsd.load_roi(subject, f'{hemi}HCP_MMP1')\n",
    "        hcp_cortices_roi = np.zeros_like(hcp_roi)\n",
    "        \n",
    "        for cortices_id, region_ids in corticies_id_mapping.items():\n",
    "            for region_id in region_ids:\n",
    "                hcp_cortices_roi[hcp_roi == region_id] = cortices_id\n",
    "                \n",
    "        affine = nsd.get_affine(subject)\n",
    "        \n",
    "        nib.save(\n",
    "            nib.Nifti1Image(hcp_cortices_roi, affine), \n",
    "            derivatives_path / f'images/{subject}/func1pt8mm/{hemi}HCP_MMP1_cortices.nii.gz'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0935f44-c481-42f1-9b91-aa3ea448a2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Unknown\n",
      "1 Primary_Visual\n",
      "2 Early_Visual\n",
      "3 Dorsal_Stream_Visual\n",
      "4 Ventral_Stream_Visual\n",
      "5 MT+_Complex_and_Neighboring_Visual_Areas\n",
      "6 Somatosensory_and_Motor\n",
      "7 Paracentral_Lobular_and_Mid_Cingulate\n",
      "8 Premotor\n",
      "9 Posterior_Opercular\n",
      "10 Early_Auditory\n",
      "11 Auditory_Association\n",
      "12 Insular_and_Frontal_Opercular\n",
      "13 Medial_Temporal\n",
      "14 Lateral_Temporal\n",
      "15 Temporo-Parieto-Occipital_Junction\n",
      "16 Superior_Parietal\n",
      "17 Inferior_Parietal\n",
      "18 Posterior_Cingulate\n",
      "19 Anterior_Cingulate_and_Medial_Prefrontal\n",
      "20 Orbital_and_Polar_Frontal\n",
      "21 Inferior_Frontal\n",
      "22 Dorsolateral_Prefrontal\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(ctab_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro-decode",
   "language": "python",
   "name": "neuro-decode"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
