{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d479e6ef-7098-4a83-b496-70230984c3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cefir\\anaconda3\\envs\\Neurophysiological-Data-Decoding\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Cefir\\anaconda3\\envs\\Neurophysiological-Data-Decoding\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\Cefir\\anaconda3\\envs\\Neurophysiological-Data-Decoding\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "C:\\Users\\Cefir\\anaconda3\\envs\\Neurophysiological-Data-Decoding\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "C:\\Users\\Cefir\\anaconda3\\envs\\Neurophysiological-Data-Decoding\\lib\\site-packages\\numpy\\.libs\\libopenblas.xwydx2ikjw2nmtwsfyngfuwkqu3lytcz.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import gc\n",
    "from typing import Tuple, Optional, Dict\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchio as tio\n",
    "import h5py\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import nibabel as nib\n",
    "from einops import rearrange\n",
    "from scipy import ndimage\n",
    "import wandb\n",
    "from pathlib import Path\n",
    "\n",
    "dir2 = os.path.abspath('../..')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path:\n",
    "    sys.path.append(dir1)\n",
    "    \n",
    "from research.data.natural_scenes import (\n",
    "    NaturalScenesDataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0f57002-df40-4c34-95e2-a20bf0c05c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsd_path = Path('D:\\\\Datasets\\\\NSD')\n",
    "nsd = NaturalScenesDataset(nsd_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31e750aa-74b5-49e7-9e26-4c559fc242f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8f94507a494d6a972775c167b142a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with h5py.File(nsd_path / 'derivatives' / 'prepared' / 'nsd_preparation_01.hdf5', 'w') as f:\n",
    "    for subject_id in tqdm(range(1, 9)):\n",
    "        subject_name = f'subj0{subject_id}'\n",
    "        group = f.require_group(subject_name)\n",
    "        voxel_selection_path = 'derivatives/voxel-selection.hdf5'\n",
    "        voxel_selection_key = 'nc/value'\n",
    "        \n",
    "        voxel_selection_file = h5py.File(nsd.dataset_path / voxel_selection_path, 'r')\n",
    "        key = f'{subject_name}/{voxel_selection_key}'\n",
    "        nc = voxel_selection_file[key][:]\n",
    "        threshold = 5.\n",
    "        nc = nc[nc > threshold]\n",
    "        \n",
    "        \n",
    "        betas, volume_indices = nsd.load_betas(\n",
    "            subject_name, \n",
    "            voxel_selection_path=voxel_selection_path,\n",
    "            voxel_selection_key=voxel_selection_key,\n",
    "            threshold=threshold,\n",
    "            return_tensor_dataset=False,\n",
    "            return_volume_indices=True,\n",
    "        )\n",
    "        \n",
    "        responses = nsd.subjects[subject_name]['responses']\n",
    "        stimulus_ids = responses['73KID'].to_numpy() - 1\n",
    "        \n",
    "        num_voxels = volume_indices.shape[0]\n",
    "        volume_mask = nsd.reconstruct_volume(subject_name, torch.ones(num_voxels), volume_indices).numpy().astype(bool)\n",
    "        group['betas'] = betas\n",
    "        group['volume_mask'] = volume_mask\n",
    "        group['stimulus_ids'] = stimulus_ids\n",
    "        group['noise_ceiling'] = nc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1561f5ba-e794-4186-b296-f80eab85b86c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([27750, 27790]), (27790, 3))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betas.shape, volume_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72ed4b5b-7fae-4954-81c7-d0a7b72dee54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Neurophysiological-Data-Decoding",
   "language": "python",
   "name": "neurophysiological-data-decoding"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
