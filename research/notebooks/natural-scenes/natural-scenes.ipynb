{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bdf5412-9357-4f34-9391-7dde91e1a8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchio as tio\n",
    "import h5py\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import nibabel as nib\n",
    "from einops import rearrange\n",
    "from scipy import ndimage\n",
    "from fracridge import FracRidgeRegressorCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "dir2 = os.path.abspath('../..')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: \n",
    "    sys.path.append(dir1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3362f022-4756-4b4c-a3c3-8f78f6413ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path('D:\\\\Datasets\\\\NSD\\\\')\n",
    "derivatives_path = dataset_path / 'derivatives'\n",
    "betas_path = dataset_path / 'nsddata_betas' / 'ppdata'\n",
    "ppdata_path = dataset_path / 'nsddata' / 'ppdata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd15e9d9-634b-4eef-a207-4b2a76d2e755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image ids of the shared 1000 images across all participants\n",
    "shared_1000_path = dataset_path / 'nsddata' / 'stimuli' / 'nsd' / 'shared1000.tsv'\n",
    "shared_1000 = pd.read_csv(shared_1000_path, sep='\\t', header=None)\n",
    "shared_1000 = set(shared_1000[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9ea6983-db26-442e-a788-2205671e58c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = {f'subj0{i}': {} for i in range(1, 9)}\n",
    "\n",
    "for subject_name, subject_data in subjects.items():\n",
    "    responses_file_path = ppdata_path / subject_name / 'behav' / 'responses.tsv'\n",
    "    subject_data['responses'] = pd.read_csv(responses_file_path, sep='\\t',)\n",
    "    \n",
    "    # The last 3 sessions are currently held-out for the algonauts challenge\n",
    "    # remove them for now.\n",
    "    session_ids = subject_data['responses']['SESSION']\n",
    "    held_out_mask = session_ids > (np.max(session_ids) - 3)\n",
    "    subject_data['responses'] = subject_data['responses'][~held_out_mask]\n",
    "    \n",
    "    subject_betas_path = betas_path / subject_name / 'func1pt8mm' / 'betas_fithrf_GLMdenoise_RR'\n",
    "    num_sessions = np.max(subject_data['responses']['SESSION'])\n",
    "    \n",
    "    subject_data['sessions'] = [\n",
    "        h5py.File(subject_betas_path / f'betas_session{i:02}.hdf5', 'r')\n",
    "        for i in range(1, num_sessions + 1)\n",
    "    ]\n",
    "    \n",
    "    #subject_data['betas'] = h5py.File(subject_betas_path / f'betas_sessions.hdf5', 'r')\n",
    "    \n",
    "    subject_data['brainmask'] = nib.load(ppdata_path / subject_name / 'func1pt8mm' / 'brainmask.nii.gz')\n",
    "    subject_data['t1_path'] = ppdata_path / subject_name / 'func1pt8mm' / 'T1_to_func1pt8mm.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f42a3bc-4ba4-490a-bdd9-ee0e28489707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a train-test-validation split\n",
    "split_name = 'split-01'\n",
    "N_test = 1000\n",
    "N_validation = 1000\n",
    "N_non_shared = N_test - len(shared_1000_three_repetitions)\n",
    "seed = 0\n",
    "\n",
    "for subject_name, subject_data in subjects.items():\n",
    "    responses = subject_data['responses']\n",
    "    \n",
    "    image_ids = responses['73KID'].to_numpy()\n",
    "    unique_image_ids, unique_counts = np.unique(image_ids, return_counts=True)\n",
    "    three_repetition_ids = unique_image_ids[unique_counts == 3]\n",
    "    subject_data['three_repetition_ids'] = set(three_repetition_ids)\n",
    "    print(f'{subject_name} {image_ids.shape=}, {len(three_repetition_ids)=}')\n",
    "    \n",
    "shared_1000_three_repetitions = set.intersection(\n",
    "    shared_1000,\n",
    "    *[subject_data['three_repetition_ids']\n",
    "    for subject_data in subjects.values()]\n",
    ")\n",
    "print(f'{len(shared_1000_three_repetitions)=}')\n",
    "\n",
    "for subject_name, subject_data in subjects.items():\n",
    "    three_repetition_ids = subject_data['three_repetition_ids']\n",
    "    non_shared_three_repetition_ids = list(three_repetition_ids - shared_1000_three_repetitions)\n",
    "    random.Random(seed).shuffle(non_shared_three_repetition_ids)\n",
    "    \n",
    "    test_image_ids = list(shared_1000_three_repetitions) + non_shared_three_repetition_ids[:N_non_shared]\n",
    "    validation_image_ids = non_shared_three_repetition_ids[N_non_shared:(N_non_shared + N_validation)]\n",
    "    subject_data['test_image_ids'] = np.array(test_image_ids)\n",
    "    subject_data['validation_image_ids'] = np.array(test_image_ids)\n",
    "    \n",
    "    test_image_ids = set(test_image_ids)\n",
    "    validation_image_ids = set(validation_image_ids)\n",
    "    image_ids = subject_data['responses']['73KID'].to_numpy()\n",
    "    subject_data['test_response_ids'] = np.argwhere([image_id in test_image_ids for image_id in image_ids])[:, 0]\n",
    "    subject_data['validation_response_ids'] = np.argwhere([image_id in validation_image_ids for image_id in image_ids])[:, 0]\n",
    "    \n",
    "with h5py.File(derivatives_path / 'data_splits' / f'{split_name}.hdf5', 'w') as f:\n",
    "    for subject_name, subject_data in subjects.items():\n",
    "        subject = f.require_group(subject_name)\n",
    "        \n",
    "        three_repetition_ids = subject_data['three_repetition_ids']\n",
    "        non_shared_three_repetition_ids = list(three_repetition_ids - shared_1000_three_repetitions)\n",
    "        random.Random(seed).shuffle(non_shared_three_repetition_ids)\n",
    "\n",
    "        test_image_ids = list(shared_1000_three_repetitions) + non_shared_three_repetition_ids[:N_non_shared]\n",
    "        validation_image_ids = non_shared_three_repetition_ids[N_non_shared:(N_non_shared + N_validation)]\n",
    "        subject['test_image_ids'] = np.array(test_image_ids)\n",
    "        subject['validation_image_ids'] = np.array(test_image_ids)\n",
    "\n",
    "        test_image_ids = set(test_image_ids)\n",
    "        validation_image_ids = set(validation_image_ids)\n",
    "        image_ids = subject_data['responses']['73KID'].to_numpy()\n",
    "        subject['test_response_mask'] = np.array([image_id in test_image_ids for image_id in image_ids], dtype=bool)\n",
    "        subject['validation_response_mask'] = np.array([image_id in validation_image_ids for image_id in image_ids], dtype=bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3974383-1c32-4356-99f9-7920e2ac6f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch implementation of fractional ridge regression\n",
    "\n",
    "def pearsonr(X, Y, dim=0, cast_dtype=torch.float64):\n",
    "    in_dtype = X.dtype\n",
    "    X = X.to(cast_dtype)\n",
    "    Y = Y.to(cast_dtype)\n",
    "\n",
    "    X = X - X.mean(dim=dim, keepdim=True)\n",
    "    Y = Y - Y.mean(dim=dim, keepdim=True)\n",
    "\n",
    "    X = X / torch.norm(X, dim=dim, keepdim=True)\n",
    "    Y = Y / torch.norm(Y, dim=dim, keepdim=True)\n",
    "\n",
    "    r = torch.tensordot(X, Y, dims=dim).to(in_dtype)\n",
    "    return r\n",
    "\n",
    "\n",
    "def rsquared(Y, Y_pred, dim=0, cast_dtype=torch.float64):\n",
    "    in_dtype = Y.dtype\n",
    "    Y = Y.to(cast_dtype)\n",
    "    Y_pred = Y_pred.to(cast_dtype)\n",
    "\n",
    "    ss_res = ((Y - Y_pred) ** 2).sum(dim=dim)\n",
    "    ss_tot = ((Y - Y.mean(dim=dim, keepdim=True)) ** 2).sum(dim=dim)\n",
    "\n",
    "    r2 = 1 - ss_res / ss_tot\n",
    "    return r2\n",
    "\n",
    "from scipy.linalg import svd\n",
    "from functools import partial\n",
    "svd = partial(svd, full_matrices=False)\n",
    "from numpy import interp\n",
    "\n",
    "def frac_ridge_regression(X, Y, fractions=None, tol=1e-6):\n",
    "    BIG_BIAS = 10e3\n",
    "    SMALL_BIAS = 10e-3\n",
    "    BIAS_STEP = 0.2\n",
    "    \n",
    "    if fractions is None:\n",
    "        fractions = torch.arange(.1, 1.1, .1)\n",
    "    \n",
    "    U, S, Vt = torch.linalg.svd(X, full_matrices=False)\n",
    "    Y_new = U.transpose(-1, -2) @ Y\n",
    "    ols_coef = (Y_new.transpose(-1, -2) / S[..., None, :]).transpose(-1, -2)\n",
    "    \n",
    "    S_small = torch.broadcast_to(S < tol, ols_coef.shape[:-1])\n",
    "    ols_coef[S_small, ...] = 0.\n",
    "    \n",
    "    val1 = BIG_BIAS * S[..., 0] ** 2\n",
    "    val2 = SMALL_BIAS * S[..., -1] ** 2\n",
    "\n",
    "    grid_low = torch.floor(torch.log10(val2))\n",
    "    grid_high = torch.ceil(torch.log10(val1))\n",
    "    steps = int(torch.max(grid_high - grid_low).item() / BIAS_STEP)\n",
    "    alphagrid = 10 ** torch.stack([\n",
    "        (i / steps) * grid_high + (1 - i / steps) * grid_low\n",
    "        for i in range(steps)\n",
    "    ])\n",
    "    alphagrid = torch.cat([torch.zeros_like(grid_low)[None], alphagrid])\n",
    "    \n",
    "    S_squared = S ** 2\n",
    "    scaling = S_squared / (S_squared + alphagrid[..., None])\n",
    "    scaling_squared = scaling ** 2\n",
    "\n",
    "    newlen = torch.sqrt(torch.einsum('g ... p, ... p b -> g ... b', scaling_squared, ols_coef ** 2))\n",
    "    newlen = (newlen / newlen[0])\n",
    "    \n",
    "    while len(fractions.shape) < len(newlen.shape):\n",
    "        fractions = fractions[:, None]\n",
    "    \n",
    "    threshold = fractions[None, :] < newlen[:, None]\n",
    "    threshold = (threshold[1:] != threshold[:-1]).int()\n",
    "    threshold = threshold.argmax(dim=0)\n",
    "\n",
    "    newlen_high = torch.gather(newlen, 0, threshold)\n",
    "    newlen_low = torch.gather(newlen, 0, threshold + 1)\n",
    "    \n",
    "    t = (newlen_high - fractions) / (newlen_high - newlen_low)\n",
    "    log_alphagrid = torch.log(1 + alphagrid)\n",
    "    log_alphagrid = torch.broadcast_to(log_alphagrid[..., None], newlen.shape)\n",
    "\n",
    "    alpha_high = torch.gather(log_alphagrid, 0, threshold)\n",
    "    alpha_low = torch.gather(log_alphagrid, 0, threshold + 1)\n",
    "    alpha = (1. - t) * alpha_high + t * alpha_low\n",
    "    alpha = torch.exp(alpha) - 1.\n",
    "    \n",
    "    sc = S_squared / (S_squared + rearrange(alpha, 'f ... b -> f b ... 1'))\n",
    "    coef = sc * rearrange(ols_coef, '... p b -> 1 b ... p')\n",
    "    \n",
    "    coef = torch.einsum('... p i, f b ... p -> ... f i b', Vt, coef)\n",
    "    alpha = rearrange(alpha, 'f ... b -> ... f b')\n",
    "    \n",
    "    return coef, alpha\n",
    "\n",
    "def predict(X, coef):\n",
    "    return torch.einsum('... n p, ... f p b -> ... f n b', X, coef)\n",
    "\n",
    "\n",
    "def frac_ridge_regression_cv(X, Y, fractions=None, cv=5, tol=1e-6):\n",
    "    if fractions is None:\n",
    "        fractions = torch.arange(.1, 1.1, .1, device=X.device)\n",
    "    \n",
    "    kf = KFold(n_splits=cv, shuffle=True)\n",
    "    r2 = []\n",
    "    for train_ids, val_ids in kf.split(np.arange(X.shape[-2])):\n",
    "        X_train = X[..., train_ids, :]\n",
    "        Y_train = Y[..., train_ids, :]\n",
    "        X_val = X[..., val_ids, :]\n",
    "        Y_val = Y[..., val_ids, :]\n",
    "        \n",
    "        coef, alpha = frac_ridge_regression(X_train, Y_train, fractions)\n",
    "        Y_val_pred = predict(X_val, coef)\n",
    "        r2.append(rsquared(Y_val[..., None, :, :], Y_val_pred, dim=-2))\n",
    "    r2 = torch.stack(r2).mean(dim=0)\n",
    "    best_r2, best_fraction_ids = r2.max(dim=-2)\n",
    "    best_fractions = fractions[best_fraction_ids]\n",
    "    \n",
    "    best_coefs, best_alpha = frac_ridge_regression(X_train, Y_train, best_fractions[None])\n",
    "    return best_coefs[..., 0, :, :], best_alpha[..., 0, :], best_r2, best_fractions\n",
    "\n",
    "\n",
    "N = 20000\n",
    "batch_size = 100\n",
    "embedding_size = 512\n",
    "t = time.time()\n",
    "for i in tqdm(range(N // batch_size)):\n",
    "    X = torch.randn(21750, embedding_size).cuda()\n",
    "    Y = torch.randn(21750, batch_size).cuda()\n",
    "    fractions = torch.arange(.05, 1.05, .05).cuda()\n",
    "    coefs, alpha, r2, frac = frac_ridge_regression_cv(X, Y, fractions)\n",
    "\n",
    "'''\n",
    "for i in tqdm(range(N // batch_size)):\n",
    "    break\n",
    "    X = np.random.randn(21750, embedding_size)\n",
    "    Y = np.random.randn(21750, batch_size)\n",
    "    fractions = np.arange(.05, 1.05, .05)\n",
    "    model = FracRidgeRegressorCV(frac_grid=fractions)\n",
    "    model.fit(X, Y)\n",
    "    print(model.best_frac_)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb76a346-f88c-49a6-b15e-0d480d3f2b94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run an encoder\n",
    "\n",
    "split_name = 'split-01'\n",
    "split = h5py.File(derivatives_path / 'data_splits' / f'{split_name}.hdf5')\n",
    "fractions = torch.arange(.05, 1.05, .05).cuda()\n",
    "#alpha = 10 ** torch.linspace(1, 5, 20).cuda()\n",
    "\n",
    "run_stimulus_embeddings = {\n",
    "    'bigbigan-resnet50': ['z_mean'],\n",
    "    'ViT-B=32': ['embedding',],# *(f'transformer.resblocks.{i}' for i in range(12))],\n",
    "    #'biggan-128': ['z', 'y_embedding'],\n",
    "    #'vqgan': ['vqgan-f16-1024-pre_quant'],\n",
    "}\n",
    "\n",
    "embedding_files = {\n",
    "    model_name: h5py.File(derivatives_path / 'stimulus_embeddings' / f'{model_name}-embeddings.hdf5', 'r')\n",
    "    for model_name in run_stimulus_embeddings.keys()\n",
    "}\n",
    "\n",
    "with h5py.File(derivatives_path / 'fracridge-parameters.hdf5', 'a') as f:\n",
    "    for subject_name, subject_data in subjects.items():\n",
    "        sessions = subject_data['sessions']\n",
    "        num_sessions = len(sessions)\n",
    "        shape = sessions[0]['betas'].shape\n",
    "        T, W, H, D = shape\n",
    "        \n",
    "        subject_split = split[subject_name]\n",
    "        test_mask = subject_split['test_response_mask'][:].astype(bool)\n",
    "        validation_mask = subject_split['validation_response_mask'][:].astype(bool)\n",
    "        training_mask = ~(test_mask | validation_mask)\n",
    "        training_indices = np.where(training_mask)[0]\n",
    "\n",
    "        responses = subject_data['responses']\n",
    "        training_stimulus_ids = responses['73KID'].to_numpy()[training_indices] - 1\n",
    "\n",
    "        subject_stimulus_embeddings = {\n",
    "            model_name : {\n",
    "                embedding_name: torch.from_numpy(embedding_files[model_name][embedding_name][:][training_stimulus_ids]).clone().cuda()\n",
    "                for embedding_name in embedding_names\n",
    "            }\n",
    "            for model_name, embedding_names in run_stimulus_embeddings.items()\n",
    "        }\n",
    "\n",
    "        for model_name, embeddings in subject_stimulus_embeddings.items():\n",
    "            for embedding_name, embedding in embeddings.items():\n",
    "                keys = (subject_name, model_name, embedding_name)\n",
    "                key = '/'.join(keys)\n",
    "                E = embedding.shape[-1]\n",
    "                group = f.require_group(key)\n",
    "                group.require_dataset('coefs', shape=(W, H, D, E), dtype='f4')\n",
    "                group.require_dataset('alpha', shape=(W, H, D), dtype='f4')\n",
    "                group.require_dataset('r2', shape=(W, H, D), dtype='f4')\n",
    "                group.require_dataset('fractions', shape=(W, H, D), dtype='f4')\n",
    "                \n",
    "                embedding_mean = embedding.mean(dim=0, keepdims=True)\n",
    "                embedding_std = embedding.std(dim=0, keepdims=True)\n",
    "                embeddings[embedding_name] = (embedding - embedding_mean) / embedding_std\n",
    "                \n",
    "                group['embedding_mean'] = embedding_mean.cpu().numpy()\n",
    "                group['embedding_std'] = embedding_std.cpu().numpy()\n",
    "\n",
    "        mask = (subjects[subject_name]['brainmask'].get_fdata() > 0.).T\n",
    "        \n",
    "        load_time = 0\n",
    "        compute_time = 0\n",
    "        store_time = 0\n",
    "        \n",
    "        for i in tqdm(range(W)):\n",
    "            if (i + 1) % 5 == 0:\n",
    "                print(f'{load_time=:03}s, {compute_time=:03}s, {store_time=:03}s')\n",
    "    \n",
    "            mask_slice = mask[i]\n",
    "            if mask_slice.sum() == 0:\n",
    "                continue\n",
    "            \n",
    "            t = time.time()\n",
    "            Y = np.concatenate([\n",
    "                session['betas'][:, i] \n",
    "                for session in sessions\n",
    "            ])\n",
    "            Y = Y[training_indices]\n",
    "            Y = Y[:, mask_slice]\n",
    "            Y = torch.from_numpy(Y).float() / 300\n",
    "            Y = (Y - Y.mean(dim=0, keepdims=True)) / Y.std(dim=0, keepdims=True)\n",
    "            #Y = Y.T[..., None]\n",
    "            \n",
    "            slice_indices = torch.from_numpy(np.argwhere(mask_slice))\n",
    "            load_time += time.time() - t\n",
    "            \n",
    "            batch_size = 100\n",
    "            Y_splits = torch.split(Y, batch_size, dim=1)\n",
    "            indices_splits = torch.split(slice_indices, batch_size)\n",
    "            for Y_batch, indices_batch in zip(Y_splits, indices_splits):\n",
    "                Y_batch = Y_batch.cuda()\n",
    "                for model_name, embeddings in subject_stimulus_embeddings.items():\n",
    "                    for embedding_name, embedding in embeddings.items():\n",
    "                        t = time.time()\n",
    "                        \n",
    "                        gc.collect()\n",
    "                        torch.cuda.empty_cache()\n",
    "\n",
    "                        keys = (subject_name, model_name, embedding_name)\n",
    "                        group = f['/'.join(keys)]\n",
    "                        X = embedding[:]\n",
    "                        \n",
    "                        #print(X.shape, Y_batch.shape, fractions.shape)\n",
    "                        #coefs, alpha, r2 = ridge_regression_cv(X, Y_batch[..., 0].T, alpha=alpha)\n",
    "                        coefs, alpha, r2, frac = frac_ridge_regression_cv(X, Y_batch, fractions)\n",
    "                        coefs = coefs.cpu().numpy()\n",
    "                        a = alpha.cpu().numpy()\n",
    "                        r2 = r2.cpu().numpy()\n",
    "                        frac = frac.cpu().numpy()\n",
    "                        \n",
    "                        compute_time += time.time() - t\n",
    "\n",
    "                        t = time.time()\n",
    "                        for v, (j, k) in enumerate(indices_batch):\n",
    "                            group['coefs'][i, j, k] = coefs[:, v]\n",
    "                            group['alpha'][i, j, k] = a[v]\n",
    "                            group['r2'][i, j, k] = r2[v]\n",
    "                            group['fractions'][i, j, k] = frac[v]\n",
    "                        store_time += time.time() - t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b939c3b-7b72-4787-89b8-c3d0854f9e63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save encoder results\n",
    "\n",
    "encoder_name = 'fracridge'\n",
    "\n",
    "with h5py.File(derivatives_path / f'{encoder_name}-parameters.hdf5', 'r') as f:\n",
    "    for subject_name, subject in f.items():\n",
    "        subject_out_path = derivatives_path / 'images' / encoder_name / subject_name\n",
    "        subject_out_path.mkdir(parents=True, exist_ok=True)\n",
    "        affine = subjects[subject_name]['brainmask'].affine\n",
    "        \n",
    "        for model_name, model in subject.items():\n",
    "            for embedding_name, embedding in model.items():\n",
    "                for image_name, image, in embedding.items():\n",
    "                    keys = (subject_name, encoder_name, model_name, embedding_name, image_name)\n",
    "                    save_file_name = f'{\"__\".join(keys)}.nii.gz'\n",
    "                    print(keys, image.shape)\n",
    "                    if len(image.shape) == 3:\n",
    "                        image = nib.Nifti1Image(image[:].T, affine)\n",
    "                    elif len(image.shape) == 4:\n",
    "                        continue\n",
    "                        image = nib.Nifti1Image(image[:].T, affine)\n",
    "                    else:\n",
    "                        continue\n",
    "                    nib.save(image, subject_out_path / save_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbde3ae4-beb0-450c-a901-d5b9fdc2513c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add feature selection indices\n",
    "\n",
    "encoder_name = 'fracridge'\n",
    "\n",
    "with h5py.File(derivatives_path / f'{encoder_name}-parameters.hdf5', 'a') as f:\n",
    "    for subject_name, subject in f.items():\n",
    "        for model_name, model in subject.items():\n",
    "            for embedding_name, embedding in model.items():\n",
    "                r2 = embedding['r2'][:]\n",
    "                sorted_indices_flat = r2.argsort(axis=None)[::-1]\n",
    "                grid = np.argwhere(np.ones_like(r2, dtype=bool))\n",
    "                sorted_indices = grid[sorted_indices_flat]\n",
    "                \n",
    "                embedding['sorted_indices_flat'] = sorted_indices_flat\n",
    "                embedding['sorted_indices'] = sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85ec727-76e3-46f9-8b9e-140eaee0d856",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_results = h5py.File(derivatives_path / f'{encoder_name}-parameters.hdf5', 'r')\n",
    "\n",
    "@interact(subject=encoder_results.items())\n",
    "def select_subject(subject):\n",
    "    subject_name = subject.name[1:]\n",
    "    sessions = subjects[subject_name]['sessions']\n",
    "    betas = subjects[subject_name]['betas']\n",
    "    print(sessions[0]['betas'].shape)\n",
    "    \n",
    "    @interact(model=subject.items())\n",
    "    def select_model(model):\n",
    "        \n",
    "        @interact(embedding=model.items())\n",
    "        def select_embedding(embedding):\n",
    "            \n",
    "            r2 = embedding['r2'][:]\n",
    "            sorted_indices_flat = r2.argsort(axis=None)[::-1]\n",
    "            grid = np.argwhere(np.ones_like(r2, dtype=bool))\n",
    "            sorted_indices = grid[sorted_indices_flat]\n",
    "            print(grid)\n",
    "            t = time.time()\n",
    "            \n",
    "            Y = np.stack([\n",
    "                betas['betas'][:, i] \n",
    "                for i in sorted_indices_flat[:2500]\n",
    "            ], axis=1)\n",
    "            \n",
    "            #for i, j, k in sorted_indices[:2500]:\n",
    "            #    Y = np.concatenate([\n",
    "            #        session['betas'][:, i, j, k]\n",
    "            #        for session in sessions\n",
    "            #    ])\n",
    "            print(time.time() - t)\n",
    "            print(Y.shape)\n",
    "        \n",
    "            @interact(w=(0, r2.shape[0]-1), num=(0, 50000))\n",
    "            def show_top(w, num):\n",
    "                selection_map = np.zeros_like(r2)\n",
    "                i, j, k = list(sorted_indices[:num].T)\n",
    "                selection_map[i, j, k] = 1\n",
    "                plt.imshow(selection_map[w].T)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4a67eb4-b720-41ad-a617-335e431cc088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subj05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68e1ad087904ddfb5a0d6e5140c8a56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subj06\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5c4ef6ae6e4a3d8a69d2178465859f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subj07\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8646854cc7c1431ca06eb6a95ed6cb5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subj08\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6864dda796934c38acb07507ac7be04d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# concatenate sessions\n",
    "\n",
    "for subject_name, subject_data in subjects.items():\n",
    "    if subject_name in ('subj01', 'subj02', 'subj03', 'subj04', ):\n",
    "        continue\n",
    "    print(subject_name)\n",
    "    path = derivatives_path / 'betas' / subject_name / 'func1pt8mm' / 'betas_fithrf_GLMdenoise_RR'\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    with h5py.File(path / 'betas_sessions.hdf5', 'a') as f:\n",
    "\n",
    "        sessions = subject_data['sessions']\n",
    "        num_sessions = len(sessions)\n",
    "        shape = sessions[0]['betas'].shape\n",
    "        T, W, H, D = shape\n",
    "        T_full = T * len(sessions)\n",
    "        \n",
    "        f.require_dataset('betas', shape=(T_full, W * H * D), dtype=np.int16, chunks=(T_full, 1))\n",
    "        for i in tqdm(range(W)):\n",
    "            Y = np.concatenate([\n",
    "                session['betas'][:, i]\n",
    "                for session in sessions\n",
    "            ])\n",
    "            slice_size = H * D\n",
    "            f['betas'][:, slice_size * i:slice_size * (i + 1)] = rearrange(Y, 't ... -> t (...)')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adcf10f-a25b-4583-ad4f-e409cb550a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save feature selection\n",
    "\n",
    "encoder_name = 'fracridge'\n",
    "\n",
    "with h5py.File(derivatives_path / f'{encoder_name}-parameters.hdf5', 'r') as f:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0561e963-4a53-4bd2-b345-fa599864ae1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder experiments on a slice\n",
    "\n",
    "subject_name = 'subj01'\n",
    "\n",
    "subject = subjects[subject_name]\n",
    "sessions = subject['sessions']\n",
    "t1 = nib.load(subject['t1_path']).get_fdata().T\n",
    "\n",
    "split_name = 'split-01'\n",
    "split = h5py.File(derivatives_path / 'data_splits' / f'{split_name}.hdf5')\n",
    "\n",
    "subject_split = split[subject_name]\n",
    "test_mask = subject_split['test_response_mask'][:].astype(bool)\n",
    "validation_mask = subject_split['validation_response_mask'][:].astype(bool)\n",
    "training_mask = ~(test_mask | validation_mask)\n",
    "training_indices = np.where(training_mask)[0]\n",
    "\n",
    "run_stimulus_embeddings = {\n",
    "    'bigbigan-resnet50': ['z_mean'],\n",
    "    'ViT-B=32': ['embedding',],# *(f'transformer.resblocks.{i}' for i in range(12))],\n",
    "    #'biggan-128': ['z', 'y_embedding'],\n",
    "    #'vqgan': ['vqgan-f16-1024-pre_quant'],\n",
    "}\n",
    "\n",
    "embedding_files = {\n",
    "    model_name: h5py.File(derivatives_path / 'stimulus_embeddings' / f'{model_name}-embeddings.hdf5', 'r')\n",
    "    for model_name in run_stimulus_embeddings.keys()\n",
    "}\n",
    "\n",
    "W, H, D = t1.shape\n",
    "axial_slice = 37\n",
    "saggital_slice = slice(None)\n",
    "coronal_slice = slice(-80)\n",
    "\n",
    "# Extract an interesting slice from the visual cortex\n",
    "# (time, axial, coronal, saggital)\n",
    "betas_slice = np.concatenate([\n",
    "    session['betas'][:, axial_slice, coronal_slice, saggital_slice]\n",
    "    for session in sessions\n",
    "])[training_indices]\n",
    "\n",
    "betas_slice = torch.from_numpy(betas_slice).float() / 300\n",
    "betas_slice = betas_slice - betas_slice.mean(dim=0, keepdims=True)\n",
    "betas_slice = betas_slice / (betas_slice.std(dim=0, keepdims=True) + 1e-7)\n",
    "\n",
    "mask = (subject['brainmask'].get_fdata() > 0.).T\n",
    "mask = mask[axial_slice, coronal_slice, saggital_slice]\n",
    "\n",
    "Y = betas_slice[:, mask]\n",
    "\n",
    "responses = subject['responses']\n",
    "training_stimulus_ids = responses['73KID'].to_numpy()[training_indices] - 1\n",
    "\n",
    "subject_stimulus_embeddings = {\n",
    "    model_name : {\n",
    "        embedding_name: torch.from_numpy(embedding_files[model_name][embedding_name][:][training_stimulus_ids])\n",
    "        for embedding_name in embedding_names\n",
    "    }\n",
    "    for model_name, embedding_names in run_stimulus_embeddings.items()\n",
    "}\n",
    "\n",
    "'''\n",
    "T = Y.shape[0]\n",
    "@interact(t=(0, T-1))\n",
    "def show(t):\n",
    "    plt.imshow(t1.get_fdata()[axial_slice, saggital_slice, coronal_slice],  cmap='gray')'''\n",
    "\n",
    "width=30\n",
    "@interact(w=(0, W-1), h=(width, H-width-1), d=(width, D-width-1),)\n",
    "def show(w, h, d):\n",
    "    #plt.imshow(t1[w, h-width:h+width, d-width:d+width],  cmap='gray')\n",
    "    plt.imshow(t1[axial_slice, coronal_slice, saggital_slice][::-1, ::-1], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa8f877-a654-43bc-9250-85ee3470c4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9ce996-bd0c-4e79-a957-e615c2f0703f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(device, *tensors):\n",
    "    return (tensor.to(device) for tensor in tensors)\n",
    "\n",
    "X_bigbigan = subject_stimulus_embeddings['bigbigan-resnet50']['z_mean']\n",
    "X_clip = subject_stimulus_embeddings['ViT-B=32']['embedding']\n",
    "\n",
    "X = X_clip.clone()\n",
    "X = X - X.mean(dim=0, keepdims=True)\n",
    "X = X / (X.std(dim=0, keepdims=True) + 1e-7)\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "fractions = torch.arange(.05, 1.05, .05)\n",
    "coefs, alpha, r2, frac = to_device('cpu', *frac_ridge_regression_cv(*to_device('cuda', X, Y, fractions)))\n",
    "\n",
    "'''\n",
    "#frac = []\n",
    "#alpha = []\n",
    "#r2 = []\n",
    "#coefs = []\n",
    "fractions = np.arange(.05, 1.05, .05)\n",
    "for i in tqdm(range(912, Y.shape[1])):\n",
    "    model = FracRidgeRegressorCV(frac_grid=fractions, cv=5)\n",
    "    model.fit(X.numpy(), Y[:, i].numpy())\n",
    "    frac.append(model.best_frac_)\n",
    "    alpha.append(model.alpha_.item())\n",
    "    r2.append(model.best_score_)\n",
    "    coefs.append(model.coef_)\n",
    "frac = np.array(frac)\n",
    "alpha = np.array(alpha)\n",
    "r2 = np.array(r2)\n",
    "coefs = np.stack(coefs)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003cfc92-0767-46bd-b286-6d921a53df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8e71cb-369c-402a-8261-d912f061b942",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice = np.zeros_like(mask, dtype=float)\n",
    "plot_slice[mask] = r2\n",
    "\n",
    "print(plot_slice.max())\n",
    "plt.imshow(plot_slice[::-1, ::-1], vmin=0, vmax=plot_slice.max(), cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb40528c-21df-40e5-b0b2-16ccc2376194",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_diff = r2_reg - r2\n",
    "max_diff = torch.max(r2_diff.abs())\n",
    "\n",
    "plot_slice[mask] = r2_diff\n",
    "\n",
    "plt.imshow(plot_slice[::-1, ::-1], vmin=-max_diff, vmax=max_diff, cmap='bwr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987b0f52-9d23-41ec-9ea4-1e51a24d40b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_bigbigan[:100]\n",
    "X = X - X.mean(dim=0, keepdims=True)\n",
    "X = X / (X.std(dim=0, keepdims=True) + 1e-7)\n",
    "\n",
    "y = np.stack([np.arange(X.shape[1]) for _ in range(X.shape[0])])\n",
    "\n",
    "plt.figure(figsize=(24, 8))\n",
    "plt.scatter(y.flatten(), X.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a83cad-6811-47b5-9204-eaaf47562ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bigbigan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b71a59d-bf44-4dbe-a6a1-73097b3523f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1777adb8-8d6d-427a-89e5-a3ca3c7585bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch implementation of ridge\n",
    "\n",
    "from numbers import Number\n",
    "from typing import Sequence\n",
    "\n",
    "def rsquared(Y, Y_pred, dim=0, cast_dtype=torch.float64):\n",
    "    in_dtype = Y.dtype\n",
    "    Y = Y.to(cast_dtype)\n",
    "    Y_pred = Y_pred.to(cast_dtype)\n",
    "\n",
    "    ss_res = ((Y - Y_pred) ** 2).sum(dim=dim)\n",
    "    ss_tot = ((Y - Y.mean(dim=dim, keepdim=True)) ** 2).sum(dim=dim)\n",
    "\n",
    "    r2 = 1 - ss_res / ss_tot\n",
    "    return r2\n",
    "\n",
    "\n",
    "def ridge_regression(X, Y, alpha=None,):\n",
    "    lhs = X.transpose(-2, -1) @ X\n",
    "    rhs = X.transpose(-2, -1) @ Y\n",
    "    if alpha is None:\n",
    "        return torch.linalg.lstsq(lhs, rhs).solution\n",
    "    else:\n",
    "        ridge = alpha * torch.eye(lhs.shape[-2], device=X.device)\n",
    "        return torch.linalg.lstsq(lhs + ridge, rhs).solution\n",
    "\n",
    "\n",
    "def ridge_regression_cv(X, Y, alpha=None, cv=5, tol=1e-6):\n",
    "    if alpha is None:\n",
    "        alpha = 10 ** torch.linspace(1, 5, 20)\n",
    "    \n",
    "    kf = KFold(n_splits=cv, shuffle=True)\n",
    "    r2 = []\n",
    "    for train_ids, val_ids in kf.split(np.arange(X.shape[-2])):\n",
    "        X_train = X[..., train_ids, :]\n",
    "        Y_train = Y[..., train_ids, :]\n",
    "        X_val = X[..., val_ids, :]\n",
    "        Y_val = Y[..., val_ids, :]\n",
    "        \n",
    "        # Add a new dimension for alphas (try every alpha vs every target)\n",
    "        coefs = ridge_regression(X_train[None], Y_train[None], alpha[:, None, None])\n",
    "        Y_val_pred = X_val[None] @ coefs\n",
    "        \n",
    "        r2.append(rsquared(Y_val[None], Y_val_pred, dim=-2))\n",
    "        \n",
    "    r2 = torch.stack(r2).mean(dim=0)\n",
    "    best_r2, best_alpha_ids = r2.max(dim=-2)\n",
    "    best_alpha = alpha[best_alpha_ids]\n",
    "    \n",
    "    best_coefs = ridge_regression(X_train[None], Y_train.transpose(-2, -1)[..., None], best_alpha[:, None, None])\n",
    "    best_coefs = best_coefs[..., 0].transpose(-1, -2)\n",
    "    return best_coefs, best_alpha, best_r2\n",
    "\n",
    "'''\n",
    "N = int(10000)\n",
    "batch_size = 100\n",
    "embedding_size = 512\n",
    "t = time.time()\n",
    "for i in tqdm(range(N // batch_size)):\n",
    "    X = torch.randn(21750, embedding_size).cuda()\n",
    "    Y = torch.randn(21750, batch_size).cuda()\n",
    "    alpha = 10 ** torch.linspace(1, 5, 20).cuda()\n",
    "    coefs, alpha, r2 = ridge_regression_cv(X, Y, alpha=alpha)\n",
    "    print(f'{coefs.shape=}, {alpha.shape=}, {r2.shape=}')\n",
    "    break'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9335ec-f852-4261-b607-6c2981fb23c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894061d6-600a-426a-aade-264356b38c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Neurophysiological-Data-Decoding",
   "language": "python",
   "name": "neurophysiological-data-decoding"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
