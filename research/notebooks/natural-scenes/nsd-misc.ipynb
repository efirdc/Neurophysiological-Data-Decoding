{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c4a539-4ffa-4fca-aa5c-245c16adb2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import gc\n",
    "from typing import Tuple, Optional, Dict\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import h5py\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import nibabel as nib\n",
    "from einops import rearrange\n",
    "from scipy import ndimage\n",
    "\n",
    "dir2 = os.path.abspath('../..')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: \n",
    "    sys.path.append(dir1)\n",
    "    \n",
    "from pipeline.utils import index_unsorted, nested_insert, nested_select\n",
    "from pipeline.compact_json_encoder import CompactJSONEncoder\n",
    "from research.metrics.metrics import (\n",
    "    cosine_similarity, \n",
    "    r2_score,\n",
    "    pearsonr, \n",
    "    embedding_distance,\n",
    "    cosine_distance,\n",
    "    squared_euclidean_distance,\n",
    "    contrastive_score,\n",
    "    two_versus_two,\n",
    "    smooth_euclidean_distance,\n",
    "    evaluate_decoding\n",
    ")\n",
    "\n",
    "from research.data.natural_scenes import (\n",
    "    NaturalScenesDataset,\n",
    "    StimulusDataset,\n",
    "    KeyDataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092bf44c-4caf-4604-8ce6-2ea1dafda93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsd_path = Path('D:\\\\Datasets\\\\NSD\\\\')\n",
    "nsd = NaturalScenesDataset(nsd_path)\n",
    "\n",
    "subject_name = 'subj01'\n",
    "betas_params = dict(\n",
    "    subject_name=subject_name,\n",
    "    voxel_selection_path='derivatives/voxel-selection.hdf5',\n",
    "    voxel_selection_key='nc/value',\n",
    "    threshold=30,\n",
    "    return_volume_indices=True\n",
    ")\n",
    "betas, betas_indices = nsd.load_betas(**betas_params)\n",
    "\n",
    "model_name = 'ViT-B=32'\n",
    "stimulus_key = 'embedding'\n",
    "stimulus_params = dict(\n",
    "    subject_name=subject_name,\n",
    "    #stimulus_path='nsddata_stimuli/stimuli/nsd/nsd_stimuli.hdf5',\n",
    "    #stimulus_key='imgBrick',\n",
    "    stimulus_path=f'derivatives/stimulus_embeddings/{model_name}.hdf5',\n",
    "    stimulus_key=stimulus_key,\n",
    "    delay_loading=True\n",
    ")\n",
    "stimulus = nsd.load_stimulus(**stimulus_params)\n",
    "dataset = KeyDataset({'betas': betas, 'stimulus': stimulus})\n",
    "train_dataset, val_dataset, test_dataset = nsd.apply_subject_split(dataset, subject_name, 'split-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4782777c-8403-4b4c-9c89-c072114eb795",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_betas = nsd.subjects[subject_name]['betas']\n",
    "volume_shape = tuple(subject_betas['betas'].attrs['spatial_shape'])\n",
    "volume_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4171ae78-8edc-4748-8cee-5054c634a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0]['stimulus']['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f82a96-92a4-4e4b-9ded-31c8a3417d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('G:\\\\Github Repositories\\\\Google Drive\\\\Repositories\\\\neuro-ml\\\\example_data\\\\nsd.hdf5', 'w') as f:\n",
    "    f['betas_indices'] = betas_indices\n",
    "    f['betas_indices'].attrs['volume_shape'] = volume_shape\n",
    "    datasets = [('train', val_dataset), ('test', test_dataset)]\n",
    "    for dset_name, dset in datasets:\n",
    "        sample = dset[0]\n",
    "        num_betas = sample['betas'][0].shape[0]\n",
    "        num_stimulus = sample['stimulus']['data'].shape[0]\n",
    "        N = len(dset)\n",
    "        f[f'{dset_name}/betas'] = np.zeros((N, num_betas), dtype='f4')\n",
    "        f[f'{dset_name}/stimulus'] = np.zeros((N, num_stimulus), dtype='f4')\n",
    "        \n",
    "        for i, elem in enumerate(dset):\n",
    "            f[f'{dset_name}/betas'][i] = elem['betas'][0]\n",
    "            f[f'{dset_name}/stimulus'][i] = elem['stimulus']['data']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5df766a-f876-4364-8b5d-8b1ca808b86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load group 1 and 2 results\n",
    "\n",
    "clip_features_path = Path('D:\\\\Datasets\\\\NSD\\\\derivatives\\\\stimulus_embeddings\\\\ViT-B=32-embeddings.hdf5')\n",
    "clip_features = h5py.File(clip_features_path, 'r')\n",
    "\n",
    "clip_decoded_features_path = Path('D:\\\\Datasets\\\\NSD\\\\derivatives\\\\decoded_features\\\\ViT-B=32')\n",
    "group1 = h5py.File(clip_decoded_features_path / 'group-1.hdf5', 'r')\n",
    "group2 = h5py.File(clip_decoded_features_path / 'group-2.hdf5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b6c941-3007-4e08-9620-c7c976081c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the standard decoding evaluation\n",
    "\n",
    "subject = 'subj01'\n",
    "embedding_names = [*(f'transformer.resblocks.{i}' for i in range(12)), 'embedding']\n",
    "results = {}\n",
    "for group_name, group in [('contrastive', group1), ('distance', group2)]:\n",
    "    for embedding_name in tqdm(embedding_names):\n",
    "        for fold_name in ('val_averaged', 'val', 'test_averaged', 'test'):\n",
    "\n",
    "            fold = group[subject][embedding_name][fold_name]\n",
    "            Y_pred = fold['Y_pred'][:]\n",
    "\n",
    "            stimulus_ids = fold['stimulus_ids'][:]\n",
    "            Y = index_unsorted(clip_features[embedding_name], stimulus_ids)\n",
    "\n",
    "            Y, Y_pred = (torch.from_numpy(y).float() for y in (Y, Y_pred))\n",
    "            Y, Y_pred = (y.flatten(start_dim=1) for y in (Y, Y_pred))\n",
    "            nested_insert(results, (group_name, embedding_name), evaluate_decoding(Y, Y_pred, fold_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e04ff37-aa88-42c1-9c1c-39c3b4bd7839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save decoding evaluation\n",
    "json_encoder = CompactJSONEncoder(indent=2)\n",
    "with open('D:\\\\Datasets\\\\NSD\\\\derivatives\\\\results\\\\ViT-B=32\\\\decoding_results_01.json', 'w') as f:\n",
    "    out_str = json_encoder.encode(results)\n",
    "    f.write(out_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8420922-3fd5-419a-a5f7-ab0119ad6c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612394d6-f195-4526-8a1e-9a9081cba19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ('contrastive', 'distance')\n",
    "resblock_embedding_names = [f'transformer.resblocks.{i}' for i in range(12)]\n",
    "embedding_names = [*resblock_embedding_names, 'embedding']\n",
    "fold_name = 'val'\n",
    "\n",
    "r2_scores = np.array(nested_select(results, [group_names, embedding_names, 'r2_score', fold_name]))\n",
    "pearsonr = np.array(nested_select(results, [group_names, embedding_names, 'pearsonr', fold_name]))\n",
    "contrastive_score = np.concatenate([\n",
    "    np.array(nested_select(results, [group_names, resblock_embedding_names, 'mean_squared_distance', 'contrastive_score', fold_name])),\n",
    "    np.array(nested_select(results, [group_names, ['embedding'], 'cosine_distance', 'contrastive_score', fold_name]))\n",
    "], axis=1)\n",
    "\n",
    "def compare_plot(data, title, x_labels, group_names):\n",
    "    num_layers = data.shape[1]\n",
    "    plt.plot(np.arange(num_layers), data[0], label=group_names[0])\n",
    "    plt.plot(np.arange(num_layers), data[1], label=group_names[1])\n",
    "    plt.xticks(np.arange(num_layers), x_labels, rotation='vertical')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "short_embedding_names = [*(f'block {i}' for i in range(12)), 'embedding']\n",
    "compare_plot(r2_scores, \"R2 score\", short_embedding_names, group_names=('contrastive loss', 'distance loss'))\n",
    "compare_plot(pearsonr, \"pearsonr\", short_embedding_names, group_names=('contrastive loss', 'distance loss'))\n",
    "compare_plot(contrastive_score, \"contrastive ranking\", short_embedding_names, group_names=('contrastive loss', 'distance loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048f0bd0-2988-465c-82f4-b38d3894fe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'subj01'\n",
    "embedding_name = f'transformer.resblocks.3'\n",
    "results = {}\n",
    "\n",
    "fold_name = 'val_averaged'\n",
    "\n",
    "fold = group1[subject][embedding_name][fold_name]\n",
    "Y_pred = fold['Y_pred'][:]\n",
    "\n",
    "stimulus_ids = fold['stimulus_ids'][:]\n",
    "Y = index_unsorted(clip_features[embedding_name], stimulus_ids)\n",
    "\n",
    "Y, Y_pred = (torch.from_numpy(y).float() for y in (Y, Y_pred))\n",
    "Y, Y_pred = (y.flatten(start_dim=1) for y in (Y, Y_pred))\n",
    "nested_insert(results, (group_name, embedding_name), evaluate_decoding(Y, Y_pred, fold_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdeab0b-714e-4b26-8d32-95df920d1b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix incorrectly saved stimulus_ids for the non-averaged results\n",
    "\n",
    "clip_decoded_features_path = Path('D:\\\\Datasets\\\\NSD\\\\derivatives\\\\decoded_features\\\\ViT-B=32')\n",
    "\n",
    "for file_name in ('group-1.hdf5', 'group-2.hdf5'):\n",
    "    with h5py.File(clip_decoded_features_path / file_name, 'a') as group:\n",
    "        for embedding in group['subj01'].values():\n",
    "            embedding['test']['stimulus_ids'][:] = np.repeat(embedding['test_averaged']['stimulus_ids'][:], 3)\n",
    "            embedding['val']['stimulus_ids'][:] = np.repeat(embedding['val_averaged']['stimulus_ids'][:], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b7202c-cc6d-4b02-bfd3-851bc34ac222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from research.data.natural_scenes import (\n",
    "    NaturalScenesDataset\n",
    ")\n",
    "\n",
    "dataset_path = Path('D:\\\\Datasets\\\\NSD\\\\')\n",
    "dataset = NaturalScenesDataset(dataset_path)\n",
    "\n",
    "derivatives_path = dataset_path / 'derivatives'\n",
    "betas_path = dataset_path / 'nsddata_betas' / 'ppdata'\n",
    "ppdata_path = dataset_path / 'nsddata' / 'ppdata'\n",
    "subjects = dataset.subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3924df93-03b3-4eda-9cc3-417f1ac0b668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b051b482-3a2b-49c3-836b-a3aa646a53fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_name = 'fracridge'\n",
    "encoder_results = h5py.File(derivatives_path / f'{encoder_name}-parameters.hdf5', 'r')\n",
    "\n",
    "@interact(encoder_subject=encoder_results.items())\n",
    "def select_subject(encoder_subject):\n",
    "    subject_name = encoder_subject.name[1:]\n",
    "    subject = subjects[subject_name]\n",
    "    betas = subject['betas']\n",
    "    roi_names = list(subject['roi_paths'].keys())\n",
    "    print(roi_names)\n",
    "    \n",
    "    @interact(model=encoder_subject.items())\n",
    "    def select_model(model, roi_name=roi_names):\n",
    "        image, label_names = dataset.load_roi(subject_name, roi_name)\n",
    "        image = image.T\n",
    "        \n",
    "        @interact(embedding=model.items())\n",
    "        def select_embedding(embedding):\n",
    "            \n",
    "            r2 = embedding['r2'][:]\n",
    "\n",
    "            @interact(w=(0, r2.shape[0]-1), min_r2=(0., 1.))\n",
    "            def show_top(w, min_r2):\n",
    "                selection_map = r2 > min_r2\n",
    "                label_counts = {\n",
    "                    (label_id, label_name): ((image == label_id) * selection_map).sum()\n",
    "                    for label_id, label_name in label_names.items()\n",
    "                }\n",
    "                label_counts\n",
    "                #print(label_counts)\n",
    "                plt.imshow(selection_map[w].T)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67f5035-d34f-414e-a828-d74135aec084",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_name = 'fracridge'\n",
    "encoder_results = h5py.File(derivatives_path / f'{encoder_name}-parameters.hdf5', 'r')\n",
    "subject_name = 'subj01'\n",
    "model_name = 'ViT-B=32'\n",
    "embedding_name = 'embedding'\n",
    "roi_name = 'prf-visualrois'\n",
    "threshold = 0.2\n",
    "\n",
    "label_image, label_names = dataset.load_roi(subject_name, roi_name)\n",
    "label_image = label_image.T\n",
    "\n",
    "r2 = encoder_results[subject_name][model_name][embedding_name]['r2'][:]\n",
    "\n",
    "def roi_performance(metric_map, threshold, label_image, label_names):\n",
    "    selection_map = metric_map > threshold\n",
    "    label_counts = {\n",
    "        (label_id, label_name): ((label_image == label_id) * selection_map).sum()\n",
    "        for label_id, label_name in label_names.items()\n",
    "    }\n",
    "    label_counts = dict(sorted(label_counts.items(), key=lambda x: x[1], reverse=True))\n",
    "    return label_counts\n",
    "\n",
    "print(roi_name, f'r2 threshold={threshold}')\n",
    "roi_performance(r2, threshold, label_image, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9c7e2c-5588-49bf-a0ee-7dd8e577acbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surfer import Brain\n",
    "%gui qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330acb20-9ae0-4ab5-afa1-a772a49eefee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surfer import Brain\n",
    "from mayavi import mlab\n",
    "mlab.init_notebook(backend='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90052b50-1a5d-4408-8d91-1eabee53dd39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_path = Path('D:\\\\Datasets\\\\NSD\\\\')\n",
    "nsd_surfer_path = dataset_path / 'nsddata' / 'freesurfer'\n",
    "subject_id = 'subj03'\n",
    "hemi = 'lh'\n",
    "\n",
    "surf_path = nsd_surfer_path / subject_id / 'surf'\n",
    "surf_file_names = [p.name for p in surf_path.iterdir() if p.name.startswith(hemi)]\n",
    "\n",
    "@interact(surf_file_name=surf_file_names)\n",
    "def select_surf(surf_file_name):\n",
    "    global brain\n",
    "    surf = '.'.join(surf_file_name.split('.')[1:])\n",
    "    print(surf)\n",
    "    brain = Brain(subject_id, hemi, surf, subjects_dir=nsd_surfer_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a40190-b229-4a51-8684-58f0e56624b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_path = nsd_surfer_path / subject_id / 'mri'\n",
    "label_path  = nsd_surfer_path / subject_id / 'label'\n",
    "overlay_file = label_path / f'{hemi}.R2.mgz'\n",
    "brain.add_overlay(str(overlay_file), min=20, max=50, sign='pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7506495-d061-4bb2-97a7-4cc3d5a0a27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in brain.overlays:\n",
    "    print(k)\n",
    "    brain.overlays[k].remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02f4d9b-c5f4-41f4-b6ee-4110741da0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain.geo[hemi].faces.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a71265-6d21-4692-81a7-a39de92ce4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init map data utility\n",
    "\n",
    "from nsdcode.nsd_mapdata import NSDmapdata\n",
    "\n",
    "dataset_path = Path('D:\\\\Datasets\\\\NSD\\\\')\n",
    "derivatives_path = dataset_path / 'derivatives'\n",
    "nsd = NSDmapdata(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083cd319-5862-43fe-8688-e05ceafdd7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map encoding encoding model result to anat\n",
    "\n",
    "encoder_name = 'fracridge'\n",
    "model_name = 'ViT-B=32'\n",
    "embedding_name = 'embedding'\n",
    "image_name = 'r2'\n",
    "sourcespace = 'func1pt8'\n",
    "targetspace = 'anat0pt8'\n",
    "\n",
    "targetdata = []\n",
    "for i in range(8, 9):\n",
    "    subject_name = f'subj0{i}'\n",
    "    image_file_name = f\"{'__'.join([subject_name, encoder_name, model_name, embedding_name, image_name])}.nii.gz\"\n",
    "    source_path = derivatives_path / 'images' / subject_name / f'{sourcespace}mm' / encoder_name \n",
    "    dest_path = derivatives_path / 'images' / subject_name / f'{targetspace}mm' / encoder_name \n",
    "    dest_path.mkdir(parents=True, exist_ok=True)\n",
    "    targetdata.append(nsd.fit(\n",
    "        i, \n",
    "        sourcespace=sourcespace, \n",
    "        targetspace=targetspace, \n",
    "        sourcedata=str(source_path / image_file_name),\n",
    "        interptype='cubic',\n",
    "        outputfile=str(dest_path / image_file_name),\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043a39fa-17f7-439a-81ce-6ccaabeeccc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map nsdbeta r2 to anat\n",
    "\n",
    "image_name = 'R2'\n",
    "betas_name = 'betas_fithrf_GLMdenoise_RR'\n",
    "sourcespace = 'func1pt8'\n",
    "targetspace = 'anat0pt8'\n",
    "\n",
    "targetdata = []\n",
    "for i in range(1, 9):\n",
    "    subject_name = f'subj0{i}'\n",
    "    image_file_name = f\"{image_name}_{betas_name}_{sourcespace}_to_{targetspace}.nii.gz\"\n",
    "    source_path = dataset_path / 'nsddata_betas' / 'ppdata' / subject_name\n",
    "    source_path = source_path / f'{sourcespace}mm' / betas_name / f'{image_name}.nii.gz'\n",
    "    dest_path = derivatives_path / 'images' / f'{targetspace}mm'\n",
    "    dest_path.mkdir(parents=True, exist_ok=True)\n",
    "    targetdata.append(nsd.fit(\n",
    "        i, \n",
    "        sourcespace=sourcespace, \n",
    "        targetspace=targetspace, \n",
    "        sourcedata=str(source_path),\n",
    "        interptype='cubic',\n",
    "        outputfile=str(dest_path / image_file_name),\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9341381a-ee4f-4aec-a438-67f6d3c8bf9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b919740a-86f7-4155-bac4-27835e04d120",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "#image_name = 'R2'\n",
    "#betas_name = 'betas_fithrf_GLMdenoise_RR'\n",
    "#sourcespace = 'func1pt8'\n",
    "#def source_path(subject_name):\n",
    "#    return str(dataset_path / f'nsddata_betas/ppdata/{subject_name}/{sourcespace}mm/{betas_name}/{image_name}.nii.gz')\n",
    "\n",
    "#encoder_name = 'fracridge'\n",
    "encoder_name = 'pytorch'\n",
    "group_name = 'group-1'\n",
    "model_name = 'ViT-B=32'\n",
    "embedding_name = 'embedding'\n",
    "image_name = 'r2'\n",
    "sourcespace = 'func1pt8'\n",
    "\n",
    "def source_path(subject_name):\n",
    "    image_file_keys = [subject_name, encoder_name, group_name, model_name, embedding_name, image_name]\n",
    "    image_file_name = f\"{'__'.join(image_file_keys)}.nii.gz\"\n",
    "    image_folder_path = derivatives_path / 'images' / subject_name / f'{sourcespace}mm' / encoder_name \n",
    "    return str(image_folder_path / image_file_name)\n",
    "\n",
    "hemis = ['lh', 'rh']\n",
    "target_spaces = ['white', 'layerB3', 'layerB2', 'layerB1', 'pial']\n",
    "subjects = [(i, f'subj0{i}') for i in range(1, 9)]\n",
    "\n",
    "#image_file_name = f\"{image_name}_{betas_name}_{sourcespace}_to_{targetspace}.nii.gz\"\n",
    "#dest_path = derivatives_path / 'images' / f'{targetspace}mm'\n",
    "#dest_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "subject_space_results = {\n",
    "    subject_name: {\n",
    "        hemi: {\n",
    "            target_space: nsd.fit(\n",
    "                subject_id, \n",
    "                sourcespace=sourcespace, \n",
    "                targetspace=f'{hemi}.{target_space}', \n",
    "                sourcedata=source_path(subject_name),\n",
    "                interptype='cubic',\n",
    "            )\n",
    "            for target_space in target_spaces\n",
    "        }\n",
    "        for hemi in hemis\n",
    "    }\n",
    "    for subject_id, subject_name in subjects\n",
    "}\n",
    "\n",
    "fsaverage_space_results = {\n",
    "    subject_name: {\n",
    "        hemi: {\n",
    "            target_space: nsd.fit(\n",
    "                subject_id, \n",
    "                sourcespace=f'{hemi}.white', \n",
    "                targetspace='fsaverage', \n",
    "                sourcedata=subject_space_results[subject_name][hemi][target_space],\n",
    "                interptype='cubic',\n",
    "            )\n",
    "            for target_space in target_spaces\n",
    "        }\n",
    "        for hemi in hemis\n",
    "    }\n",
    "    for subject_id, subject_name in subjects\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e75d093-110f-45ba-bc85-c996044357d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for subject_id, subject_name in subjects:\n",
    "    for hemi in hemis:\n",
    "        print({(k, v.shape) for k, v in subject_space_results[subject_name][hemi].items()})\n",
    "        print({(k, v.shape) for k, v in fsaverage_space_results[subject_name][hemi].items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2d6e65-512a-4f1b-918d-19fd2ab4e936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.utils import read_patch\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "lh_flat = read_patch(dataset_path / 'nsddata/freesurfer/fsaverage/surf/lh.full.flat.patch.3d')\n",
    "rh_flat = read_patch(dataset_path / 'nsddata/freesurfer/fsaverage/surf/rh.full.flat.patch.3d')\n",
    "\n",
    "print(f\"{lh_flat['x'].min()=}, {lh_flat['x'].max()=}\")\n",
    "print(f\"{lh_flat['y'].min()=}, {lh_flat['y'].max()=}\")\n",
    "print(f\"{rh_flat['x'].min()=}, {rh_flat['x'].max()=}\")\n",
    "print(f\"{rh_flat['y'].min()=}, {rh_flat['y'].max()=}\")\n",
    "\n",
    "def make_flat(hemi_data, hemi_flat, shape):\n",
    "    hemi_data = hemi_data[hemi_flat['vno']]\n",
    "    \n",
    "    points = np.stack([hemi_flat['x'], hemi_flat['y']], axis=-1)\n",
    "    values = hemi_data\n",
    "    grid = np.stack(np.meshgrid(\n",
    "        np.linspace(-160, 160, shape[0]), \n",
    "        np.linspace(-160, 160, shape[1])\n",
    "    ), axis=-1).reshape(shape[0] * shape[1], 2)\n",
    "    result = griddata(points, values, grid)\n",
    "    return result.reshape(*shape)\n",
    "\n",
    "@interact(subject=subjects, layer=target_spaces)\n",
    "def flat_plot(subject, layer):\n",
    "    global lh_data, rh_data\n",
    "    \n",
    "    lh_data = fsaverage_space_results[subject]['lh'][layer]\n",
    "    rh_data = fsaverage_space_results[subject]['rh'][layer]\n",
    "    \n",
    "    lh_data = make_flat(lh_data, lh_flat, shape=(3200, 3200))\n",
    "    \n",
    "    print(lh_data.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1028dd9b-3ae3-4e47-9c8b-cccf898815df",
   "metadata": {},
   "outputs": [],
   "source": [
    "lh_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d00a3dc-a21b-4ba0-ad22-c63a16a581bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(subject=subjects, layer=target_spaces)\n",
    "def flat_scatter_plot(subject, layer):\n",
    "    #global lh_data, rh_data\n",
    "    \n",
    "    lh_data = fsaverage_space_results[subject]['lh'][layer]\n",
    "    rh_data = fsaverage_space_results[subject]['rh'][layer]\n",
    "    \n",
    "    spread = 140\n",
    "    y_diff = np.max(rh_flat['y']) - np.max(lh_flat['y'])\n",
    "    x = np.concatenate([lh_flat['x'] - spread, rh_flat['x'] + spread])\n",
    "    y = np.concatenate([lh_flat['y'], rh_flat['y'] - y_diff])\n",
    "    c = np.concatenate([lh_data[lh_flat['vno']], rh_data[rh_flat['vno']]])\n",
    "    \n",
    "    xmin, xmax = np.min(x), np.max(x)\n",
    "    ymin, ymax = np.min(y), np.max(y)\n",
    "    xsize = xmax - xmin\n",
    "    ysize = ymax - ymin\n",
    "    \n",
    "    scale = 0.05\n",
    "    plt.figure(figsize=(xsize * scale, ysize * scale))\n",
    "    plt.xlim(xmin, xmax)\n",
    "    plt.ylim(ymin, ymax)\n",
    "    padding=5\n",
    "    fontsize=25\n",
    "    plt.text(xmin+padding, ymin+padding, f'{layer=}\\n{subject=}', \n",
    "             horizontalalignment='left', verticalalignment='bottom', fontsize=fontsize)\n",
    "    plt.text(xmax-padding, ymin+padding, f'{image_name=}\\n{model_name=}\\n{embedding_name=}', \n",
    "             horizontalalignment='right', verticalalignment='bottom', fontsize=fontsize)\n",
    "    plt.tick_params(axis='both', which='both', bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "    plt.scatter(x, y, s=5, c=c, cmap='jet', vmin=0.0, vmax=0.5, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f857262-8fdf-4719-9262-1db2a9a16152",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for subject_id, subject_name in subjects:\n",
    "    for layer_name in target_spaces:\n",
    "        file_name = '__'.join([subject_name, layer_name, encoder_name, model_name, embedding_name, image_name]) + '.png'\n",
    "        out_path = dataset_path / f'derivatives/inspections/{subject_name}/{embedding_name}'\n",
    "        out_path.mkdir(exist_ok=True, parents=True)\n",
    "        flat_scatter_plot(subject_name, layer_name)\n",
    "        plt.savefig(out_path / file_name, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42197532-f0ea-4011-bcc4-9efbfb0e6e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.help(imageio.mimsave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57342e97-768d-45ae-8ee4-847268b64af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "from glob import glob\n",
    "\n",
    "image_paths = []\n",
    "for subject_id, subject_name in subjects:\n",
    "    for layer_name in target_spaces:\n",
    "        path = str(dataset_path / f'derivatives/inspections/{subject_name}/embedding/{subject_name}__{layer_name}*')\n",
    "        image_paths.append(glob(path)[0])\n",
    "imageio.mimsave(\n",
    "    dataset_path / 'derivatives/inspections/custom/all__fracridge__ViT-B=32__embedding__r2.gif', \n",
    "    [imageio.imread(im_path) for im_path in image_paths],\n",
    "    fps=1,\n",
    ")\n",
    "\n",
    "image_paths = []\n",
    "for subject_id, subject_name in subjects:\n",
    "    path = str(dataset_path / f'derivatives/inspections/{subject_name}/embedding/{subject_name}__pial*')\n",
    "    image_paths.append(glob(path)[0])\n",
    "imageio.mimsave(\n",
    "    dataset_path / 'derivatives/inspections/custom/pial__fracridge__ViT-B=32__embedding__r2.gif', \n",
    "    [imageio.imread(im_path) for im_path in image_paths],\n",
    "    fps=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2d22d6-ede3-4f6d-b8e5-fd4454701f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = []\n",
    "path = str(dataset_path / f'nsddata/inspections/surfacevisualizations/fsaverageflat_b*nc_groupavg.png')\n",
    "image_paths = glob(path)\n",
    "\n",
    "imageio.mimsave(\n",
    "    dataset_path / 'derivatives/inspections/custom/glm_improvement.gif', \n",
    "    [imageio.imread(im_path) for im_path in image_paths],\n",
    "    fps=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cb8e59-592f-48c3-a187-322609a04c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.stack(np.meshgrid(\n",
    "        np.linspace(-160, 160, shape[0]), \n",
    "        np.linspace(-160, 160, shape[1])\n",
    "    )).reshape(shape[0] * shape[1], 2)\n",
    "grid[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9768621b-7d94-40c9-b46b-052c1a8970ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lh_data[~np.isnan(lh_data)].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7c54f0-925b-48d8-9917-d532540f45f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(lh_data, vmin=0, vmax=50, cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a750bdc-7c25-44e8-9d86-61c95b3c0e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape=(1600, 1600)\n",
    "grid = np.stack(np.meshgrid(\n",
    "    np.linspace(-160, 160, shape[0]), \n",
    "    np.linspace(-160, 160, shape[1])\n",
    "))\n",
    "grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c96ecf-9dc2-4320-96e9-071e383454c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1df4df7-6bb6-43b1-9f3e-1af707f59cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create white matter masks\n",
    "\n",
    "spaces = ['func1pt8mm', 'func1mm']\n",
    "for space in spaces:\n",
    "    for i in range(1, 9):\n",
    "        subject_name = f'subj0{i}'\n",
    "        source_path = dataset_path / 'nsddata' / 'ppdata' / subject_name / space / 'aseg.nii.gz'\n",
    "        dest_path = dataset_path / 'derivatives' / 'images' / subject_name / space\n",
    "        dest_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        source_image = nib.load(source_path)\n",
    "        source_data = source_image.get_fdata().astype(int)\n",
    "        dest_data = ((source_data == 3) | (source_data == 42)) * 1\n",
    "        dest_image = nib.Nifti1Image(dest_data, source_image.affine, source_image.header)\n",
    "        nib.save(dest_image, dest_path / 'wm.nii.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1e0a18-46f8-4d5a-bd5c-58103be38e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create masks for\n",
    "\n",
    "betas_name = 'betas_fithrf_GLMdenoise_RR'\n",
    "space = 'func1pt8'\n",
    "\n",
    "i = 1\n",
    "subject_name = f'subj0{i}'\n",
    "func_path = dataset_path / 'nsddata' / 'ppdata' / subject_name / f'{space}mm'\n",
    "betas_path = dataset_path / 'nsddata_betas' / 'ppdata' / subject_name / f'{space}mm' / betas_name\n",
    "\n",
    "t1_image = nib.load(func_path / f'T1_to_{space}mm.nii.gz')\n",
    "r2_image = nib.load(betas_path / 'R2.nii.gz')\n",
    "ncsnr_image = nib.load(betas_path / 'ncsnr.nii.gz')\n",
    "\n",
    "r2 = np.nan_to_num(r2_image.get_fdata())\n",
    "ncsnr = np.nan_to_num(ncsnr_image.get_fdata())\n",
    "nc = ncsnr ** 2 / (ncsnr ** 2 + 1) * 100.\n",
    "print(nc.max(), nc.min())\n",
    "t1 = t1_image.get_fdata()\n",
    "H, W, D = r2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8813e7ab-2dde-426a-9329-2ac339c5b03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(r2_t=(0., 100.), nc_t=(0., 100.), d=(0, D-1))\n",
    "def show_threshold(r2_t, nc_t, d):\n",
    "    global mask\n",
    "    mask = (r2 > r2_t) & (nc > nc_t)\n",
    "    #print(mask.sum())\n",
    "    masked_r2 = r2 * mask\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(mask[:, :, d], cmap='jet', vmin=0, vmax=1.)\n",
    "#dest_path = derivatives_path / 'images' / f'{targetspace}mm'\n",
    "#dest_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf9344e-c2aa-4fed-a8d3-547cdf4574b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save noise ceilings for voxel selection\n",
    "\n",
    "betas_name = 'betas_fithrf_GLMdenoise_RR'\n",
    "space = 'func1pt8'\n",
    "\n",
    "def require_dataset(group, name, data):\n",
    "    group.require_dataset(name, shape=data.shape, dtype=data.dtype)\n",
    "    group[name][:] = data\n",
    "\n",
    "with h5py.File(dataset_path / 'derivatives' / 'voxel-selection.hdf5', 'a') as f:\n",
    "    for i in range(1, 9):\n",
    "        subject_name = f'subj0{i}'\n",
    "        func_path = dataset_path / 'nsddata' / 'ppdata' / subject_name / f'{space}mm'\n",
    "        betas_path = dataset_path / 'nsddata_betas' / 'ppdata' / subject_name / f'{space}mm' / betas_name\n",
    "\n",
    "        r2_image = nib.load(betas_path / 'R2.nii.gz')\n",
    "        ncsnr_image = nib.load(betas_path / 'ncsnr.nii.gz')\n",
    "        \n",
    "        r2 = np.nan_to_num(r2_image.get_fdata()).astype(float).T\n",
    "        ncsnr = np.nan_to_num(ncsnr_image.get_fdata()).astype(float).T\n",
    "        nc = ncsnr ** 2 / (ncsnr ** 2 + 1) * 100.\n",
    "        \n",
    "        grid = np.argwhere(np.ones_like(r2, dtype=bool))\n",
    "        \n",
    "        r2_sorted_indices_flat = r2.argsort(axis=None)[::-1].astype(int)\n",
    "        nc_sorted_indices_flat = nc.argsort(axis=None)[::-1].astype(int)\n",
    "        r2_sorted_indices = grid[r2_sorted_indices_flat].astype(int)\n",
    "        nc_sorted_indices = grid[nc_sorted_indices_flat].astype(int)\n",
    "        \n",
    "        group = f.require_group(subject_name)\n",
    "        \n",
    "        require_dataset(group, 'r2/value', r2)\n",
    "        require_dataset(group, 'r2/sorted_indices_flat', r2_sorted_indices_flat)\n",
    "        require_dataset(group, 'r2/sorted_indices', r2_sorted_indices)\n",
    "        \n",
    "        require_dataset(group, 'nc/value', nc)\n",
    "        require_dataset(group, 'nc/sorted_indices_flat', nc_sorted_indices_flat)\n",
    "        require_dataset(group, 'nc/sorted_indices', nc_sorted_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce536e6-f842-4c12-9085-e90584c266d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "fig = plt.subplots(figsize=(6, 5))\n",
    "plt.hist2d(r2.flatten(), nc.flatten(), range=[[0, 100], [0, 100]], bins=(20, 20), cmap='jet', norm=mpl.colors.LogNorm())\n",
    "plt.title(\"2D Histrogram of Voxels\\nNoise Ceiling vs R^2 - Subject 1\")\n",
    "plt.ylabel(\"Noise Ceiling\")\n",
    "plt.xlabel(\"R^2\")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4f9373-4e67-4c07-ab37-def8080ca243",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25754cb9-afee-474f-8855-7110f1ef30d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2.flatten()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro-decode",
   "language": "python",
   "name": "neuro-decode"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
