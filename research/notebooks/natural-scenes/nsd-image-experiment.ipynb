{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ccd05f9-017e-4422-9888-52d38a44e125",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import gc\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import h5py\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import nibabel as nib\n",
    "from einops import rearrange\n",
    "from scipy import ndimage\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "dir2 = os.path.abspath('../..')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: \n",
    "    sys.path.append(dir1)\n",
    "    \n",
    "from research.data.natural_scenes import NaturalScenesDataset\n",
    "from research.experiments.nsd.nsd_access import NSDAccess\n",
    "from research.metrics.metrics import cosine_distance, top_knn_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a56427fc-7e98-40fe-a321-e91a7b2a7d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsd_path = Path('D:\\\\Datasets\\\\NSD\\\\')\n",
    "nsd = NaturalScenesDataset(nsd_path, coco_path='X:\\\\Datasets\\\\COCO')\n",
    "stimuli_path = nsd_path / 'nsddata_stimuli' / 'stimuli' / 'nsd' / 'nsd_stimuli.hdf5'\n",
    "stimulus_images = h5py.File(stimuli_path, 'r')['imgBrick']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c2e4770-b30c-41ad-9036-70a9f29b5983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_images(images, captions, embeddings, image_id, thresholds, shuffle=True):\n",
    "    N = embeddings.shape[0]\n",
    "    distances, nearest_image_ids = neighbors.kneighbors(embeddings[image_id, None], n_neighbors=N)\n",
    "    distances, nearest_image_ids = distances[0], nearest_image_ids[0]\n",
    "\n",
    "    t_id = 0\n",
    "    k_values = [0]\n",
    "    for k, d in enumerate(distances):\n",
    "        if t_id >= len(thresholds):\n",
    "            break\n",
    "        if d > thresholds[t_id]:\n",
    "            k_values.append(k)\n",
    "            t_id += 1\n",
    "\n",
    "    similar_images = []\n",
    "    for k in k_values:\n",
    "        near_image_id = nearest_image_ids[k]\n",
    "        similar_images.append({\n",
    "            'image': stimulus_images[near_image_id], \n",
    "            'caption': str(captions[near_image_id]),\n",
    "            'cosine_distance': float(distances[k]),\n",
    "            'stim_id': int(near_image_id),\n",
    "            'k': int(k)\n",
    "        })\n",
    "\n",
    "    if shuffle:\n",
    "        shuffle_ids = np.arange(len(similar_images))\n",
    "        np.random.shuffle(shuffle_ids)\n",
    "        similar_images = [similar_images[i] for i in shuffle_ids]\n",
    "\n",
    "    return similar_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de19dd7d-95c3-4681-9b15-afd2a84c02cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73000, 5)\n",
      "[[0.3166824  0.29903737 0.2705831  0.26404428 0.3248881 ]\n",
      " [0.3135147  0.29028302 0.30885544 0.29989666 0.2975764 ]\n",
      " [0.35390684 0.2882279  0.3490643  0.35402402 0.32551354]\n",
      " ...\n",
      " [0.28977567 0.2876259  0.29651064 0.30269492 0.31399542]\n",
      " [0.31555313 0.31223205 0.30614698 0.3007291  0.26928315]\n",
      " [0.29240453 0.28594497 0.32062352 0.29156315 0.2844131 ]]\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016000747680664062,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 11,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 73000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb8c4abadc3b43f1a356935513c0acd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = 'ViT-B=32'\n",
    "stimulus_key = 'embedding'\n",
    "\n",
    "save_key = stimulus_key\n",
    "save_model_name = model_name\n",
    "\n",
    "stimulus_file = h5py.File(nsd_path / f'derivatives/stimulus_embeddings/{model_name}.hdf5', 'r')\n",
    "x = stimulus_file[stimulus_key][:]\n",
    "\n",
    "stimulus_file_text = h5py.File(nsd_path / f'derivatives/stimulus_embeddings/{model_name}-text.hdf5', 'r')\n",
    "x_text = stimulus_file_text[stimulus_key][:]\n",
    "x_text = x_text / np.linalg.norm(x_text, axis=-1, keepdims=True)\n",
    "\n",
    "ids = np.stack([np.arange(73000) for _ in range(5)], axis=-1)\n",
    "print(ids.shape)\n",
    "\n",
    "#random_ids = np.arange(73000)\n",
    "#np.random.shuffle(random_ids)\n",
    "#print(random_ids)\n",
    "#x_text = x_text[random_ids]\n",
    "\n",
    "text_dists = np.einsum('ni,nti->nt', x, x_text)\n",
    "print(text_dists)\n",
    "\n",
    "neighbors = NearestNeighbors(metric='cosine')\n",
    "neighbors.fit(x)\n",
    "\n",
    "all_captions = np.array([nsd.load_coco(i)[:5] for i in tqdm(range(73000))])\n",
    "best_captions = all_captions[np.arange(73000), np.argmax(text_dists, axis=1)]\n",
    "\n",
    "#top_knn_test(x, x_text.reshape(-1, 512), ids.flatten(), k=[1, 5, 10], metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4fe28cc-8bde-4eeb-9da9-44b2ae6d47c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b7aea537e54b13b059463ac65b83fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Checkbox(value=False, description='ground_truth_reconstructions'), Dropdown(description=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Results viewer\n",
    "\n",
    "model_name = 'clip-vit-large-patch14-text'\n",
    "\n",
    "fold_subset = 'special100'\n",
    "subset_file = nsd_path / f'nsddata/stimuli/nsd/{fold_subset}.tsv'\n",
    "subset_stimulus_ids = (np.array(pd.read_csv(subset_file, header=None)[0]) - 1).tolist()\n",
    "\n",
    "def get_stim_id(p: Path):\n",
    "    return int(p.name.split('_')[1].split('-')[1])\n",
    "\n",
    "groups = ['group-5', 'group-6']\n",
    "run_names = [f'run-002', 'run-003', 'run-004', 'run-005']\n",
    "subjects = [f'subj0{i}' for i in range(1, 9)]\n",
    "modes = ['Ground Truth', 'Image Experiment', 'Caption Experiment']\n",
    "\n",
    "rois = ['', 'Primary_Visual', 'Early_Visual', 'Dorsal_Stream_Visual', 'Ventral_Stream_Visual',\n",
    "        'MT+_Complex_and_Neighboring_Visual_Areas', 'Medial_Temporal', 'Lateral_Temporal',\n",
    "        'Temporo-Parieto-Occipital_Junction', 'Superior_Parietal', 'Inferior_Parietal',\n",
    "        'Posterior_Cingulate', 'Frontal']\n",
    "\n",
    "@interact(ground_truth_reconstructions=False, \n",
    "          run_name=run_names, \n",
    "          subject=(1, 8), \n",
    "          stim_id=subset_stimulus_ids, \n",
    "          mode=modes,\n",
    "          group_name=groups,\n",
    "          options=[2, 5],\n",
    "          roi=rois)\n",
    "def select(ground_truth_reconstructions, run_name, subject, stim_id, mode, group_name, options, roi):\n",
    "    subject = subjects[subject-1]\n",
    "    if ground_truth_reconstructions:\n",
    "        reconstructions_path = nsd_path / f'derivatives/reconstructions/{model_name}/ground_truth/run-001/images'\n",
    "    else:\n",
    "        reconstructions_path = nsd_path / f'derivatives/reconstructions/{model_name}/{group_name}/{run_name}/{subject}/{roi}/images'\n",
    "    reconstruction_files = [p for p in reconstructions_path.iterdir() if p.name != 'desktop.ini']\n",
    "    reconstruction_files.sort(key=get_stim_id)\n",
    "    stimulus_ids = np.array([get_stim_id(p) for p in reconstruction_files])\n",
    "    unique_stimulus_ids = np.unique(stimulus_ids)\n",
    "\n",
    "    neighbors = NearestNeighbors(metric='cosine')\n",
    "    neighbors.fit(x)\n",
    "\n",
    "    recon_ids = np.where(stimulus_ids == stim_id)[0]\n",
    "    if recon_ids.shape[0] < 1:\n",
    "        print(f'Stim id {stim_id} not presented to {subject}.')\n",
    "        return\n",
    "    reconstruction_img = [\n",
    "        np.array(Image.open(reconstruction_files[recon_id]))\n",
    "        for recon_id in recon_ids\n",
    "    ]\n",
    "    if len(reconstruction_img) == 3:\n",
    "        reconstruction_img = np.concatenate(reconstruction_img, axis=1)\n",
    "    elif len(reconstruction_img) == 9:\n",
    "        reconstruction_img = np.concatenate([\n",
    "            np.concatenate(reconstruction_img[:3], axis=1),\n",
    "            np.concatenate(reconstruction_img[3:6], axis=1),\n",
    "            np.concatenate(reconstruction_img[6:], axis=1),\n",
    "        ], axis=0)\n",
    "    \n",
    "    print(\"Computer generated images:\")\n",
    "    plt.figure(figsize=(9, 9))\n",
    "    plt.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n",
    "    plt.imshow(reconstruction_img)\n",
    "    plt.show()\n",
    "    \n",
    "    ground_truth_img = stimulus_images[stim_id]\n",
    "    captions = nsd.load_coco(stim_id)\n",
    "    \n",
    "    if mode == 'Ground Truth':\n",
    "        print(\"Original stimulus\")\n",
    "        plt.figure(figsize=(3, 3))\n",
    "        plt.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n",
    "        plt.imshow(ground_truth_img)\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Stimulus captions\")\n",
    "        for i, c in enumerate(captions):\n",
    "            print(f'caption_similarity={text_dists[stim_id, i]:.2f}', c)\n",
    "        return\n",
    "    \n",
    "    else:\n",
    "        if options == 2:\n",
    "            thresholds = [0.3]\n",
    "        elif options == 5:\n",
    "            thresholds = [0.3, 0.4, 0.5, 0.6]\n",
    "        similar_images = get_similar_images(\n",
    "            images=stimulus_images, \n",
    "            captions=best_captions, \n",
    "            embeddings=x, \n",
    "            image_id=stim_id, \n",
    "            thresholds=thresholds,\n",
    "            shuffle=True\n",
    "        )\n",
    "        \n",
    "        if mode == 'Image Experiment':\n",
    "            print(\"Choose the image that is most similar to the computer generated images.\")\n",
    "            fsize = (len(thresholds) + 1) * 3\n",
    "            plt.figure(figsize=(fsize, fsize))\n",
    "            plt.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n",
    "            plt.imshow(np.concatenate([similar_image['image'] for similar_image in similar_images], axis=1))\n",
    "            plt.show()\n",
    "            \n",
    "            @interact(show_ans=False)\n",
    "            def show(show_ans):\n",
    "                if show_ans:\n",
    "                    for i, similar_image in enumerate(similar_images):\n",
    "                        tag = '(ANSWER)' if similar_image['k'] == 0 else f'd={similar_image[\"cosine_distance\"]:.2f}'\n",
    "                        print(f'Image {i + 1}, caption: \"{similar_image[\"caption\"]}\" {tag}')\n",
    "                            \n",
    "        if mode == 'Caption Experiment':\n",
    "            print(\"Choose the sentence that best describes the computer generated images.\")\n",
    "            @interact(show_ans=False)\n",
    "            def show(show_ans):\n",
    "                for i, similar_image in enumerate(similar_images):\n",
    "                    if show_ans:\n",
    "                        tag = '(ANSWER)' if similar_image['k'] == 0 else f'd={similar_image[\"cosine_distance\"]:.2f}'\n",
    "                    else:\n",
    "                        tag = ''\n",
    "                    print(f'{i+1}) {similar_image[\"caption\"]} {tag}')\n",
    "\n",
    "            \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd352fc9-5302-4d82-899f-8b38d954a08b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clip-vit-large-patch14-text/group-5/run-003/subj01 80\n",
      "clip-vit-large-patch14-text/group-5/run-003/subj02 80\n",
      "clip-vit-large-patch14-text/group-5/run-003/subj03 79\n",
      "clip-vit-large-patch14-text/group-5/run-003/subj04 78\n",
      "clip-vit-large-patch14-text/group-5/run-003/subj05 81\n",
      "clip-vit-large-patch14-text/group-5/run-003/subj06 80\n",
      "clip-vit-large-patch14-text/group-5/run-003/subj07 80\n",
      "clip-vit-large-patch14-text/group-5/run-003/subj08 78\n"
     ]
    }
   ],
   "source": [
    "# Generate CSV data for MTurk experiments\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "model_name = 'clip-vit-large-patch14-text'\n",
    "group_name = 'group-5'\n",
    "run_names = ['run-003']\n",
    "subjects = [f'subj0{i}' for i in range(1, 9)]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for run_name in run_names:\n",
    "    for subject in subjects:\n",
    "        API_KEY = 'AIzaSyCsVkNto4IU5yX2pOSeguqknNgbOlDvoVU'\n",
    "        service = build('drive', 'v3', developerKey=API_KEY)\n",
    "\n",
    "        folder_id = '18-b4AWlYcR5njrkVAVakqn8AiYx_a8Dj'\n",
    "        \n",
    "        query_shared = {\n",
    "            \"includeItemsFromAllDrives\": True,\n",
    "            \"supportsAllDrives\": True,\n",
    "            \"fields\": \"*\"\n",
    "        }\n",
    "        \n",
    "        for folder_name in (model_name, group_name, run_name, subject, 'merged'):\n",
    "            result = service.files().list(\n",
    "                q=f\"'{folder_id}' in parents\",\n",
    "                pageToken=None,\n",
    "                **query_shared\n",
    "            ).execute()\n",
    "            files = result.get('files')\n",
    "            \n",
    "            for file in files:\n",
    "                if file['name'] == folder_name:\n",
    "                    folder_id = file['id']\n",
    "                    break\n",
    "        images = []\n",
    "        next_page_token = None\n",
    "        while True:\n",
    "            result = service.files().list(\n",
    "                q=f\"'{folder_id}' in parents\", \n",
    "                pageToken=next_page_token,\n",
    "                **query_shared\n",
    "            ).execute()\n",
    "            images += result.get(\"files\")\n",
    "            next_page_token = result.get(\"nextPageToken\")\n",
    "            if next_page_token is None:\n",
    "                break\n",
    "        key = '/'.join((model_name, group_name, run_name, subject))\n",
    "        results[key] = {\n",
    "            int(img['name'].split('_')[1].split('-')[1].split('.')[0]): img['id']\n",
    "            for img in images\n",
    "        }\n",
    "        print(key, len(images))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fa68be50-153f-4285-968c-9bdf27e833e1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n"
     ]
    }
   ],
   "source": [
    "# Save all of the google ids for ground truth images.\n",
    "\n",
    "folder_id = '1tzk0iMAYLjo6LeOu5iR-Oz-oPKqs48n7'\n",
    "images = []\n",
    "next_page_token = None\n",
    "while True:\n",
    "    result = service.files().list(\n",
    "        q=f\"'{folder_id}' in parents\", \n",
    "        pageToken=next_page_token,\n",
    "        **query_shared\n",
    "    ).execute()\n",
    "    images += result.get(\"files\")\n",
    "    next_page_token = result.get(\"nextPageToken\")\n",
    "    if next_page_token is None:\n",
    "        break\n",
    "    if len(images) % 1000 == 0:\n",
    "        print(len(images))\n",
    "gt_google_ids = {\n",
    "    int(img['name'].split('.')[0]): img['id']\n",
    "    for img in images if img['name'].endswith('png')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "784c342a-d575-42e7-8825-66b0c5eab1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(nsd_path / 'derivatives/stim_google_ids.json', 'w') as f:\n",
    "    f.write(json.dumps(gt_google_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2740f31-af7b-4eda-b256-242ab72b1c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(nsd_path / 'derivatives/stim_google_ids.json', 'r') as f:\n",
    "    gt_google_ids = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "80ef0e46-cb4a-4afb-a515-6f2eee2aeb6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subj01 run-003\n",
      "subj02 run-003\n",
      "subj03 run-003\n",
      "subj04 run-003\n",
      "subj05 run-003\n",
      "subj06 run-003\n",
      "subj07 run-003\n",
      "subj08 run-003\n"
     ]
    }
   ],
   "source": [
    "# Generate CSV files for tasks.\n",
    "import json\n",
    "\n",
    "task_version = 'version-2'\n",
    "\n",
    "stimuli_path = nsd_path / 'nsddata_stimuli' / 'stimuli' / 'nsd' / 'nsd_stimuli.hdf5'\n",
    "stimulus_images = h5py.File(stimuli_path, 'r')['imgBrick']\n",
    "\n",
    "for run_name in run_names:\n",
    "    for subject in subjects:\n",
    "        print(subject, run_name)\n",
    "        key = f'{model_name}/{group_name}/{run_name}/{subject}'\n",
    "        drive_ids = results[key]\n",
    "        \n",
    "        img_url = 'https://drive.google.com/uc?id={}&export=view'\n",
    "        \n",
    "        task2_txt = 'key_image_url,comparison_image_urls\\n'\n",
    "        #task3_txt = 'image_url,A,B,C,D,E\\n'\n",
    "        task3_txt = 'image_url,A,B\\n'\n",
    "        \n",
    "        all_images = []\n",
    "        for stim_id, drive_id in drive_ids.items():\n",
    "            similar_images = get_similar_images(\n",
    "                images=stimulus_images, \n",
    "                captions=best_captions, \n",
    "                embeddings=x, \n",
    "                image_id=stim_id, \n",
    "                thresholds=[0.3,],# 0.4, 0.5, 0.6],\n",
    "                shuffle=True\n",
    "            )\n",
    "            for img in similar_images:\n",
    "                del img['image']\n",
    "            all_images.append(similar_images)\n",
    "            generated_img_url = img_url.format(drive_id)\n",
    "            captions = [img[\"caption\"].replace(\"\\\"\", \"\\'\") for img in similar_images]\n",
    "            captions = [f'\"{caption}\"' for caption in captions]\n",
    "            comparison_img_urls = [\n",
    "                img_url.format(gt_google_ids[str(img['stim_id'])])\n",
    "                for img in similar_images\n",
    "            ]\n",
    "            \n",
    "            task2_txt += f'{generated_img_url},\"{str(comparison_img_urls)}\"\\n'\n",
    "            task3_txt += f\"{generated_img_url},{','.join(captions)}\\n\"\n",
    "        \n",
    "        with open(nsd_path / f'derivatives/reconstructions/{key}/task2_{task_version}.csv', 'w') as f:\n",
    "            f.write(task2_txt)\n",
    "        with open(nsd_path / f'derivatives/reconstructions/{key}/task3_{task_version}.csv', 'w') as f:\n",
    "            f.write(task3_txt)\n",
    "        with open(nsd_path / f'derivatives/reconstructions/{key}/task_{task_version}_info.json', 'w') as f:\n",
    "            f.write(json.dumps(all_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "555b8d40-16bb-4c20-b4a9-ef3ae9e83b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create merged images for MTurk\n",
    "model_name = 'clip-vit-large-patch14-text'\n",
    "group_name = 'group-5'\n",
    "run_names = ['run-002', 'run-003']\n",
    "subjects = [f'subj0{i}' for i in range(1, 9)]\n",
    "\n",
    "for run_name in run_names:\n",
    "    for subject in subjects:\n",
    "        reconstructions_path = nsd_path / f'derivatives/reconstructions/{model_name}/{group_name}/{run_name}/{subject}/images'\n",
    "        reconstruction_files = [p for p in reconstructions_path.iterdir() if p.name != 'desktop.ini']\n",
    "        reconstruction_files.sort(key=get_stim_id)\n",
    "        stimulus_ids = np.array([get_stim_id(p) for p in reconstruction_files])\n",
    "        unique_stimulus_ids = np.unique(stimulus_ids)\n",
    "        \n",
    "        for stim_id in unique_stimulus_ids:\n",
    "            recon_ids = np.where(stimulus_ids == stim_id)[0]\n",
    "            reconstruction_img = np.concatenate([\n",
    "                np.array(Image.open(reconstruction_files[recon_id]))\n",
    "                for recon_id in recon_ids\n",
    "            ], axis=1)\n",
    "\n",
    "            merged_path = nsd_path / f'derivatives/reconstructions/{model_name}/{group_name}/{run_name}/{subject}/merged'\n",
    "            merged_path.mkdir(exist_ok=True, parents=True)\n",
    "            Image.fromarray(reconstruction_img).save(merged_path / f'merged_stim-{stim_id}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "157b92c5-9cc6-4bde-815f-5e5693ed33af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"imgBrick\": shape (73000, 425, 425, 3), type \"|u1\">"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stimulus_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b1328e4-9705-4e1f-91d4-a7abac6a1123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run-002 subj01\n",
      "run-002 subj02\n",
      "run-002 subj03\n",
      "run-002 subj04\n",
      "run-002 subj05\n",
      "run-002 subj06\n",
      "run-002 subj07\n",
      "run-002 subj08\n",
      "run-003 subj01\n",
      "run-003 subj02\n",
      "run-003 subj03\n",
      "run-003 subj04\n",
      "run-003 subj05\n",
      "run-003 subj06\n",
      "run-003 subj07\n",
      "run-003 subj08\n"
     ]
    }
   ],
   "source": [
    "# Create comparison images for fun\n",
    "model_name = 'clip-vit-large-patch14-text'\n",
    "group_name = 'group-5'\n",
    "run_names = ['run-002', 'run-003']\n",
    "subjects = [f'subj0{i}' for i in range(1, 9)]\n",
    "\n",
    "for run_name in run_names:\n",
    "    for subject in subjects:\n",
    "        print(run_name, subject)\n",
    "        reconstructions_path = nsd_path / f'derivatives/reconstructions/{model_name}/{group_name}/{run_name}/{subject}/images'\n",
    "        reconstruction_files = [p for p in reconstructions_path.iterdir() if p.name != 'desktop.ini']\n",
    "        reconstruction_files.sort(key=get_stim_id)\n",
    "        stimulus_ids = np.array([get_stim_id(p) for p in reconstruction_files])\n",
    "        unique_stimulus_ids = np.unique(stimulus_ids)\n",
    "        \n",
    "        for stim_id in unique_stimulus_ids:\n",
    "            recon_ids = np.where(stimulus_ids == stim_id)[0]\n",
    "            reconstruction_img = np.concatenate([np.array(Image.fromarray(stimulus_images[stim_id]).resize((512, 512)))] + [\n",
    "                np.array(Image.open(reconstruction_files[recon_id]))\n",
    "                for recon_id in recon_ids\n",
    "            ], axis=1)\n",
    "\n",
    "            merged_path = nsd_path / f'derivatives/reconstructions/{model_name}/{group_name}/{run_name}/{subject}/comparisons'\n",
    "            merged_path.mkdir(exist_ok=True, parents=True)\n",
    "            Image.fromarray(reconstruction_img).save(merged_path / f'merged_stim-{stim_id}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b749b2fe-05e7-4fe6-80ab-b10fea5776c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AvailableBalance': '2428.90',\n",
       " 'ResponseMetadata': {'RequestId': 'd63fe8f5-929a-4889-988b-f1b608c7e448',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'd63fe8f5-929a-4889-988b-f1b608c7e448',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '30',\n",
       "   'date': 'Mon, 19 Sep 2022 05:35:01 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize MTurk client\n",
    "\n",
    "import boto3\n",
    "\n",
    "region_name = 'us-east-1'\n",
    "\n",
    "with open('aws_key.txt') as f:\n",
    "    aws_access_key_id, aws_secret_access_key = f.read().split('\\n')\n",
    "\n",
    "#endpoint_url = 'https://mturk-requester-sandbox.us-east-1.amazonaws.com'\n",
    "#image_hit_type_id = '370Y8Q6HBNLLDYRMFUVI4HD0I2711V'\n",
    "#image_hit_layout_id = '3ES3DE1QF1UWHWRVU4Y10IHAID1HT8'\n",
    "#caption_hit_type_id = '3K3YEJM75DID2H88D5MF0XGBQVL5WG'\n",
    "#caption_hit_layout_id = '3DS6MGEQ9MKRE39D9DRS4I533TXEX8'\n",
    "\n",
    "# Uncomment to use in production\n",
    "endpoint_url = 'https://mturk-requester.us-east-1.amazonaws.com'\n",
    "image_hit_type_id = '3Z1ME8JRSUPQWT8L1TOV35Y20G2OCL'\n",
    "image_hit_layout_id = '3I13DBCGHBTC6JGD4D2XVBI4G6N6ZZ'\n",
    "caption_hit_type_id = '3VU3J1KUFOCJQXTYZW6DN6P4XGBTGM'\n",
    "caption_hit_layout_id = '3QZN5R01ALPXHDB9A3CBQAGE82AUGZ'\n",
    "\n",
    "client = boto3.client(\n",
    "    'mturk',\n",
    "    endpoint_url=endpoint_url,\n",
    "    region_name=region_name,\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    ")\n",
    "\n",
    "# This will return $10,000.00 in the MTurk Developer Sandbox\n",
    "client.get_account_balance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "46fa811d-80ba-410c-ab3f-1c1da901812c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subj05\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "subj08\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "model_name = 'clip-vit-large-patch14-text'\n",
    "group_name = 'group-5'\n",
    "run_name = 'run-003'\n",
    "#subjects = [f'subj0{i}' for i in range(1, 9)]\n",
    "subjects = ['subj05', 'subj08']\n",
    "task_version = 'version-2'\n",
    "batch_name = 'batch-1'\n",
    "\n",
    "num_assignments = 3\n",
    "task_lifetime = 3600 * 24 * 7\n",
    "\n",
    "for subject in subjects:\n",
    "    print(subject)\n",
    "    reconstructions_path = nsd_path / f'derivatives/reconstructions/{model_name}/{group_name}/{run_name}/{subject}/'\n",
    "    task2_data = pd.read_csv(reconstructions_path / f'task2_{task_version}.csv')\n",
    "    task3_data = pd.read_csv(reconstructions_path / f'task3_{task_version}.csv')\n",
    "    with open(reconstructions_path / f'task_{task_version}_info.json') as f:\n",
    "        task_info = json.loads(f.read())\n",
    "        \n",
    "    task2_hit_ids = []\n",
    "    task3_hit_ids = []\n",
    "    for i, (tinfo, t2, t3) in enumerate(zip(task_info, task2_data.iterrows(), task3_data.iterrows())):\n",
    "        if i % 20 == 0:\n",
    "            print(i)\n",
    "        annotation = {\n",
    "            'model_name': model_name,\n",
    "            'group_name': group_name,\n",
    "            'run_name': run_name,\n",
    "            'subject': subject,\n",
    "            'batch_name': batch_name,\n",
    "            'task_version': task_version,\n",
    "            'local_id': i,\n",
    "        }\n",
    "        t2_layout_params = [{'Name': k, 'Value': v} for k, v in dict(t2[1]).items()]\n",
    "        t3_layout_params = [{'Name': k, 'Value': v.replace(\"'\", \"\")} for k, v in dict(t3[1]).items()]\n",
    "        \n",
    "        time.sleep(0.1)\n",
    "        while True:\n",
    "            #\n",
    "            task2_result = client.create_hit_with_hit_type(\n",
    "                HITTypeId=image_hit_type_id,\n",
    "                MaxAssignments=num_assignments,\n",
    "                LifetimeInSeconds=task_lifetime,\n",
    "                RequesterAnnotation=json.dumps({**annotation, 'task': 2}),\n",
    "                HITLayoutId=image_hit_layout_id,\n",
    "                HITLayoutParameters=t2_layout_params,\n",
    "            )\n",
    "            break\n",
    "            #except:\n",
    "            #    time.sleep(5)\n",
    "        \n",
    "        \n",
    "        while True:\n",
    "            #try:\n",
    "            task3_result = client.create_hit_with_hit_type(\n",
    "                HITTypeId=caption_hit_type_id,\n",
    "                MaxAssignments=num_assignments,\n",
    "                LifetimeInSeconds=task_lifetime,\n",
    "                RequesterAnnotation=json.dumps({**annotation, 'task': 3}),\n",
    "                HITLayoutId=caption_hit_layout_id,\n",
    "                HITLayoutParameters=t3_layout_params,\n",
    "            )\n",
    "            break\n",
    "            #except:\n",
    "            #    time.sleep(5)\n",
    "        \n",
    "        task2_hit_ids.append(task2_result['HIT']['HITId'])\n",
    "        task3_hit_ids.append(task3_result['HIT']['HITId'])\n",
    "        \n",
    "    with open(reconstructions_path / f'task2_{task_version}_{batch_name}_hits.txt', 'w') as f:\n",
    "        f.write('\\n'.join(task2_hit_ids))\n",
    "    with open(reconstructions_path / f'task3_{task_version}_{batch_name}_hits.txt', 'w') as f: \n",
    "        f.write('\\n'.join(task3_hit_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7d4f3927-b2b2-4829-a6dc-883f1567ed7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1391\n"
     ]
    }
   ],
   "source": [
    "# Count number of reviewable HITs\n",
    "hits = []\n",
    "\n",
    "next_token = None\n",
    "while True:\n",
    "    if next_token:\n",
    "        result = client.list_reviewable_hits(NextToken=next_token, MaxResults=100)\n",
    "    else:\n",
    "        result = client.list_reviewable_hits(MaxResults=100)\n",
    "    hits += result['HITs']\n",
    "    \n",
    "    if 'NextToken' in result:\n",
    "        next_token = result['NextToken']\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "print(len(hits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7297975d-3275-4cc7-bbcb-01e5d8430b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check status of HIT\n",
    "\n",
    "model_name = 'clip-vit-large-patch14-text'\n",
    "group_name = 'group-5'\n",
    "run_name = 'run-003'\n",
    "#subjects = [f'subj0{i}' for i in range(1, 9)]\n",
    "subjects = ['subj05', 'subj08']\n",
    "tasks = ['task2', 'task3']\n",
    "batch_name = 'batch-1'\n",
    "task_version = 'version-2'\n",
    "\n",
    "for subject in subjects:\n",
    "    print(subject)\n",
    "    reconstructions_path = nsd_path / f'derivatives/reconstructions/{model_name}/{group_name}/{run_name}/{subject}/'\n",
    "    for task in tasks:\n",
    "        print(task)\n",
    "    \n",
    "        with open(reconstructions_path / f'{task}_{task_version}_{batch_name}_hits.txt') as f:\n",
    "            task_hit_ids = f.read().split('\\n')\n",
    "            \n",
    "        for hit_id in task_hit_ids:\n",
    "            hit_assignments_result = client.list_assignments_for_hit(HITId=hit_id)\n",
    "            \n",
    "            for assignment in hit_assignments_result['Assignments']:\n",
    "                task_workers.append({\n",
    "                    'WorkerId': assignment['WorkerId'],\n",
    "                    'Time': (assignment['SubmitTime'] - assignment['AcceptTime']).total_seconds(),\n",
    "                })\n",
    "                \n",
    "                answer = ET.fromstring(client.get_assignment(AssignmentId=assignment['AssignmentId'])['Assignment']['Answer'])\n",
    "                task_results.append(answer[0][1].text)\n",
    "                \n",
    "        continue\n",
    "        with open(reconstructions_path / f'{task}_{task_version}_{batch_name}_results.txt', 'w') as f:\n",
    "            f.write('\\n'.join(task_results))\n",
    "        with open(reconstructions_path / f'{task}_{task_version}_{batch_name}_workers.txt', 'w') as f:\n",
    "            f.write(json.dumps(task_workers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b842d54d-e031-465e-906a-fa0ebc8ecf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subj05\n",
      "task2\n",
      "{'NextToken': 'p2:BRrak86qEuW6L3y2uJHA4RoJrl8rPwr4Rl+tj++U6VliVLAJ6r8M7yth4zGrBg==', 'NumResults': 3, 'Assignments': [{'AssignmentId': '3ITXP059PAXBZRVUECLBEIOVK8USJP', 'WorkerId': 'A1YSYI926BBOHW', 'HITId': '3HUR21WDE7363DEZ4KN0ZTOMQSTXYJ', 'AssignmentStatus': 'Submitted', 'AutoApprovalTime': datetime.datetime(2022, 9, 21, 23, 53, 10, tzinfo=tzlocal()), 'AcceptTime': datetime.datetime(2022, 9, 18, 23, 52, 54, tzinfo=tzlocal()), 'SubmitTime': datetime.datetime(2022, 9, 18, 23, 53, 10, tzinfo=tzlocal()), 'Answer': '<?xml version=\"1.0\" encoding=\"ASCII\"?><QuestionFormAnswers xmlns=\"http://mechanicalturk.amazonaws.com/AWSMechanicalTurkDataSchemas/2005-10-01/QuestionFormAnswers.xsd\"><Answer><QuestionIdentifier>selected_image_idx</QuestionIdentifier><FreeText>0</FreeText></Answer></QuestionFormAnswers>'}, {'AssignmentId': '33CUSNVVN1Q4WQK29AIF81FGS4U88O', 'WorkerId': 'A3CJVRJ34U70Y9', 'HITId': '3HUR21WDE7363DEZ4KN0ZTOMQSTXYJ', 'AssignmentStatus': 'Submitted', 'AutoApprovalTime': datetime.datetime(2022, 9, 21, 23, 58, 37, tzinfo=tzlocal()), 'AcceptTime': datetime.datetime(2022, 9, 18, 23, 58, 17, tzinfo=tzlocal()), 'SubmitTime': datetime.datetime(2022, 9, 18, 23, 58, 37, tzinfo=tzlocal()), 'Answer': '<?xml version=\"1.0\" encoding=\"ASCII\"?><QuestionFormAnswers xmlns=\"http://mechanicalturk.amazonaws.com/AWSMechanicalTurkDataSchemas/2005-10-01/QuestionFormAnswers.xsd\"><Answer><QuestionIdentifier>selected_image_idx</QuestionIdentifier><FreeText>1</FreeText></Answer></QuestionFormAnswers>'}, {'AssignmentId': '3WEV0KO0O06YW5V24GZ0BKTIFPYSDE', 'WorkerId': 'A264NN7JBX4UDQ', 'HITId': '3HUR21WDE7363DEZ4KN0ZTOMQSTXYJ', 'AssignmentStatus': 'Submitted', 'AutoApprovalTime': datetime.datetime(2022, 9, 21, 23, 59, 16, tzinfo=tzlocal()), 'AcceptTime': datetime.datetime(2022, 9, 18, 23, 58, 53, tzinfo=tzlocal()), 'SubmitTime': datetime.datetime(2022, 9, 18, 23, 59, 16, tzinfo=tzlocal()), 'Answer': '<?xml version=\"1.0\" encoding=\"ASCII\"?><QuestionFormAnswers xmlns=\"http://mechanicalturk.amazonaws.com/AWSMechanicalTurkDataSchemas/2005-10-01/QuestionFormAnswers.xsd\"><Answer><QuestionIdentifier>selected_image_idx</QuestionIdentifier><FreeText>1</FreeText></Answer></QuestionFormAnswers>'}], 'ResponseMetadata': {'RequestId': 'f3dbe60e-3a53-4522-bcee-4487eac6e642', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'f3dbe60e-3a53-4522-bcee-4487eac6e642', 'content-type': 'application/x-amz-json-1.1', 'content-length': '1738', 'date': 'Mon, 19 Sep 2022 06:18:20 GMT'}, 'RetryAttempts': 0}}\n",
      "[]\n",
      "completed=True\n",
      "task3\n",
      "{'NextToken': 'p2:AwJPpAWXMBcn73EUyj1hGepZfFE98OsTFHc4XM29CeO+8oO9e+wllTfbpJyRnw==', 'NumResults': 3, 'Assignments': [{'AssignmentId': '3LWJHTCVCQ0JH9UL3I5L4KH29DQQFT', 'WorkerId': 'A1NF6PELRKACS9', 'HITId': '3TFJJUELTU3SZUAXK3KICC27AVB2C6', 'AssignmentStatus': 'Submitted', 'AutoApprovalTime': datetime.datetime(2022, 9, 21, 23, 42, 53, tzinfo=tzlocal()), 'AcceptTime': datetime.datetime(2022, 9, 18, 23, 41, 20, tzinfo=tzlocal()), 'SubmitTime': datetime.datetime(2022, 9, 18, 23, 42, 53, tzinfo=tzlocal()), 'Answer': '<?xml version=\"1.0\" encoding=\"ASCII\"?><QuestionFormAnswers xmlns=\"http://mechanicalturk.amazonaws.com/AWSMechanicalTurkDataSchemas/2005-10-01/QuestionFormAnswers.xsd\"><Answer><QuestionIdentifier>category.label</QuestionIdentifier><FreeText>A skateboarder doing tricks on an indoor skate ramp.</FreeText></Answer></QuestionFormAnswers>'}, {'AssignmentId': '3F1567XTNAJAGZ380W5TUOVR6FWQ92', 'WorkerId': 'A26399B1QZ7XJJ', 'HITId': '3TFJJUELTU3SZUAXK3KICC27AVB2C6', 'AssignmentStatus': 'Submitted', 'AutoApprovalTime': datetime.datetime(2022, 9, 21, 23, 47, 36, tzinfo=tzlocal()), 'AcceptTime': datetime.datetime(2022, 9, 18, 23, 46, 24, tzinfo=tzlocal()), 'SubmitTime': datetime.datetime(2022, 9, 18, 23, 47, 36, tzinfo=tzlocal()), 'Answer': '<?xml version=\"1.0\" encoding=\"ASCII\"?><QuestionFormAnswers xmlns=\"http://mechanicalturk.amazonaws.com/AWSMechanicalTurkDataSchemas/2005-10-01/QuestionFormAnswers.xsd\"><Answer><QuestionIdentifier>category.label</QuestionIdentifier><FreeText>an orange and yellow surf board is laid up against the wall</FreeText></Answer></QuestionFormAnswers>'}, {'AssignmentId': '37WLF8U1W341ND3FPKIKESSGH8X6KG', 'WorkerId': 'A2KLJKDG90K1PP', 'HITId': '3TFJJUELTU3SZUAXK3KICC27AVB2C6', 'AssignmentStatus': 'Submitted', 'AutoApprovalTime': datetime.datetime(2022, 9, 21, 23, 49, 55, tzinfo=tzlocal()), 'AcceptTime': datetime.datetime(2022, 9, 18, 23, 48, 9, tzinfo=tzlocal()), 'SubmitTime': datetime.datetime(2022, 9, 18, 23, 49, 55, tzinfo=tzlocal()), 'Answer': '<?xml version=\"1.0\" encoding=\"ASCII\"?><QuestionFormAnswers xmlns=\"http://mechanicalturk.amazonaws.com/AWSMechanicalTurkDataSchemas/2005-10-01/QuestionFormAnswers.xsd\"><Answer><QuestionIdentifier>category.label</QuestionIdentifier><FreeText>an orange and yellow surf board is laid up against the wall</FreeText></Answer></QuestionFormAnswers>'}], 'ResponseMetadata': {'RequestId': 'a3f661d3-79df-4a89-8872-c75fa2147b4b', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'a3f661d3-79df-4a89-8872-c75fa2147b4b', 'content-type': 'application/x-amz-json-1.1', 'content-length': '1894', 'date': 'Mon, 19 Sep 2022 06:18:21 GMT'}, 'RetryAttempts': 0}}\n",
      "[]\n",
      "completed=True\n",
      "subj08\n",
      "task2\n",
      "{'NextToken': 'p2:Puf9ag/FJjyPkjRy3BTjikYmsSr0FnIi5SW4u4uGTyknZ3ifb6ZFA/c5ZGIRcQ==', 'NumResults': 3, 'Assignments': [{'AssignmentId': '3IQ1VMJRY7YITJWRB0874OGM2XAA9F', 'WorkerId': 'A264NN7JBX4UDQ', 'HITId': '3IV1AEQ4E4RQTNISACA597S5MFC8JT', 'AssignmentStatus': 'Submitted', 'AutoApprovalTime': datetime.datetime(2022, 9, 21, 23, 44, 47, tzinfo=tzlocal()), 'AcceptTime': datetime.datetime(2022, 9, 18, 23, 43, 36, tzinfo=tzlocal()), 'SubmitTime': datetime.datetime(2022, 9, 18, 23, 44, 47, tzinfo=tzlocal()), 'Answer': '<?xml version=\"1.0\" encoding=\"ASCII\"?><QuestionFormAnswers xmlns=\"http://mechanicalturk.amazonaws.com/AWSMechanicalTurkDataSchemas/2005-10-01/QuestionFormAnswers.xsd\"><Answer><QuestionIdentifier>selected_image_idx</QuestionIdentifier><FreeText>0</FreeText></Answer></QuestionFormAnswers>'}, {'AssignmentId': '3K9FOBBF2VXKE4RP91G2V3RH1YRLN8', 'WorkerId': 'A1YSYI926BBOHW', 'HITId': '3IV1AEQ4E4RQTNISACA597S5MFC8JT', 'AssignmentStatus': 'Submitted', 'AutoApprovalTime': datetime.datetime(2022, 9, 21, 23, 53, 30, tzinfo=tzlocal()), 'AcceptTime': datetime.datetime(2022, 9, 18, 23, 53, 11, tzinfo=tzlocal()), 'SubmitTime': datetime.datetime(2022, 9, 18, 23, 53, 30, tzinfo=tzlocal()), 'Answer': '<?xml version=\"1.0\" encoding=\"ASCII\"?><QuestionFormAnswers xmlns=\"http://mechanicalturk.amazonaws.com/AWSMechanicalTurkDataSchemas/2005-10-01/QuestionFormAnswers.xsd\"><Answer><QuestionIdentifier>selected_image_idx</QuestionIdentifier><FreeText>0</FreeText></Answer></QuestionFormAnswers>'}, {'AssignmentId': '3TXWC2NHND4MTFILS0UYPOASO4JS9X', 'WorkerId': 'A2KJ983WWTEK4L', 'HITId': '3IV1AEQ4E4RQTNISACA597S5MFC8JT', 'AssignmentStatus': 'Submitted', 'AutoApprovalTime': datetime.datetime(2022, 9, 21, 23, 59, 3, tzinfo=tzlocal()), 'AcceptTime': datetime.datetime(2022, 9, 18, 23, 58, 45, tzinfo=tzlocal()), 'SubmitTime': datetime.datetime(2022, 9, 18, 23, 59, 3, tzinfo=tzlocal()), 'Answer': '<?xml version=\"1.0\" encoding=\"ASCII\"?><QuestionFormAnswers xmlns=\"http://mechanicalturk.amazonaws.com/AWSMechanicalTurkDataSchemas/2005-10-01/QuestionFormAnswers.xsd\"><Answer><QuestionIdentifier>selected_image_idx</QuestionIdentifier><FreeText>0</FreeText></Answer></QuestionFormAnswers>'}], 'ResponseMetadata': {'RequestId': '70bd416b-2783-44e4-96fd-f043c51b17cc', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '70bd416b-2783-44e4-96fd-f043c51b17cc', 'content-type': 'application/x-amz-json-1.1', 'content-length': '1738', 'date': 'Mon, 19 Sep 2022 06:18:21 GMT'}, 'RetryAttempts': 0}}\n",
      "[]\n",
      "completed=True\n",
      "task3\n",
      "{'NextToken': 'p2:RECwD70AVBYFKsQMvb6fBesV1kHMLZBbOidYmeQR7eTEXtRwmexT4OwKHpLikw==', 'NumResults': 3, 'Assignments': [{'AssignmentId': '3YGXWBAF7EV5PSNDEJ87TBVUG8GC4M', 'WorkerId': 'A4J4GGMKJ68L0', 'HITId': '375VMB7D5WX6F7UD920LJYR6KRKIDX', 'AssignmentStatus': 'Submitted', 'AutoApprovalTime': datetime.datetime(2022, 9, 21, 23, 41, 18, tzinfo=tzlocal()), 'AcceptTime': datetime.datetime(2022, 9, 18, 23, 38, 33, tzinfo=tzlocal()), 'SubmitTime': datetime.datetime(2022, 9, 18, 23, 41, 18, tzinfo=tzlocal()), 'Answer': '<?xml version=\"1.0\" encoding=\"ASCII\"?><QuestionFormAnswers xmlns=\"http://mechanicalturk.amazonaws.com/AWSMechanicalTurkDataSchemas/2005-10-01/QuestionFormAnswers.xsd\"><Answer><QuestionIdentifier>category.label</QuestionIdentifier><FreeText>A blue and white boat with stuff in it on a beach. </FreeText></Answer></QuestionFormAnswers>'}, {'AssignmentId': '3WYP994K1L5W7ISWTZJBN07RFN66YB', 'WorkerId': 'A3JN18TC8GL3IH', 'HITId': '375VMB7D5WX6F7UD920LJYR6KRKIDX', 'AssignmentStatus': 'Submitted', 'AutoApprovalTime': datetime.datetime(2022, 9, 21, 23, 49, 39, tzinfo=tzlocal()), 'AcceptTime': datetime.datetime(2022, 9, 18, 23, 48, 56, tzinfo=tzlocal()), 'SubmitTime': datetime.datetime(2022, 9, 18, 23, 49, 39, tzinfo=tzlocal()), 'Answer': '<?xml version=\"1.0\" encoding=\"ASCII\"?><QuestionFormAnswers xmlns=\"http://mechanicalturk.amazonaws.com/AWSMechanicalTurkDataSchemas/2005-10-01/QuestionFormAnswers.xsd\"><Answer><QuestionIdentifier>category.label</QuestionIdentifier><FreeText>A blue and white boat with stuff in it on a beach. </FreeText></Answer></QuestionFormAnswers>'}, {'AssignmentId': '3WT783CTPPVPAR8MTYIU1P10Q0ZBCT', 'WorkerId': 'A1NF6PELRKACS9', 'HITId': '375VMB7D5WX6F7UD920LJYR6KRKIDX', 'AssignmentStatus': 'Submitted', 'AutoApprovalTime': datetime.datetime(2022, 9, 21, 23, 49, 43, tzinfo=tzlocal()), 'AcceptTime': datetime.datetime(2022, 9, 18, 23, 48, 51, tzinfo=tzlocal()), 'SubmitTime': datetime.datetime(2022, 9, 18, 23, 49, 43, tzinfo=tzlocal()), 'Answer': '<?xml version=\"1.0\" encoding=\"ASCII\"?><QuestionFormAnswers xmlns=\"http://mechanicalturk.amazonaws.com/AWSMechanicalTurkDataSchemas/2005-10-01/QuestionFormAnswers.xsd\"><Answer><QuestionIdentifier>category.label</QuestionIdentifier><FreeText>A person holding a surfboard walking on the watery beach.</FreeText></Answer></QuestionFormAnswers>'}], 'ResponseMetadata': {'RequestId': '7d4f62d8-d1e1-41a7-9bda-0a50a8f1cd80', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '7d4f62d8-d1e1-41a7-9bda-0a50a8f1cd80', 'content-type': 'application/x-amz-json-1.1', 'content-length': '1883', 'date': 'Mon, 19 Sep 2022 06:18:21 GMT'}, 'RetryAttempts': 0}}\n",
      "[]\n",
      "completed=True\n"
     ]
    }
   ],
   "source": [
    "# Check status of a MTurk batch\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "model_name = 'clip-vit-large-patch14-text'\n",
    "group_name = 'group-5'\n",
    "run_name = 'run-003'\n",
    "#subjects = [f'subj0{i}' for i in range(1, 9)]\n",
    "subjects = ['subj05', 'subj08']\n",
    "tasks = ['task2', 'task3']\n",
    "batch_name = 'batch-1'\n",
    "task_version = 'version-2'\n",
    "\n",
    "for subject in subjects:\n",
    "    print(subject)\n",
    "    reconstructions_path = nsd_path / f'derivatives/reconstructions/{model_name}/{group_name}/{run_name}/{subject}/'\n",
    "    for task in tasks:\n",
    "        print(task)\n",
    "    \n",
    "        with open(reconstructions_path / f'{task}_{task_version}_{batch_name}_hits.txt') as f:\n",
    "            task_hit_ids = f.read().split('\\n')\n",
    "            \n",
    "        num_results = []\n",
    "        \n",
    "        for hit_id in task_hit_ids:\n",
    "            hit_assignments_result = client.list_assignments_for_hit(HITId=hit_id)\n",
    "            print(hit_assignments_result)\n",
    "            break\n",
    "            num_results.append(hit_assignments_result['NumResults'])\n",
    "        print(num_results)\n",
    "        print(f'completed={np.all(np.array(num_results) == 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ee271ec5-e474-422c-be97-8a0bf3beb82c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subj05\n",
      "task2\n",
      "task3\n",
      "subj08\n",
      "task2\n",
      "task3\n"
     ]
    }
   ],
   "source": [
    "# Save results of MTurk batch\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "model_name = 'clip-vit-large-patch14-text'\n",
    "group_name = 'group-5'\n",
    "run_name = 'run-003'\n",
    "#subjects = [f'subj0{i}' for i in range(1, 9)]\n",
    "subjects = ['subj05', 'subj08']\n",
    "tasks = ['task2', 'task3']\n",
    "batch_name = 'batch-1'\n",
    "task_version = 'version-2'\n",
    "\n",
    "for subject in subjects:\n",
    "    print(subject)\n",
    "    reconstructions_path = nsd_path / f'derivatives/reconstructions/{model_name}/{group_name}/{run_name}/{subject}/'\n",
    "    for task in tasks:\n",
    "        print(task)\n",
    "    \n",
    "        with open(reconstructions_path / f'{task}_{task_version}_{batch_name}_hits.txt') as f:\n",
    "            task_hit_ids = f.read().split('\\n')\n",
    "            \n",
    "        task_results = []\n",
    "        task_workers = []\n",
    "        for hit_id in task_hit_ids:\n",
    "            hit_assignments_result = client.list_assignments_for_hit(HITId=hit_id)\n",
    "            \n",
    "            assignment_results = []\n",
    "            assignment_workers = []\n",
    "            \n",
    "            for assignment in hit_assignments_result['Assignments']:\n",
    "                assignment_workers.append({\n",
    "                    'WorkerId': assignment['WorkerId'],\n",
    "                    'Time': (assignment['SubmitTime'] - assignment['AcceptTime']).total_seconds(),\n",
    "                })\n",
    "                \n",
    "                answer = ET.fromstring(client.get_assignment(AssignmentId=assignment['AssignmentId'])['Assignment']['Answer'])\n",
    "                assignment_results.append(answer[0][1].text)\n",
    "            task_results.append(assignment_results)\n",
    "            task_workers.append(assignment_workers)\n",
    "\n",
    "        with open(reconstructions_path / f'{task}_{task_version}_{batch_name}_results.txt', 'w') as f:\n",
    "            f.write(json.dumps(task_results))\n",
    "        with open(reconstructions_path / f'{task}_{task_version}_{batch_name}_workers.txt', 'w') as f:\n",
    "            f.write(json.dumps(task_workers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1e7746b-c157-4315-9b61-40661b347942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AssignmentId': '3S4AW7T80PWYSWHJRW16WULH9KM4LR',\n",
       " 'WorkerId': 'A3CJVRJ34U70Y9',\n",
       " 'HITId': '3VQTAXTYOGZI91RTPNYT7BRHBQBUB4',\n",
       " 'AssignmentStatus': 'Submitted',\n",
       " 'AutoApprovalTime': datetime.datetime(2022, 9, 17, 1, 49, 3, tzinfo=tzlocal()),\n",
       " 'AcceptTime': datetime.datetime(2022, 9, 14, 1, 48, 45, tzinfo=tzlocal()),\n",
       " 'SubmitTime': datetime.datetime(2022, 9, 14, 1, 49, 3, tzinfo=tzlocal()),\n",
       " 'Answer': '<?xml version=\"1.0\" encoding=\"ASCII\"?><QuestionFormAnswers xmlns=\"http://mechanicalturk.amazonaws.com/AWSMechanicalTurkDataSchemas/2005-10-01/QuestionFormAnswers.xsd\"><Answer><QuestionIdentifier>selected_image_idx</QuestionIdentifier><FreeText>1</FreeText></Answer></QuestionFormAnswers>'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83c5e293-09f1-43f5-a486-ed1110a1783f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AssignmentId': '3XXU1SWE8090XP8EB4PEBDFTYWDA05',\n",
       " 'WorkerId': 'AORHXBTOCXFUK',\n",
       " 'HITId': '3D1UCPY6HTNF89G37RIIT0BGQ7883D',\n",
       " 'AssignmentStatus': 'Submitted',\n",
       " 'AutoApprovalTime': datetime.datetime(2022, 9, 17, 2, 38, 1, tzinfo=tzlocal()),\n",
       " 'AcceptTime': datetime.datetime(2022, 9, 14, 2, 37, 36, tzinfo=tzlocal()),\n",
       " 'SubmitTime': datetime.datetime(2022, 9, 14, 2, 38, 1, tzinfo=tzlocal()),\n",
       " 'Answer': '<?xml version=\"1.0\" encoding=\"ASCII\"?><QuestionFormAnswers xmlns=\"http://mechanicalturk.amazonaws.com/AWSMechanicalTurkDataSchemas/2005-10-01/QuestionFormAnswers.xsd\"><Answer><QuestionIdentifier>category.label</QuestionIdentifier><FreeText>A surfer in a wetsuit rides on a wave.</FreeText></Answer></QuestionFormAnswers>'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b84091ec-103d-492f-8162-d8c840cac07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"ASCII\"?><QuestionFormAnswers xmlns=\"http://mechanicalturk.amazonaws.com/AWSMechanicalTurkDataSchemas/2005-10-01/QuestionFormAnswers.xsd\"><Answer><QuestionIdentifier>category.label</QuestionIdentifier><FreeText>A person holding a surfboard walking on the watery beach.</FreeText></Answer></QuestionFormAnswers>\n",
      "A person holding a surfboard walking on the watery beach.\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "hit_assignments_result = client.list_assignments_for_hit(HITId='38RHULDVABT5ODU4QX0T5QRQN22WIO')\n",
    "for assignment in hit_assignments_result['Assignments']:\n",
    "    print(client.get_assignment(AssignmentId=assignment['AssignmentId'])['Assignment']['Answer'])\n",
    "    answer = ET.fromstring(client.get_assignment(AssignmentId=assignment['AssignmentId'])['Assignment']['Answer'])\n",
    "    print(answer[0][1].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "20de2ff9-8c26-465c-9e55-dd93fa511d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HIT': {'HITId': '366FYU4PUT32D8Y150RZW0Z382REK6',\n",
       "  'HITTypeId': '3K3YEJM75DID2H88D5MF0XGBQVL5WG',\n",
       "  'HITGroupId': '3PBTVBPQ96GCMSALE03YLMKESSNLGB',\n",
       "  'HITLayoutId': '3TVX9BGUNUTQFYGJYRQ8P8PWY5PH6W',\n",
       "  'CreationTime': datetime.datetime(2022, 9, 14, 1, 16, 39, tzinfo=tzlocal()),\n",
       "  'Title': 'Choose a caption that best describes the generated image.',\n",
       "  'Description': 'Choose a caption that best describes the generated image.',\n",
       "  'Question': '<?xml version=\"1.0\"?>\\n<HTMLQuestion xmlns=\"http://mechanicalturk.amazonaws.com/AWSMechanicalTurkDataSchemas/2011-11-11/HTMLQuestion.xsd\">\\n  <HTMLContent><![CDATA[<html><head><title>HIT</title><meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"/></head><body><script src=\"https://assets.crowd.aws/crowd-html-elements.js\"></script>\\r\\n<link href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css\" rel=\"stylesheet\"\\r\\n      integrity=\"sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3\" crossorigin=\"anonymous\">\\r\\n<script src=\"https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js\"\\r\\n        integrity=\"sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p\"\\r\\n        crossorigin=\"anonymous\"></script>\\r\\n<script src=\"https://cdn.jsdelivr.net/npm/js-cookie@3.0.1/dist/js.cookie.min.js\"\\r\\n        integrity=\"sha256-0H3Nuz3aug3afVbUlsu12Puxva3CP4EhJtPExqs54Vg=\" crossorigin=\"anonymous\"></script>\\r\\n\\r\\n<crowd-alert type=\"info\" dismissible>\\r\\n    On Safari, you may need to deselect <a href=\"https://support.apple.com/en-ca/guide/safari/sfri40732/mac\"\\r\\n                                           target=\"_blank\">Prevent Cross Site Tracking</a> for images to load properly.\\r\\n</crowd-alert>\\r\\n\\r\\n<div class=\"modal fade\" id=\"staticModal\" tabindex=\"-1\">\\r\\n    <div class=\"modal-dialog\">\\r\\n        <div class=\"modal-content\">\\r\\n            <div class=\"modal-header\">\\r\\n                <h5 class=\"modal-title\" id=\"staticBackdropLabel\">Consent Form</h5>\\r\\n            </div>\\r\\n            <div class=\"modal-body\">\\r\\n                By clicking Accept, I confirm that I have read, understand, and agree to the <a\\r\\n                    href=\"https://drive.google.com/file/d/1q7NoMpDP-ltaBMzjkFDwhypLyatK6Op2/view\" target=\"_blank\">Consent\\r\\n                Form</a>.\\r\\n            </div>\\r\\n            <div class=\"modal-footer\">\\r\\n                <button type=\"button\" class=\"btn btn-primary\" data-bs-dismiss=\"modal\">Accept</button>\\r\\n            </div>\\r\\n        </div>\\r\\n    </div>\\r\\n</div>\\r\\n\\r\\n<crowd-form answer-format=\"flatten-objects\">\\r\\n<crowd-classifier\\r\\n            name=\"category\"\\r\\n            categories=\"[\\'a close up of luggage bags on a grassy ground\\', \\'The giraffe is bowing it\\'s head down while it\\'s walking. \\', \\'A pitcher prepares to throw a ball to a batter and catcher while many spectators look on.\\', \\'A young man throwing a yellow frisbee towards a green house.\\', \\'a bike and other items in a trunk\\']\"\\r\\n            header=\"Select the sentence which best represents the image.\"\\r\\n    >\\r\\n        <classification-target style=\"text-align: center;\">\\r\\n            <img frameborder=\"0\" scrolling=\"no\" width=\"100%\" \\r\\n                    src=\"https://drive.google.com/uc?id=1d9zJvO9fvwL5L3p4QmvBP7HnaAOm1BC_&export=view\" name=\"imgbox\" id=\"imgbox\">\\r\\n            </img>\\r\\n            <br/>\\r\\n\\r\\n        </classification-target>\\r\\n\\r\\n        <short-instructions header=\"Document Classification Instructions\">\\r\\n            <p>Read the task carefully and inspect the image.</p>\\r\\n            <p>Choose the sentence that best represents the image.</p>\\r\\n        </short-instructions>\\r\\n    </crowd-classifier>\\r\\n</crowd-form>\\r\\n<script type=\"text/javascript\">\\r\\n    (function () {\\r\\n\\r\\n        const options = {\\r\\n            backdrop: \\'static\\',\\r\\n            keyboard: false,\\r\\n            focus: true\\r\\n        }\\r\\n        const modal = new bootstrap.Modal(document.getElementById(\\'staticModal\\'), options)\\r\\n\\r\\n        document.getElementById(\"staticModal\").addEventListener(\"hide.bs.modal\", (event) => {\\r\\n            Cookies.set(\"task_3_consent_agreement\", \"1\")\\r\\n        })\\r\\n\\r\\n        if (Cookies.get(\"task_3_consent_agreement\") === undefined) {\\r\\n            modal.toggle()\\r\\n        }\\r\\n    })()\\r\\n\\r\\n</script></body></html>]]></HTMLContent>\\n  <FrameHeight>0</FrameHeight>\\n</HTMLQuestion>\\n',\n",
       "  'Keywords': 'categorize, image',\n",
       "  'HITStatus': 'Unassignable',\n",
       "  'MaxAssignments': 1,\n",
       "  'Reward': '0.09',\n",
       "  'AutoApprovalDelayInSeconds': 259200,\n",
       "  'Expiration': datetime.datetime(2022, 9, 21, 1, 16, 39, tzinfo=tzlocal()),\n",
       "  'AssignmentDurationInSeconds': 300,\n",
       "  'RequesterAnnotation': '{\"model_name\": \"clip-vit-large-patch14-text\", \"group_name\": \"group-5\", \"run_name\": \"run-003\", \"subject\": \"subj01\", \"batch_name\": \"batch-1\", \"local_id\": 26, \"task\": 3}',\n",
       "  'QualificationRequirements': [],\n",
       "  'HITReviewStatus': 'NotReviewed',\n",
       "  'NumberOfAssignmentsPending': 1,\n",
       "  'NumberOfAssignmentsAvailable': 0,\n",
       "  'NumberOfAssignmentsCompleted': 0},\n",
       " 'ResponseMetadata': {'RequestId': '4a2e4c11-7017-4c24-873e-9ee63ee0fe5c',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '4a2e4c11-7017-4c24-873e-9ee63ee0fe5c',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '5011',\n",
       "   'date': 'Wed, 14 Sep 2022 07:20:08 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_hit(HITId='366FYU4PUT32D8Y150RZW0Z382REK6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "10d11159-6b56-48ee-b3c7-64711a4e948d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# PURGE HITS\n",
    "\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "\n",
    "next_token = None\n",
    "while True:\n",
    "    if next_token:\n",
    "        result = client.list_hits(NextToken=next_token, MaxResults=100)\n",
    "    else:\n",
    "        result = client.list_hits(MaxResults=100)\n",
    "    \n",
    "    if 'NextToken' in result:\n",
    "        next_token = result['NextToken']\n",
    "    hits = result['HITs']\n",
    "    print(len(hits))\n",
    "    if len(hits) == 0:\n",
    "        break\n",
    "    \n",
    "    for hit in hits:\n",
    "        hit_id = hit['HITId']\n",
    "        status = hit['HITStatus']\n",
    "        print(f'{hit_id=}, {status=}')\n",
    "\n",
    "        if status == 'Assignable':\n",
    "            response = client.update_expiration_for_hit(\n",
    "                HITId=hit_id,\n",
    "                ExpireAt=datetime(2015, 1, 1)\n",
    "            )\n",
    "            \n",
    "        if status == 'Reviewable':\n",
    "            for assignment in client.list_assignments_for_hit(HITId=hit_id)['Assignments']:\n",
    "                try:\n",
    "                    print(f'Approving assignment {assignment[\"AssignmentId\"]}')\n",
    "                    client.approve_assignment(AssignmentId=assignment['AssignmentId'])\n",
    "                except:\n",
    "                    print('Failed')\n",
    "\n",
    "        # Delete the HIT\n",
    "        try:\n",
    "            client.delete_hit(HITId=hit_id)\n",
    "        except:\n",
    "            print('Not deleted')\n",
    "        else:\n",
    "            print('Deleted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro-decode",
   "language": "python",
   "name": "neuro-decode"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
