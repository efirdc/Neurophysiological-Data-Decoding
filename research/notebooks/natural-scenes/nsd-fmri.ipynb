{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bdf5412-9357-4f34-9391-7dde91e1a8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cefir\\anaconda3\\envs\\Neurophysiological-Data-Decoding\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Cefir\\anaconda3\\envs\\Neurophysiological-Data-Decoding\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\Cefir\\anaconda3\\envs\\Neurophysiological-Data-Decoding\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "C:\\Users\\Cefir\\anaconda3\\envs\\Neurophysiological-Data-Decoding\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "C:\\Users\\Cefir\\anaconda3\\envs\\Neurophysiological-Data-Decoding\\lib\\site-packages\\numpy\\.libs\\libopenblas.xwydx2ikjw2nmtwsfyngfuwkqu3lytcz.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchio as tio\n",
    "import h5py\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import nibabel as nib\n",
    "from einops import rearrange\n",
    "from scipy import ndimage\n",
    "from fracridge import FracRidgeRegressorCV\n",
    "\n",
    "\n",
    "dir2 = os.path.abspath('../..')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path:\n",
    "    sys.path.append(dir1)\n",
    "    \n",
    "from research.models.regression_torch import (\n",
    "    pearsonr, \n",
    "    rsquared,\n",
    "    frac_ridge_regression,\n",
    "    frac_ridge_regression_cv,\n",
    "    ridge_regression,\n",
    "    ridge_regression_cv,\n",
    ")\n",
    "\n",
    "from research.data.natural_scenes import (\n",
    "    NaturalScenesDataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3362f022-4756-4b4c-a3c3-8f78f6413ae4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_path = Path('D:\\\\Datasets\\\\NSD\\\\')\n",
    "dataset = NaturalScenesDataset(dataset_path)\n",
    "\n",
    "derivatives_path = dataset_path / 'derivatives'\n",
    "betas_path = dataset_path / 'nsddata_betas' / 'ppdata'\n",
    "ppdata_path = dataset_path / 'nsddata' / 'ppdata'\n",
    "subjects = dataset.subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ea6983-db26-442e-a788-2205671e58c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subjects = {f'subj0{i}': {} for i in range(1, 9)}\n",
    "\n",
    "for subject_name, subject_data in subjects.items():\n",
    "    responses_file_path = ppdata_path / subject_name / 'behav' / 'responses.tsv'\n",
    "    subject_data['responses'] = pd.read_csv(responses_file_path, sep='\\t',)\n",
    "    \n",
    "    # The last 3 sessions are currently held-out for the algonauts challenge\n",
    "    # remove them for now.\n",
    "    session_ids = subject_data['responses']['SESSION']\n",
    "    held_out_mask = session_ids > (np.max(session_ids) - 3)\n",
    "    subject_data['responses'] = subject_data['responses'][~held_out_mask]\n",
    "    \n",
    "    subject_betas_path = derivatives_path / subject_name / 'func1pt8mm' / 'betas_fithrf_GLMdenoise_RR'\n",
    "    num_sessions = np.max(subject_data['responses']['SESSION'])\n",
    "    \n",
    "    #subject_data['sessions'] = [\n",
    "    #    h5py.File(subject_betas_path / f'betas_session{i:02}.hdf5', 'r')\n",
    "    #    for i in range(1, num_sessions + 1)\n",
    "    #]\n",
    "    \n",
    "    subject_data['betas'] = h5py.File(subject_betas_path / f'betas_sessions.hdf5', 'r')\n",
    "    \n",
    "    subject_data['brainmask'] = nib.load(ppdata_path / subject_name / 'func1pt8mm' / 'brainmask.nii.gz')\n",
    "    subject_data['t1_path'] = ppdata_path / subject_name / 'func1pt8mm' / 'T1_to_func1pt8mm.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb76a346-f88c-49a6-b15e-0d480d3f2b94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run an encoder\n",
    "\n",
    "split_name = 'split-01'\n",
    "split = h5py.File(derivatives_path / 'data_splits' / f'{split_name}.hdf5')\n",
    "fractions = torch.arange(.05, 1.05, .05).cuda()\n",
    "#alpha = 10 ** torch.linspace(1, 5, 20).cuda()\n",
    "\n",
    "run_stimulus_embeddings = {\n",
    "    #'bigbigan-resnet50': ['z_mean'],\n",
    "    #'ViT-B=32': [f'transformer.resblocks.{i}' for i in range(12)],\n",
    "    #'ViT-B=32': ['embedding', *(f'transformer.resblocks.{i}' for i in range(12))],\n",
    "    'DPT_Large': ['depth-pyramid-24'],\n",
    "    #'biggan-128': ['z', 'y_embedding'],\n",
    "    #'vqgan': ['vqgan-f16-1024-pre_quant'],\n",
    "}\n",
    "\n",
    "embedding_files = {\n",
    "    model_name: h5py.File(derivatives_path / 'stimulus_embeddings' / f'{model_name}.hdf5', 'r')\n",
    "    for model_name in run_stimulus_embeddings.keys()\n",
    "}\n",
    "\n",
    "seed = 0\n",
    "max_features = 1e9 # 512\n",
    "normalize_embeddings = True\n",
    "\n",
    "with h5py.File(derivatives_path / 'fracridge-parameters.hdf5', 'a') as f:\n",
    "    for subject_name, subject_data in list(subjects.items())[:1]:\n",
    "        sessions = subject_data['sessions']\n",
    "        num_sessions = len(sessions)\n",
    "        shape = sessions[0]['betas'].shape\n",
    "        T, W, H, D = shape\n",
    "        \n",
    "        subject_split = split[subject_name]\n",
    "        test_mask = subject_split['test_response_mask'][:].astype(bool)\n",
    "        validation_mask = subject_split['validation_response_mask'][:].astype(bool)\n",
    "        training_mask = ~(test_mask | validation_mask)\n",
    "        training_indices = np.where(training_mask)[0]\n",
    "\n",
    "        responses = subject_data['responses']\n",
    "        training_stimulus_ids = responses['73KID'].to_numpy()[training_indices] - 1\n",
    "        \n",
    "        subject_stimulus_embeddings = {}\n",
    "        for model_name, embedding_names in run_stimulus_embeddings.items():\n",
    "            subject_stimulus_embeddings[model_name] = {}\n",
    "            for embedding_name in embedding_names:\n",
    "                keys = (subject_name, model_name, embedding_name)\n",
    "                print('loading', keys)\n",
    "                \n",
    "                embedding = embedding_files[model_name][embedding_name][:][training_stimulus_ids]\n",
    "                embedding = torch.from_numpy(embedding)\n",
    "                embedding = embedding.flatten(start_dim=1)\n",
    "                if embedding.shape[1] > max_features:\n",
    "                    np.random.seed(seed)\n",
    "                    choice = np.random.choice(max_features, size=max_features)\n",
    "                    embedding = embedding[:, choice]\n",
    "                embedding = embedding.float().cuda()\n",
    "                embedding_mean = embedding.mean(dim=0, keepdims=True)\n",
    "                embedding_std = embedding.std(dim=0, keepdims=True)\n",
    "                if normalize_embeddings:\n",
    "                    embedding = (embedding - embedding_mean) / embedding_std\n",
    "                subject_stimulus_embeddings[model_name][embedding_name] = embedding.float().cuda()\n",
    "                \n",
    "                key = '/'.join(keys)\n",
    "                E = embedding.shape[-1]\n",
    "                group = f.require_group(key)\n",
    "                group.require_dataset('coefs', shape=(W, H, D, E), dtype='f4')\n",
    "                group.require_dataset('alpha', shape=(W, H, D), dtype='f4')\n",
    "                group.require_dataset('r2', shape=(W, H, D), dtype='f4')\n",
    "                group.require_dataset('fractions', shape=(W, H, D), dtype='f4')\n",
    "                \n",
    "                group.require_dataset('embedding_mean', embedding_mean.shape, 'f4')\n",
    "                group.require_dataset('embedding_std', embedding_std.shape, 'f4')\n",
    "                group['embedding_mean'][:] = embedding_mean.cpu().numpy()\n",
    "                group['embedding_std'][:] = embedding_std.cpu().numpy()\n",
    "\n",
    "        mask = (subjects[subject_name]['brainmask'].get_fdata() > 0.).T\n",
    "        \n",
    "        load_time = 0\n",
    "        compute_time = 0\n",
    "        store_time = 0\n",
    "        \n",
    "        for i in tqdm(range(32, W)):\n",
    "            if (i + 1) % 5 == 0:\n",
    "                print(f'{load_time=:03}s, {compute_time=:03}s, {store_time=:03}s')\n",
    "    \n",
    "            mask_slice = mask[i]\n",
    "            if mask_slice.sum() == 0:\n",
    "                continue\n",
    "            \n",
    "            t = time.time()\n",
    "            Y = np.concatenate([\n",
    "                session['betas'][:, i] \n",
    "                for session in sessions\n",
    "            ])\n",
    "            Y = Y[training_indices]\n",
    "            Y = Y[:, mask_slice]\n",
    "            Y = torch.from_numpy(Y).float() / 300\n",
    "            Y = (Y - Y.mean(dim=0, keepdims=True)) / Y.std(dim=0, keepdims=True)\n",
    "            #Y = Y.T[..., None]\n",
    "            \n",
    "            slice_indices = torch.from_numpy(np.argwhere(mask_slice))\n",
    "            load_time += time.time() - t\n",
    "            \n",
    "            batch_size = 100\n",
    "            Y_splits = torch.split(Y, batch_size, dim=1)\n",
    "            indices_splits = torch.split(slice_indices, batch_size)\n",
    "            for Y_batch, indices_batch in zip(Y_splits, indices_splits):\n",
    "                Y_batch = Y_batch.cuda()\n",
    "                for model_name, embeddings in subject_stimulus_embeddings.items():\n",
    "                    for embedding_name, embedding in embeddings.items():\n",
    "                        t = time.time()\n",
    "                        \n",
    "                        gc.collect()\n",
    "                        torch.cuda.empty_cache()\n",
    "\n",
    "                        keys = (subject_name, model_name, embedding_name)\n",
    "                        group = f['/'.join(keys)]\n",
    "                        X = embedding[:]\n",
    "                        \n",
    "                        #print(X.shape, Y_batch.shape, fractions.shape)\n",
    "                        #coefs, alpha, r2 = ridge_regression_cv(X, Y_batch[..., 0].T, alpha=alpha)\n",
    "                        coefs, alpha, r2, frac = frac_ridge_regression_cv(X, Y_batch, fractions)\n",
    "                        coefs = coefs.cpu().numpy()\n",
    "                        a = alpha.cpu().numpy()\n",
    "                        r2 = r2.cpu().numpy()\n",
    "                        frac = frac.cpu().numpy()\n",
    "                        \n",
    "                        compute_time += time.time() - t\n",
    "\n",
    "                        t = time.time()\n",
    "                        for v, (j, k) in enumerate(indices_batch):\n",
    "                            group['coefs'][i, j, k] = coefs[:, v]\n",
    "                            group['alpha'][i, j, k] = a[v]\n",
    "                            group['r2'][i, j, k] = r2[v]\n",
    "                            group['fractions'][i, j, k] = frac[v]\n",
    "                        store_time += time.time() - t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b939c3b-7b72-4787-89b8-c3d0854f9e63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save encoder results\n",
    "\n",
    "encoder_name = 'fracridge'\n",
    "\n",
    "with h5py.File(derivatives_path / f'{encoder_name}-parameters.hdf5', 'r') as f:\n",
    "    for subject_name, subject in f.items():\n",
    "        subject_out_path = derivatives_path / 'images' / encoder_name / subject_name\n",
    "        subject_out_path.mkdir(parents=True, exist_ok=True)\n",
    "        affine = subjects[subject_name]['brainmask'].affine\n",
    "        \n",
    "        for model_name, model in subject.items():\n",
    "            for embedding_name, embedding in model.items():\n",
    "                for image_name, image, in embedding.items():\n",
    "                    keys = (subject_name, encoder_name, model_name, embedding_name, image_name)\n",
    "                    save_file_name = f'{\"__\".join(keys)}.nii.gz'\n",
    "                    print(keys, image.shape)\n",
    "                    if len(image.shape) == 3:\n",
    "                        image = nib.Nifti1Image(image[:].T, affine)\n",
    "                    elif len(image.shape) == 4:\n",
    "                        continue\n",
    "                        image = nib.Nifti1Image(image[:].T, affine)\n",
    "                    else:\n",
    "                        continue\n",
    "                    nib.save(image, subject_out_path / save_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b941cee-5b57-4d81-ac14-8b2d3cd0eeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save sequence\n",
    "\n",
    "encoder_name = 'fracridge'\n",
    "model_name = 'ViT-B=32'\n",
    "embedding_names = [*(f'transformer.resblocks.{i}' for i in range(12)), 'embedding']\n",
    "image_names = ['alpha', 'fractions', 'r2']\n",
    "sequence_name = 'depth_sequence'\n",
    "\n",
    "with h5py.File(derivatives_path / f'{encoder_name}-parameters.hdf5', 'r') as f:\n",
    "    for subject_name, subject in f.items():\n",
    "        subject_out_path = derivatives_path / 'images' / encoder_name / subject_name\n",
    "        subject_out_path.mkdir(parents=True, exist_ok=True)\n",
    "        affine = subjects[subject_name]['brainmask'].affine\n",
    "        \n",
    "        model = subject[model_name]\n",
    "        for image_name in image_names:\n",
    "            image_data = np.stack([\n",
    "                model[embedding_name][image_name][:]\n",
    "                for embedding_name in embedding_names\n",
    "            ]).T\n",
    "            keys = (subject_name, encoder_name, model_name, sequence_name, image_name)\n",
    "            save_file_name = f'{\"__\".join(keys)}.nii.gz'\n",
    "            image = nib.Nifti1Image(image_data, affine)\n",
    "            nib.save(image, subject_out_path / save_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbde3ae4-beb0-450c-a901-d5b9fdc2513c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add feature selection indices\n",
    "\n",
    "def require_dataset(group, name, data):\n",
    "    group.require_dataset(name, shape=data.shape, dtype=data.dtype)\n",
    "    group[name][:] = data\n",
    "\n",
    "encoder_name = 'fracridge'\n",
    "\n",
    "with h5py.File(derivatives_path / f'{encoder_name}-parameters.hdf5', 'a') as f:\n",
    "    for subject_name, subject in f.items():\n",
    "        for model_name, model in subject.items():\n",
    "            for embedding_name, embedding in model.items():\n",
    "                r2 = embedding['r2'][:]\n",
    "                sorted_indices_flat = r2.argsort(axis=None)[::-1]\n",
    "                grid = np.argwhere(np.ones_like(r2, dtype=bool))\n",
    "                sorted_indices = grid[sorted_indices_flat]\n",
    "                \n",
    "                require_dataset(embedding, 'sorted_indices_flat', sorted_indices_flat)\n",
    "                require_dataset(embedding, 'sorted_indices', sorted_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85ec727-76e3-46f9-8b9e-140eaee0d856",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_name = 'fracridge'\n",
    "encoder_results = h5py.File(derivatives_path / f'{encoder_name}-parameters.hdf5', 'r')\n",
    "\n",
    "@interact(subject=encoder_results.items())\n",
    "def select_subject(subject):\n",
    "    subject_name = subject.name[1:]\n",
    "    #sessions = subjects[subject_name]['sessions']\n",
    "    betas = subjects[subject_name]['betas']\n",
    "    \n",
    "    @interact(model=subject.items())\n",
    "    def select_model(model):\n",
    "        \n",
    "        @interact(embedding=model.items())\n",
    "        def select_embedding(embedding):\n",
    "            \n",
    "            r2 = embedding['r2'][:]\n",
    "            sorted_indices_flat = r2.argsort(axis=None)[::-1]\n",
    "            grid = np.argwhere(np.ones_like(r2, dtype=bool))\n",
    "            sorted_indices = grid[sorted_indices_flat]\n",
    "            print(grid)\n",
    "            t = time.time()\n",
    "            \n",
    "            Y = np.stack([\n",
    "                betas[:, i] \n",
    "                for i in sorted_indices_flat[:2500]\n",
    "            ], axis=1)\n",
    "            \n",
    "            #for i, j, k in sorted_indices[:2500]:\n",
    "            #    Y = np.concatenate([\n",
    "            #        session['betas'][:, i, j, k]\n",
    "            #        for session in sessions\n",
    "            #    ])\n",
    "            print(time.time() - t)\n",
    "            print(Y.shape)\n",
    "        \n",
    "            @interact(w=(0, r2.shape[0]-1), num=(0, 50000))\n",
    "            def show_top(w, num):\n",
    "                selection_map = np.zeros_like(r2)\n",
    "                i, j, k = list(sorted_indices[:num].T)\n",
    "                selection_map[i, j, k] = 1\n",
    "                plt.imshow(selection_map[w].T)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a67eb4-b720-41ad-a617-335e431cc088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate sessions\n",
    "\n",
    "for subject_name, subject_data in subjects.items():\n",
    "    #if subject_name in ('subj01', 'subj02', 'subj03', 'subj04', ):\n",
    "    #    continue\n",
    "    print(subject_name)\n",
    "    path = derivatives_path / 'betas' / subject_name / 'func1pt8mm' / 'betas_fithrf_GLMdenoise_RR'\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    with h5py.File(path / 'betas_sessions_new.hdf5', 'a') as f:\n",
    "\n",
    "        sessions = subject_data['sessions']\n",
    "        num_sessions = len(sessions)\n",
    "        shape = sessions[0]['betas'].shape\n",
    "        T, W, H, D = shape\n",
    "        T_full = T * len(sessions)\n",
    "        \n",
    "        f.require_dataset('betas', shape=(T_full, W * H * D), dtype=np.int16, chunks=(T_full, 1))\n",
    "        for i in tqdm(range(W)):\n",
    "            Y = np.concatenate([\n",
    "                session['betas'][:, i]\n",
    "                for session in sessions\n",
    "            ])\n",
    "            slice_size = H * D\n",
    "            f['betas'][:, slice_size * i:slice_size * (i + 1)] = rearrange(Y, 't ... -> t (...)')\n",
    "    break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1df9f96-3e3a-441d-b72d-2f126f342f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5, 500)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rearrange(np.ones((500, 500)), '(s b) v -> s b v', s=100).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ff01ed5-309a-4320-9362-1ad1c5931615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "673200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3850e1e8d3c0429785c446ebd2f6f24f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "699192\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f40ba9f4158497a931155cb18158467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "730128\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e138614496c442faeab43796c22618c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704052\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8aa59e1201e4bc7888204d613b541a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "673200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e328734211184776966b569ba4c9cea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "597714\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d50fed1e30a4eedbfc06265b43cf5c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "797215\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c0206d61a848fab269316d782b97b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600210\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd08d264ebb6438289746f1a1fe549b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute and cache mean and std of betas for each session\n",
    "\n",
    "dataset_path = Path('D:\\\\Datasets\\\\NSD\\\\')\n",
    "space = 'func1pt8mm'\n",
    "glm = 'betas_fithrf_GLMdenoise_RR'\n",
    "\n",
    "betas_scale = 300\n",
    "betas_per_session = 750\n",
    "\n",
    "for i in range(1, 9):\n",
    "    subject_name = f'subj0{i}'\n",
    "    subject_betas_path = dataset_path / 'derivatives' / 'betas' / subject_name / space / glm\n",
    "    betas_file_path = subject_betas_path / 'betas_sessions.hdf5'\n",
    "    \n",
    "    original_session_path = dataset_path / 'nsddata_betas' / 'ppdata' / subject_name / space / glm\n",
    "    original_session = h5py.File(original_session_path / 'betas_session01.hdf5', 'r')\n",
    "    \n",
    "    with h5py.File(betas_file_path, 'a') as f:\n",
    "        print(num_voxels)\n",
    "        num_betas = f['betas'].shape[0]\n",
    "        num_voxels = f['betas'].shape[1]\n",
    "        \n",
    "        num_sessions = int(num_betas / betas_per_session)\n",
    "        spatial_shape = original_session['betas'].shape[1:]\n",
    "        \n",
    "        f['betas'].attrs['spatial_shape'] = spatial_shape\n",
    "        f.require_dataset('mean', shape=(num_sessions, num_voxels), dtype=np.float32)\n",
    "        f.require_dataset('std', shape=(num_sessions, num_voxels), dtype=np.float32)\n",
    "        indices = np.argwhere(np.ones(shape=spatial_shape, dtype=bool)).astype(int)\n",
    "        f.require_dataset('indices', shape=indices.shape, dtype=indices.dtype)\n",
    "        f['indices'][:] = indices\n",
    "        \n",
    "        num_batches = 100\n",
    "        for voxel_indices in tqdm(np.array_split(np.arange(num_voxels), num_batches)):\n",
    "            betas = f['betas'][:, voxel_indices]\n",
    "            betas = rearrange(betas, '(s b) v -> s b v', s=num_sessions, b=betas_per_session)\n",
    "            betas = betas.astype(float) / betas_scale\n",
    "            f['mean'][:, voxel_indices] = betas.mean(axis=1)\n",
    "            f['std'][:, voxel_indices] = betas.std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd82e527-7e4f-4d89-81ea-eae6825ba3cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'subjects' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5884/4171196582.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# save noise ceilings for voxel selection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msubjects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'subjects' is not defined"
     ]
    }
   ],
   "source": [
    "# save noise ceilings for voxel selection\n",
    "\n",
    "subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adcf10f-a25b-4583-ad4f-e409cb550a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save feature selection\n",
    "\n",
    "encoder_name = 'fracridge'\n",
    "\n",
    "with h5py.File(derivatives_path / f'{encoder_name}-parameters.hdf5', 'r') as f:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0561e963-4a53-4bd2-b345-fa599864ae1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder experiments on a slice\n",
    "\n",
    "subject_name = 'subj01'\n",
    "\n",
    "subject = subjects[subject_name]\n",
    "sessions = subject['sessions']\n",
    "t1 = nib.load(subject['t1_path']).get_fdata().T\n",
    "\n",
    "split_name = 'split-01'\n",
    "split = h5py.File(derivatives_path / 'data_splits' / f'{split_name}.hdf5')\n",
    "\n",
    "subject_split = split[subject_name]\n",
    "test_mask = subject_split['test_response_mask'][:].astype(bool)\n",
    "validation_mask = subject_split['validation_response_mask'][:].astype(bool)\n",
    "training_mask = ~(test_mask | validation_mask)\n",
    "training_indices = np.where(training_mask)[0]\n",
    "\n",
    "run_stimulus_embeddings = {\n",
    "    'bigbigan-resnet50': ['z_mean'],\n",
    "    'ViT-B=32': ['embedding', *(f'transformer.resblocks.{i}' for i in range(12))],\n",
    "    #'biggan-128': ['z', 'y_embedding'],\n",
    "    #'vqgan': ['vqgan-f16-1024-pre_quant'],\n",
    "}\n",
    "\n",
    "embedding_files = {\n",
    "    model_name: h5py.File(derivatives_path / 'stimulus_embeddings' / f'{model_name}-embeddings.hdf5', 'r')\n",
    "    for model_name in run_stimulus_embeddings.keys()\n",
    "}\n",
    "\n",
    "W, H, D = t1.shape\n",
    "axial_slice = 37\n",
    "saggital_slice = slice(None)\n",
    "coronal_slice = slice(-80)\n",
    "\n",
    "# Extract an interesting slice from the visual cortex\n",
    "# (time, axial, coronal, saggital)\n",
    "betas_slice = np.concatenate([\n",
    "    session['betas'][:, axial_slice, coronal_slice, saggital_slice]\n",
    "    for session in sessions\n",
    "])[training_indices]\n",
    "\n",
    "betas_slice = torch.from_numpy(betas_slice).float() / 300\n",
    "betas_slice = betas_slice - betas_slice.mean(dim=0, keepdims=True)\n",
    "betas_slice = betas_slice / (betas_slice.std(dim=0, keepdims=True) + 1e-7)\n",
    "\n",
    "mask = (subject['brainmask'].get_fdata() > 0.).T\n",
    "mask = mask[axial_slice, coronal_slice, saggital_slice]\n",
    "\n",
    "Y = betas_slice[:, mask]\n",
    "\n",
    "responses = subject['responses']\n",
    "training_stimulus_ids = responses['73KID'].to_numpy()[training_indices] - 1\n",
    "\n",
    "max_features = 512\n",
    "seed = 0\n",
    "\n",
    "subject_stimulus_embeddings = {}\n",
    "for model_name, embedding_names in run_stimulus_embeddings.items():\n",
    "    subject_stimulus_embeddings[model_name] = {}\n",
    "    for embedding_name in embedding_names:\n",
    "        keys = (subject_name, model_name, embedding_name)\n",
    "        print('loading', keys)\n",
    "\n",
    "        embedding = embedding_files[model_name][embedding_name][:][training_stimulus_ids]\n",
    "        embedding = torch.from_numpy(embedding)\n",
    "        embedding = embedding.flatten(start_dim=1)\n",
    "        if embedding.shape[1] > max_features:\n",
    "            np.random.seed(seed)\n",
    "            choice = np.random.choice(max_features, size=max_features)\n",
    "            embedding = embedding[:, choice]\n",
    "        embedding = embedding.float()\n",
    "        subject_stimulus_embeddings[model_name][embedding_name] = embedding.float().cuda()\n",
    "\n",
    "'''\n",
    "T = Y.shape[0]\n",
    "@interact(t=(0, T-1))\n",
    "def show(t):\n",
    "    plt.imshow(t1.get_fdata()[axial_slice, saggital_slice, coronal_slice],  cmap='gray')'''\n",
    "\n",
    "width=30\n",
    "@interact(w=(0, W-1), h=(width, H-width-1), d=(width, D-width-1),)\n",
    "def show(w, h, d):\n",
    "    #plt.imshow(t1[w, h-width:h+width, d-width:d+width],  cmap='gray')\n",
    "    plt.imshow(t1[axial_slice, coronal_slice, saggital_slice][::-1, ::-1], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa8f877-a654-43bc-9250-85ee3470c4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b390af0-6b63-4d9b-af29-78ff15a11dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9ce996-bd0c-4e79-a957-e615c2f0703f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_device(device, *tensors):\n",
    "    return [tensor.to(device) for tensor in tensors]\n",
    "\n",
    "X_bigbigan = subject_stimulus_embeddings['bigbigan-resnet50']['z_mean']\n",
    "X_clip = subject_stimulus_embeddings['ViT-B=32']['transformer.resblocks.3']\n",
    "\n",
    "X = X_clip.clone()\n",
    "X = X - X.mean(dim=0, keepdims=True)\n",
    "X = X / (X.std(dim=0, keepdims=True) + 1e-7)\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "'''\n",
    "alpha = 10 ** torch.linspace(1, 5, 20)\n",
    "results = [\n",
    "    to_device('cpu', *ridge_regression_cv(*to_device('cuda', X, y, alpha)))\n",
    "    for y in tqdm(torch.split(Y, 100, dim=1))\n",
    "]\n",
    "\n",
    "coefs, alpha, r2 = [\n",
    "    torch.cat([elem for elem in val], dim=-1)\n",
    "    for val in list(zip(*results))\n",
    "]'''\n",
    "\n",
    "\n",
    "fractions = torch.arange(.05, 1.05, .05)\n",
    "results = [\n",
    "    to_device('cpu', *frac_ridge_regression_cv(*to_device('cuda', X, y, fractions)))\n",
    "    for y in tqdm(torch.split(Y, 100, dim=1))\n",
    "]\n",
    "\n",
    "#results = [\n",
    "#    frac_ridge_regression_cv2(X.cpu(), y.cpu(), fractions)\n",
    "#    for y in tqdm(torch.split(Y, 100, dim=1))\n",
    "#]\n",
    "\n",
    "coefs, alpha, r2, frac = [\n",
    "    torch.cat([elem for elem in val], dim=-1)\n",
    "    for val in list(zip(*results))\n",
    "]\n",
    "\n",
    "'''\n",
    "frac = []\n",
    "alpha = []\n",
    "r2 = []\n",
    "coefs = []\n",
    "fractions = np.arange(.05, 1.05, .05)\n",
    "for i in tqdm(range(Y.shape[1])):\n",
    "    model = FracRidgeRegressorCV(frac_grid=fractions, cv=5)\n",
    "    model.fit(X.cpu().numpy(), Y[:, i].cpu().numpy())\n",
    "    frac.append(model.best_frac_)\n",
    "    alpha.append(model.alpha_.item())\n",
    "    r2.append(model.best_score_)\n",
    "    coefs.append(model.coef_)\n",
    "frac = np.array(frac)\n",
    "alpha = np.array(alpha)\n",
    "r2 = np.array(r2)\n",
    "coefs = np.stack(coefs)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a9ff31-d8e0-42b6-98d8-0503a5af3f42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[coefs[:, i].isnan().sum() for i in range(coefs.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8e71cb-369c-402a-8261-d912f061b942",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice = np.zeros_like(mask, dtype=float)\n",
    "plot_slice[mask] = frac\n",
    "\n",
    "print(plot_slice.max())\n",
    "plt.imshow(plot_slice[::-1, ::-1], vmin=0, vmax=plot_slice.max(), cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74d5366-946f-49f5-bc7b-a95a70e9b4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522757a3-0db9-4fca-a635-087d536a3d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "coefs, alpha = frac_ridge_regression(*to_device('cuda', X, Y[:, 0:1], fractions))\n",
    "print(time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5878a5b-c195-4e55-82bc-a376fd3dc664",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from fracridge import fracridge\n",
    "\n",
    "t = time.time()\n",
    "coefs, alphas = fracridge(X.cpu().numpy(), Y.cpu().numpy(), fractions.cpu().numpy())\n",
    "print(time.time() - t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0d7cce-6acd-4eec-bbe1-9f7f4d2ca553",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fracridge.fracridge import _do_svd\n",
    "BIG_BIAS = 10e3\n",
    "SMALL_BIAS = 10e-3\n",
    "BIAS_STEP = 0.2\n",
    "from numpy import interp\n",
    "from sklearn.model_selection import KFold\n",
    "from einops import rearrange\n",
    "    \n",
    "\n",
    "def fracridge(X, y, fracs=None, tol=1e-10, jit=True):\n",
    "    \"\"\"\n",
    "    Approximates alpha parameters to match desired fractions of OLS length.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray, shape (n, p)\n",
    "        Design matrix for regression, with n number of\n",
    "        observations and p number of model parameters.\n",
    "    y : ndarray, shape (n, b)\n",
    "        Data, with n number of observations and b number of targets.\n",
    "    fracs : float or 1d array, optional\n",
    "        The desired fractions of the parameter vector length, relative to\n",
    "        OLS solution. If 1d array, the shape is (f,). This input is required\n",
    "        to be sorted. Otherwise, raises ValueError.\n",
    "        Default: np.arange(.1, 1.1, .1).\n",
    "    jit : bool, optional\n",
    "        Whether to speed up computations by using a just-in-time compiled\n",
    "        version of core computations. This may not work well with very large\n",
    "        datasets. Default: True\n",
    "    Returns\n",
    "    -------\n",
    "    coef : ndarray, shape (p, f, b)\n",
    "        The full estimated parameters across units of measurement for every\n",
    "        desired fraction.\n",
    "    alphas : ndarray, shape (f, b)\n",
    "        The alpha coefficients associated with each solution\n",
    "    Examples\n",
    "    --------\n",
    "    Generate random data:\n",
    "    >>> np.random.seed(0)\n",
    "    >>> y = np.random.randn(100)\n",
    "    >>> X = np.random.randn(100, 10)\n",
    "    Calculate coefficients with naive OLS:\n",
    "    >>> coef = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "    >>> print(np.linalg.norm(coef))  # doctest: +NUMBER\n",
    "    0.35\n",
    "    Call fracridge function:\n",
    "    >>> coef2, alpha = fracridge(X, y, 0.3)\n",
    "    >>> print(np.linalg.norm(coef2))  # doctest: +NUMBER\n",
    "    0.10\n",
    "    >>> print(np.linalg.norm(coef2) / np.linalg.norm(coef))  # doctest: +NUMBER\n",
    "    0.3\n",
    "    Calculate coefficients with naive RR:\n",
    "    >>> alphaI = alpha * np.eye(X.shape[1])\n",
    "    >>> coef3 = np.linalg.inv(X.T @ X + alphaI) @ X.T @ y\n",
    "    >>> print(np.linalg.norm(coef2 - coef3))  # doctest: +NUMBER\n",
    "    0.0\n",
    "    \"\"\"\n",
    "    if fracs is None:\n",
    "        fracs = np.arange(.1, 1.1, .1)\n",
    "\n",
    "    if hasattr(fracs, \"__len__\"):\n",
    "        if np.any(np.diff(fracs) < 0):\n",
    "            raise ValueError(\"The `frac` inputs to the `fracridge` function \",\n",
    "                             f\"must be sorted. You provided: {fracs}\")\n",
    "\n",
    "    else:\n",
    "        fracs = [fracs]\n",
    "    fracs = np.array(fracs)\n",
    "\n",
    "    nn, pp = X.shape\n",
    "    if len(y.shape) == 1:\n",
    "        y = y[:, np.newaxis]\n",
    "\n",
    "    bb = y.shape[-1]\n",
    "    ff = fracs.shape[0]\n",
    "    print(y.dtype)\n",
    "\n",
    "    # Calculate the rotation of the data\n",
    "    selt, v_t, ols_coef = _do_svd(X, y, jit=jit)\n",
    "    print(f'{selt.dtype=}, {v_t.dtype=}, {ols_coef.dtype=}')\n",
    "\n",
    "    # Set solutions for small eigenvalues to 0 for all targets:\n",
    "    isbad = selt < tol\n",
    "    if np.any(isbad):\n",
    "        warnings.warn(\"Some eigenvalues are being treated as 0\")\n",
    "\n",
    "    ols_coef[isbad, ...] = 0\n",
    "\n",
    "    # Limits on the grid of candidate alphas used for interpolation:\n",
    "    val1 = BIG_BIAS * selt[0] ** 2\n",
    "    val2 = SMALL_BIAS * selt[-1] ** 2\n",
    "\n",
    "    # Generates the grid of candidate alphas used in interpolation:\n",
    "    alphagrid = np.concatenate(\n",
    "        [np.array([0]),\n",
    "         10 ** np.arange(np.floor(np.log10(val2)),\n",
    "                         np.ceil(np.log10(val1)), BIAS_STEP)])\n",
    "    print(f'{alphagrid.dtype=}')\n",
    "\n",
    "    # The scaling factor applied to coefficients in the rotated space is\n",
    "    # lambda**2 / (lambda**2 + alpha), where lambda are the singular values\n",
    "    seltsq = selt**2\n",
    "    sclg = seltsq / (seltsq + alphagrid[:, None])\n",
    "    sclg_sq = sclg**2\n",
    "    print(f'{sclg_sq.dtype=} {sclg.dtype=}')\n",
    "\n",
    "    # Prellocate the solution:\n",
    "    if nn >= pp:\n",
    "        first_dim = pp\n",
    "    else:\n",
    "        first_dim = nn\n",
    "\n",
    "    coef = np.empty((first_dim, ff, bb))\n",
    "    alphas = np.empty((ff, bb))\n",
    "    print(f'{coef.dtype=} {alphas.dtype=}')\n",
    "\n",
    "    # The main loop is over targets:\n",
    "    for ii in range(y.shape[-1]):\n",
    "        # Applies the scaling factors per alpha\n",
    "        newlen = np.sqrt(sclg_sq @ ols_coef[..., ii]**2).T\n",
    "        # Normalize to the length of the unregularized solution,\n",
    "        # because (alphagrid[0] == 0)\n",
    "        newlen = (newlen / newlen[0])\n",
    "        # Perform interpolation in a log transformed space (so it behaves\n",
    "        # nicely), avoiding log of 0.\n",
    "        temp = interp(fracs, newlen[::-1], np.log(1 + alphagrid)[::-1])\n",
    "        print(f'{temp.dtype=} {newlen.dtype=}')\n",
    "        # Undo the log transform from the previous step\n",
    "        targetalphas = np.exp(temp) - 1\n",
    "        # Allocate the alphas for this target:\n",
    "        alphas[:, ii] = targetalphas\n",
    "        # Calculate the new scaling factor, based on the interpolated alphas:\n",
    "        sc = seltsq / (seltsq + targetalphas[np.newaxis].T)\n",
    "        # Use the scaling factor to calculate coefficients in the rotated\n",
    "        # space:\n",
    "        coef[..., ii] = (sc * ols_coef[..., ii]).T\n",
    "\n",
    "    # After iterating over all targets, we unrotate using the unitary v\n",
    "    # matrix and reshape to conform to desired output:\n",
    "    coef = np.reshape(v_t.T @ coef.reshape((first_dim, ff * bb)),\n",
    "                      (pp, ff, bb))\n",
    "\n",
    "    return coef.squeeze(), alphas\n",
    "\n",
    "def frac_ridge_regression_cv2(X, Y, fractions=None, cv=5, tol=1e-6):\n",
    "    if fractions is None:\n",
    "        fractions = torch.arange(.1, 1.1, .1)\n",
    "\n",
    "    kf = KFold(n_splits=cv, shuffle=True)\n",
    "    r2 = []\n",
    "    for train_ids, val_ids in kf.split(np.arange(X.shape[-2])):\n",
    "        X_train = X[..., train_ids, :]\n",
    "        Y_train = Y[..., train_ids, :]\n",
    "        X_val = X[..., val_ids, :]\n",
    "        Y_val = Y[..., val_ids, :]\n",
    "        \n",
    "        coef, alpha = fracridge(X_train.numpy(), Y_train.numpy(), fractions.numpy())\n",
    "        coef = torch.from_numpy(coef).float()\n",
    "        alpha = torch.from_numpy(alpha).float()\n",
    "        #print(X_val.shape, coef.shape)\n",
    "        \n",
    "        Y_val_pred = torch.einsum('... n p, ... p f b -> ... f n b', X_val, coef)\n",
    "        r2.append(rsquared(Y_val[..., None, :, :], Y_val_pred, dim=-2))\n",
    "    r2 = torch.stack(r2).mean(dim=0)\n",
    "    best_r2, best_fraction_ids = r2.max(dim=-2)\n",
    "    best_fractions = fractions[best_fraction_ids]\n",
    "\n",
    "    #best_coefs, best_alpha = fracridge(X.numpy(), Y.numpy(), best_fractions[None].numpy())\n",
    "    return coef, alpha, best_r2, best_fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb40528c-21df-40e5-b0b2-16ccc2376194",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_diff = r2_reg - r2\n",
    "max_diff = torch.max(r2_diff.abs())\n",
    "\n",
    "plot_slice[mask] = r2_diff\n",
    "\n",
    "plt.imshow(plot_slice[::-1, ::-1], vmin=-max_diff, vmax=max_diff, cmap='bwr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987b0f52-9d23-41ec-9ea4-1e51a24d40b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_clip[:100]\n",
    "X = X - X.mean(dim=0, keepdims=True)\n",
    "X = X / (X.std(dim=0, keepdims=True) + 1e-7)\n",
    "\n",
    "y = np.stack([np.arange(X.shape[1]) for _ in range(X.shape[0])])\n",
    "\n",
    "plt.figure(figsize=(24, 8))\n",
    "plt.scatter(y.flatten(), X.flatten().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a83cad-6811-47b5-9204-eaaf47562ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bigbigan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b71a59d-bf44-4dbe-a6a1-73097b3523f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1777adb8-8d6d-427a-89e5-a3ca3c7585bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch implementation of ridge\n",
    "\n",
    "\n",
    "'''\n",
    "N = int(10000)\n",
    "batch_size = 100\n",
    "embedding_size = 512\n",
    "t = time.time()\n",
    "for i in tqdm(range(N // batch_size)):\n",
    "    X = torch.randn(21750, embedding_size).cuda()\n",
    "    Y = torch.randn(21750, batch_size).cuda()\n",
    "    alpha = 10 ** torch.linspace(1, 5, 20).cuda()\n",
    "    coefs, alpha, r2 = ridge_regression_cv(X, Y, alpha=alpha)\n",
    "    print(f'{coefs.shape=}, {alpha.shape=}, {r2.shape=}')\n",
    "    break'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9335ec-f852-4261-b607-6c2981fb23c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894061d6-600a-426a-aade-264356b38c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Neurophysiological-Data-Decoding",
   "language": "python",
   "name": "neurophysiological-data-decoding"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
