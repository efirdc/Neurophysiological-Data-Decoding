{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c9f7d05-c175-486e-bdb0-cb57c1f99170",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import gc\n",
    "from typing import Tuple, Optional, Dict\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import torchio as tio\n",
    "import h5py\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import nibabel as nib\n",
    "from einops import rearrange\n",
    "from scipy import ndimage\n",
    "import wandb\n",
    "\n",
    "dir2 = os.path.abspath('../..')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: \n",
    "    sys.path.append(dir1)\n",
    "\n",
    "from research.data.natural_scenes import (\n",
    "    NaturalScenesDataset\n",
    ")\n",
    "from research.models.components_2d import BlurConvTranspose2d\n",
    "from research.models.fmri_decoders import VariationalDecoder, SpatialDecoder, SpatialDiscriminator, Decoder\n",
    "from research.metrics.loss_functions import (\n",
    "    EuclideanLoss, \n",
    "    EmbeddingClassifierLoss,\n",
    "    ProbabalisticCrossEntropyLoss,\n",
    "    VariationalLoss,\n",
    "    CosineSimilarityLoss,\n",
    "    EmbeddingDistributionLoss,\n",
    "    ContrastiveDistanceLoss,\n",
    ")\n",
    "from research.experiments.nsd_decoding import NSDExperiment\n",
    "from research.metrics.metrics import (\n",
    "    cosine_similarity, \n",
    "    r2_score,\n",
    "    pearsonr, \n",
    "    embedding_distance,\n",
    "    cosine_distance,\n",
    "    squared_euclidean_distance,\n",
    "    contrastive_score,\n",
    "    two_versus_two,\n",
    "    smooth_euclidean_distance,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e9b0741-0824-482f-b8a8-0edb821c9d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path('D:\\\\Datasets\\\\NSD\\\\')\n",
    "dataset = NaturalScenesDataset(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d689b6e1-3897-4686-875e-fdc74bd788cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.subjects['subj01']['betas'][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee9f647-2483-4238-8bd0-9c2e38e638a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_params = dict(\n",
    "    subject_name='subj01',\n",
    "    model_name='DPT_Large',\n",
    "    embedding_name='transformer.resblocks.0',\n",
    "    encoder_name='fracridge',\n",
    "    split_name='split-01',\n",
    "    num_voxels=2500,\n",
    "    normalize_X=True,\n",
    "    normalize_Y=False,\n",
    ")\n",
    "train, val, test = dataset.load_data(**dataset_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Neurophysiological-Data-Decoding",
   "language": "python",
   "name": "neurophysiological-data-decoding"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
