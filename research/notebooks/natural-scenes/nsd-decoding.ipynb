{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "966b46e7-8338-4383-99c5-7bd69ca0ad71",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 127] The specified procedure could not be found. Error loading \"C:\\Users\\Cefir\\anaconda3\\envs\\Neurophysiological-Data-Decoding\\lib\\site-packages\\torch\\lib\\torch_cuda_cpp.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2240/1123730706.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Neurophysiological-Data-Decoding\\lib\\site-packages\\torch\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    122\u001b[0m                 \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWinError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m                 \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrerror\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34mf' Error loading \"{dll}\" or one of its dependencies.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                 \u001b[0mis_loaded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 127] The specified procedure could not be found. Error loading \"C:\\Users\\Cefir\\anaconda3\\envs\\Neurophysiological-Data-Decoding\\lib\\site-packages\\torch\\lib\\torch_cuda_cpp.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import gc\n",
    "from typing import Tuple, Optional, Dict\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import torchio as tio\n",
    "import h5py\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import nibabel as nib\n",
    "from einops import rearrange\n",
    "from scipy import ndimage\n",
    "import wandb\n",
    "\n",
    "dir2 = os.path.abspath('../..')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: \n",
    "    sys.path.append(dir1)\n",
    "\n",
    "from research.data.natural_scenes import (\n",
    "    NaturalScenesDataset\n",
    ")\n",
    "from research.models.components_2d import BlurConvTranspose2d\n",
    "from research.models.fmri_decoders import VariationalDecoder, SpatialDecoder, SpatialDiscriminator, Decoder\n",
    "from research.metrics.loss_functions import (\n",
    "    EuclideanLoss, \n",
    "    EmbeddingClassifierLoss,\n",
    "    ProbabalisticCrossEntropyLoss,\n",
    "    VariationalLoss,\n",
    "    CosineSimilarityLoss,\n",
    "    EmbeddingDistributionLoss,\n",
    "    ContrastiveDistanceLoss,\n",
    ")\n",
    "from research.experiments.nsd_decoding import NSDExperiment\n",
    "from research.metrics.metrics import (\n",
    "    cosine_similarity, \n",
    "    r2_score,\n",
    "    pearsonr, \n",
    "    embedding_distance,\n",
    "    cosine_distance,\n",
    "    squared_euclidean_distance,\n",
    "    contrastive_score,\n",
    "    two_versus_two,\n",
    "    smooth_euclidean_distance,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfbdc4c-bc7b-489e-a0f6-25eeb3df479b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path('D:\\\\Datasets\\\\NSD\\\\')\n",
    "dataset = NaturalScenesDataset(dataset_path)\n",
    "dataset_params = dict(\n",
    "    subject_name='subj01',\n",
    "    model_name='ViT-B=32',\n",
    "    embedding_name='transformer.resblocks.0',\n",
    "    encoder_name='fracridge',\n",
    "    split_name='split-01',\n",
    "    num_voxels=2500,\n",
    "    normalize_X=True,\n",
    "    normalize_Y=False,\n",
    ")\n",
    "train, val, test = dataset.load_data(**dataset_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628a439c-cd84-4058-bb38-afe34754bbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "        embedding_name: str, \n",
    "        batch_size: int = 128,\n",
    "        group: str = None,\n",
    "        max_iterations: int = 10001,\n",
    "        notes: str = None\n",
    "):\n",
    "    cosine_embedding = embedding_name == 'embedding'\n",
    "    dataset_path = Path('D:\\\\Datasets\\\\NSD\\\\')\n",
    "    dataset = NaturalScenesDataset(dataset_path)\n",
    "    dataset_params = dict(\n",
    "        subject_name='subj01',\n",
    "        model_name='ViT-B=32',\n",
    "        embedding_name=embedding_name,\n",
    "        encoder_name='fracridge',\n",
    "        split_name='split-01',\n",
    "        num_voxels=2500,\n",
    "        normalize_X=True,\n",
    "        normalize_Y=(not cosine_embedding),\n",
    "    )\n",
    "    train, val, test = dataset.load_data(**dataset_params)\n",
    "    \n",
    "    model_params = dict(\n",
    "        hidden_size=5000,\n",
    "        dropout_p=0.9,\n",
    "        normalize=cosine_embedding,\n",
    "    )\n",
    "    model = Decoder(num_voxels=dataset_params['num_voxels'], out_size=train.Y.shape[1], **model_params)\n",
    "    \n",
    "    criterion_params = dict(distance_metric=cosine_distance if cosine_embedding else squared_euclidean_distance)\n",
    "    criterion = ContrastiveDistanceLoss(**criterion_params)\n",
    "    \n",
    "    #criterion_params = dict()\n",
    "    #criterion = CosineSimilarityLoss() if cosine_embedding else nn.MSELoss()\n",
    "\n",
    "    optimizer_params = dict(lr=1e-4)\n",
    "    optimizer = Adam(\n",
    "        params=[*model.parameters(), *criterion.parameters()],\n",
    "        **optimizer_params,\n",
    "    )\n",
    "\n",
    "    device = torch.device('cuda')\n",
    "    model.to(device)\n",
    "    \n",
    "    training_params = dict(\n",
    "        train_on_averaged=False,\n",
    "        batch_size=batch_size,\n",
    "        evaluation_interval=2500,\n",
    "        evaluation_subset_size=500,\n",
    "    )\n",
    "    experiment = NSDExperiment(train, val, test, device, model, criterion, optimizer, **training_params)\n",
    "    \n",
    "    config = {\n",
    "        **dataset_params,\n",
    "        **training_params,\n",
    "        'model': model,\n",
    "        **model_params,\n",
    "        'criterion': criterion,\n",
    "        **criterion_params,\n",
    "        'optimizer': optimizer,\n",
    "        **optimizer_params,\n",
    "    }\n",
    "    wandb.init(project='natural-scenes', config=config, group=group, notes=notes)\n",
    "    wandb.define_metric(\"*\", summary=\"max\")\n",
    "    wandb.define_metric(\"*\", summary=\"min\")\n",
    "    \n",
    "    experiment.train_model(max_iterations=max_iterations, logger=wandb.log)\n",
    "    \n",
    "    return experiment\n",
    "\n",
    "def save_experiment(experiment):\n",
    "    decoded_features_path = Path('D:\\\\Datasets\\\\NSD\\\\derivatives\\\\decoded_features\\\\')\n",
    "    save_file_name = wandb.run.group if wandb.run.group else wandb.run.name\n",
    "    save_file_path = decoded_features_path / wandb.config['model_name'] / f'{save_file_name}.hdf5'\n",
    "    h5_key = (wandb.config['subject_name'], wandb.config['embedding_name'])\n",
    "    attributes = dict(wandb.config)\n",
    "    attributes['wandb_run_name'] = wandb.run.name\n",
    "    attributes['wandb_run_url'] = wandb.run.url\n",
    "    attributes['wandb_group'] = wandb.run.group\n",
    "    attributes['wandb_notes'] = wandb.run.notes\n",
    "    experiment.save(save_file_path, attributes, h5_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0f846a-cbcd-4300-ac68-24d28f35a766",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_params = {\n",
    "    'group': 'group-1',\n",
    "    #'notes': 'Contrastive loss -> mean distance loss. normalize_y for resblocks.',\n",
    "    'max_iterations': 10001,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c685df-c110-484d-8881-346cb848408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = run_experiment('embedding', **shared_params)\n",
    "save_experiment(experiment)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09ec1ef-1329-4470-8b19-33dc33800b25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_names = [f'transformer.resblocks.{i}' for i in range(6, 12)]\n",
    "for embedding_name in embedding_names:\n",
    "    experiment = None\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    experiment = run_experiment(embedding_name, batch_size=24, **shared_params)\n",
    "    save_experiment(experiment)\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aed34d-4b88-4361-877c-0f7f761c18f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb.finish()\n",
    "experiment = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb08e2c-2e74-4df1-95e9-2e86fffbeddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'name': 'clip-embeddings',\n",
    "    'method': 'grid',\n",
    "    'parameters': {\n",
    "        'embedding_name': {\n",
    "            'values': [f'transformer.resblocks.{i}' for i in range(12)]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdea1ca4-9296-4b67-b4ee-49c851a8b142",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.train_model(max_iterations=3500, logger=wandb.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0525e4-97a0-478e-bbbe-5e786437b2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'D:/Datasets/NSD/derivatives/decoded_features/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d307b16a-7a41-4337-a130-fd0406e887b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "runs = api.runs('efirdc/natural-scenes') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912a3ddd-c85a-4397-81b8-f017a09ac6e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for run in runs:\n",
    "    print(run.history())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8215305d-83b6-422c-85ac-ab90159bb6c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run = runs[0]\n",
    "run.summary['_step']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22de7bd-c090-4137-99cb-1395ebb731d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.perf_counter()\n",
    "experiment.evaluate()\n",
    "print(time.perf_counter() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81551d1e-a9c4-4adc-9f75-00658c51c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Optional, Dict\n",
    "from functools import partial\n",
    "\n",
    "import wandb\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from research.models.components_2d import BlurConvTranspose2d\n",
    "from research.models.fmri_decoders import VariationalDecoder, SpatialDecoder, SpatialDiscriminator, Decoder\n",
    "from research.metrics.loss_functions import (\n",
    "    EuclideanLoss, \n",
    "    EmbeddingClassifierLoss,\n",
    "    ProbabalisticCrossEntropyLoss,\n",
    "    VariationalLoss,\n",
    "    CosineSimilarityLoss,\n",
    "    EmbeddingDistributionLoss,\n",
    "    ContrastiveDistanceLoss,\n",
    ")\n",
    "\n",
    "from research.metrics.metrics import (\n",
    "    cosine_similarity, \n",
    "    r2_score,\n",
    "    pearsonr, \n",
    "    embedding_distance,\n",
    "    cosine_distance,\n",
    "    squared_euclidean_distance,\n",
    "    contrastive_score,\n",
    "    two_versus_two,\n",
    "    smooth_euclidean_distance,\n",
    ")\n",
    "\n",
    "#model = VariationalDecoder(\n",
    "#    num_voxels, out_size, hidden_size, \n",
    "#    #decoder_class=decoder_class,\n",
    "#    #decoder_params=decoder_params,\n",
    "#)\n",
    "\n",
    "\n",
    "model_params = dict(\n",
    "    hidden_size=5000,\n",
    "    dropout_p=0.9,\n",
    ")\n",
    "model = Decoder(num_voxels=dataset_params['num_voxels'], out_size=train.Y.shape[1], **model_params)\n",
    "\n",
    "training_params = dict(train_on_averaged=False)\n",
    "#criterion = ContrastiveDistanceLoss(distance_metric=partial(smooth_euclidean_distance, beta=0.25))\n",
    "\n",
    "#criterion = nn.MSELoss()\n",
    "#criterion = CosineSimilarityLoss()\n",
    "#criterion = nn.L1Loss()\n",
    "#criterion = VariationalLoss(distance_loss=criterion, kld_weight=training_params['kld_weight'])\n",
    "\n",
    "criterion_params = dict(distance_metric=cosine_distance)\n",
    "criterion = ContrastiveDistanceLoss(**criterion_params)\n",
    "\n",
    "optimizer_params = dict(lr=1e-4)\n",
    "optimizer = Adam(\n",
    "    params=[*model.parameters(), *criterion.parameters()],\n",
    "    **optimizer_params,\n",
    ")\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model.to(device)\n",
    "\n",
    "train_dataset = train.torch_dataset(training_params['train_on_averaged'])\n",
    "dataloader = DataLoader(train_dataset, shuffle=True, batch_size=128)\n",
    "def get_data_iterator(loader):\n",
    "    while True:\n",
    "        for batch in loader:\n",
    "            yield batch\n",
    "data_iterator = get_data_iterator(dataloader)\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "def run_all(X):\n",
    "    Y = []\n",
    "    for x in X:\n",
    "        y = model(x.to(device)[None])\n",
    "        if isinstance(y, Tuple):\n",
    "            y = y[0]\n",
    "        Y.append(y)\n",
    "    return torch.cat(Y).cpu()\n",
    "\n",
    "evaluation_metrics = [r2_score, pearsonr]\n",
    "distance_metrics = [cosine_distance, squared_euclidean_distance]\n",
    "distance_classification_measures = [two_versus_two, contrastive_score]\n",
    "def evaluate():\n",
    "    evaluation_dict = {}\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        Y_train_pred = run_all(train_dataset.tensors[0])\n",
    "        Y_val_pred = run_all(val.X)\n",
    "        Y_val_avg_pred = run_all(val.X_averaged)\n",
    "        \n",
    "    for evaluation_metric in evaluation_metrics:\n",
    "        evaluation_dict[evaluation_metric.__name__] = {\n",
    "            'train': evaluation_metric(train_dataset.tensors[1], Y_train_pred),\n",
    "            'val': evaluation_metric(val.Y, Y_val_pred),\n",
    "            'val_averaged': evaluation_metric(val.Y_averaged, Y_val_avg_pred),\n",
    "        }\n",
    "\n",
    "    for distance_metric in distance_metrics:\n",
    "        distances = {}\n",
    "        distances['train'] = distance_metric(train_dataset.tensors[1][None, :], Y_train_pred[:, None])\n",
    "        distances['val'] = distance_metric(val.Y[None, :], Y_val_pred[:, None])\n",
    "        distances['val_averaged'] = distance_metric(val.Y_averaged[None, :], Y_val_avg_pred[:, None])\n",
    "        stats = {\n",
    "            measure.__name__: {\n",
    "                d_name: measure(d).item() for d_name, d in distances.items()\n",
    "            }\n",
    "            for measure in distance_classification_measures\n",
    "        }\n",
    "        stats.update({\n",
    "            'mean': {d_name: d.diag().mean().item() for d_name, d in distances.items()},\n",
    "            'std': {d_name: d.diag().std().item() for d_name, d in distances.items()},\n",
    "        })\n",
    "        evaluation_dict[distance_metric.__name__] = stats\n",
    "    \n",
    "    return evaluation_dict\n",
    "\n",
    "wandb.init(\n",
    "    project='natural-scenes',\n",
    "    config={\n",
    "        **dataset_params,\n",
    "        **training_params,\n",
    "        'model': model,\n",
    "        **model_params,\n",
    "        'criterion': criterion,\n",
    "        **criterion_params,\n",
    "        'optimizer': optimizer,\n",
    "        **optimizer_params,\n",
    "    },\n",
    ")\n",
    "wandb.define_metric(\"*\", summary=\"max\")\n",
    "wandb.define_metric(\"*\", summary=\"min\")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8b50e1-e99b-4815-a55b-f5021a35f97b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_iterations = 1500\n",
    "for i in range(max_iterations):\n",
    "    evaluation_dict = {}\n",
    "    if iteration % 250 == 0:\n",
    "        evaluation_dict = evaluate()\n",
    "    \n",
    "    x, y = next(data_iterator)\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    model.train()\n",
    "    model_out = model(x)\n",
    "    if isinstance(model_out, Tuple):\n",
    "        y_pred, mu, log_var = model_out\n",
    "        loss, loss_dict = criterion(y, y_pred, mu, log_var)\n",
    "    else:\n",
    "        y_pred = model_out\n",
    "        loss = criterion(y, y_pred)\n",
    "        loss_dict = {'loss': loss}\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    model.eval()\n",
    "    \n",
    "    log_dict = {**loss_dict, **evaluation_dict}\n",
    "    wandb.log(log_dict)\n",
    "    \n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d942ee-01e8-4815-ae55-e84594151d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    Y_train_pred = run_all(train_dataset.tensors[0])\n",
    "    Y_val_pred = run_all(val.X)\n",
    "    Y_val_avg_pred = run_all(val.X_averaged)\n",
    "\n",
    "for evaluation_metric in evaluation_metrics:\n",
    "    evaluation_dict[evaluation_metric.__name__] = {\n",
    "        'train': evaluation_metric(train_dataset.tensors[1], Y_train_pred),\n",
    "        'val': evaluation_metric(val.Y, Y_val_pred),\n",
    "        'val_averaged': evaluation_metric(val.Y_averaged, Y_val_avg_pred),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eff0235-c26a-4f13-a0d0-403bc637a24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val_pred.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9574865e-f498-407d-b310-150618245829",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b12abd0-abf9-4104-b5f2-84d8be63cb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d2f050-59af-4681-8124-aa4f80589b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "out_path = derivatives_path / 'decoded_features'\n",
    "\n",
    "def run_all_variational(X):\n",
    "    mean = []\n",
    "    std = []\n",
    "    for x in X:\n",
    "        _, mu, log_var = model(x.to(device)[None])\n",
    "        mean.append(mu)\n",
    "        std.append(torch.exp(0.5 * log_var))\n",
    "    mean = torch.cat(mean)\n",
    "    std = torch.cat(std)\n",
    "    out = torch.stack([mean, std], dim=1)\n",
    "    return out.cpu().numpy()\n",
    "\n",
    "with torch.no_grad():\n",
    "    Y_val_pred = run_all_variational(X_val).cpu().numpy()\n",
    "    Y_val_avg_pred = run_all_variational(X_val_avg).cpu().numpy()\n",
    "\n",
    "version = '1-0'\n",
    "code_name = 'averaging'\n",
    "out_dir = out_path / embedding_model / embedding_key / subject_name\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.save(out_dir / f'Y_val_pred__{code_name}__v{version}.npy', Y_val_pred)\n",
    "np.save(out_dir / f'Y_val__{code_name}__v{version}.npy', Y_val)\n",
    "\n",
    "np.save(out_dir / f'Y_val_avg_pred__{code_name}__v{version}.npy', Y_val_avg_pred)\n",
    "np.save(out_dir / f'Y_val_avg__{code_name}__v{version}.npy', Y_val_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f301d79-da2a-48f2-b9b3-96a56f65b01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "out_path = derivatives_path / 'decoded_features'\n",
    "\n",
    "with torch.no_grad():\n",
    "    Y_val_pred = run_all(X_val)\n",
    "    Y_val_avg_pred = run_all(X_val_avg)\n",
    "\n",
    "version = '1-0'\n",
    "code_name = 'standard'\n",
    "out_dir = out_path / embedding_model / embedding_key / subject_name\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.save(out_dir / f'Y_val_pred__{code_name}__v{version}.npy', Y_val_pred)\n",
    "np.save(out_dir / f'Y_val__{code_name}__v{version}.npy', Y_val)\n",
    "\n",
    "np.save(out_dir / f'Y_val_avg_pred__{code_name}__v{version}.npy', Y_val_avg_pred)\n",
    "np.save(out_dir / f'Y_val_avg__{code_name}__v{version}.npy', Y_val_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa23b86e-07b3-45ae-9d38-5e07f9d19c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_samples = 4\n",
    "Y_pred_mean = Y_val_pred[:, 0]\n",
    "Y_pred_std = Y_val_pred[:, 1]\n",
    "sample = np.random.randn(num_samples, *Y_pred_mean.shape)\n",
    "Y_pred = Y_pred_mean[None] + Y_pred_std[None] * sample\n",
    "Y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf42d86-65fc-41b8-b232-60d321f50788",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530bcdd2-1c08-4bc6-a770-94c226405ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = euclidean_distance(Y1[None, :], Y2[:, None])\n",
    "different = distances + distances.T\n",
    "\n",
    "distances_diag = torch.diag(distances)\n",
    "same = distances_diag[None, :] + distances_diag[:, None]\n",
    "\n",
    "comparison = same < different\n",
    "\n",
    "plt.imshow(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30986bd1-8932-4c6f-90e2-52988a62574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "distances = euclidean_distance(Y1[None, :], Y2[:, None])\n",
    "column_score = ((distances < distances.diag()).sum(dim=0) / (N - 1)).mean()\n",
    "row_score = ((distances < distances.diag()[:, None]).sum(dim=1) / (N - 1)).mean()\n",
    "print(column_score, row_score)\n",
    "plt.imshow(distances < distances.diag())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf37836-8f99-47f2-9b57-dd6216bc54e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_score(Y, Y_pred, dim=0, cast_dtype=torch.float64):\n",
    "    Y = Y.to(torch.float64)\n",
    "    Y_pred = Y_pred.to(torch.float64)\n",
    "\n",
    "    Y = Y - Y.mean(dim=dim, keepdim=True)\n",
    "    Y_pred = Y_pred - Y_pred.mean(dim=dim, keepdim=True)\n",
    "\n",
    "    Y = Y / torch.norm(Y, dim=dim, keepdim=True)\n",
    "    Y_pred = Y_pred / torch.norm(Y_pred, dim=dim, keepdim=True)\n",
    "\n",
    "    r = (Y * Y_pred).sum(dim=dim)\n",
    "    print(r)\n",
    "    return r.mean().item()\n",
    "\n",
    "test_score(val.Y, Y_val_pred / Y_val_pred.norm(dim=1, keepdim=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bea7f50-5b24-40a2-b2e0-00f405230253",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(val.Y.shape)\n",
    "Y_norm = Y_val_pred / Y_val_pred.norm(dim=1, keepdim=True)\n",
    "\n",
    "@interact(i=(0, 512), j=(0, 3000))\n",
    "def show(i, j):\n",
    "    x = np.arange(val.Y.shape[0])\n",
    "    y = val.Y[:, i]\n",
    "    y_pred = Y_norm[:, i]\n",
    "    plt.figure(figsize=(24, 8))\n",
    "    plt.plot(x[:j], y[:j])\n",
    "    plt.plot(x[:j], y_pred[:j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f75589-3740-4e83-b62f-e6428f8d91ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "constrastive_distance(Y1, Y2, distance_measure=euclidean_distance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Neurophysiological-Data-Decoding",
   "language": "python",
   "name": "neurophysiological-data-decoding"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
