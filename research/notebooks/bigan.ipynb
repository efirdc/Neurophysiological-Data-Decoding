{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-withdrawal",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import IPython.display\n",
    "import PIL.Image\n",
    "from pprint import pformat\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "dir2 = os.path.abspath('..')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: \n",
    "    sys.path.append(dir1)\n",
    "    \n",
    "from research.scripts.bigbigan import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-thanksgiving",
   "metadata": {},
   "outputs": [],
   "source": [
    "from research.data.things_dataset import ThingsDataset\n",
    "from research.imagenet_classes import imagenet_classes\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "things_dataset = ThingsDataset(\n",
    "    root=\"X:\\\\Datasets\\\\EEG\\\\Things-concepts-and-images\\\\\",\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-charleston",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bigbigan-resnet50'# ResNet-50\n",
    "#model_name = 'bigbigan-revnet50x4' # RevNet-50 x4\n",
    "module_path = f'https://tfhub.dev/deepmind/{model_name}/1'\n",
    "\n",
    "# module = hub.Module(module_path, trainable=True, tags={'train'})  # training\n",
    "module = hub.Module(module_path)  # inference\n",
    "\n",
    "for signature in module.get_signature_names():\n",
    "    print('Signature:', signature)\n",
    "    print('Inputs:', pformat(module.get_input_info_dict(signature)))\n",
    "    print('Outputs:', pformat(module.get_output_info_dict(signature)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigbigan = BigBiGAN(module)\n",
    "\n",
    "# Make input placeholders for x (`enc_ph`) and z (`gen_ph`).\n",
    "enc_ph = bigbigan.make_encoder_ph()\n",
    "gen_ph = bigbigan.make_generator_ph()\n",
    "\n",
    "# Compute samples G(z) from encoder input z (`gen_ph`).\n",
    "gen_samples = bigbigan.generate(gen_ph)\n",
    "\n",
    "# Compute reconstructions G(E(x)) of encoder input x (`enc_ph`).\n",
    "recon_x = bigbigan.reconstruct_x(enc_ph, upsample=True)\n",
    "\n",
    "# Compute encoder features used for representation learning evaluations given\n",
    "# encoder input x (`enc_ph`).\n",
    "enc_features = bigbigan.encode(enc_ph, return_all_features=True)\n",
    "\n",
    "# Compute discriminator scores for encoder pairs (x, E(x)) given x (`enc_ph`)\n",
    "# and generator pairs (G(z), z) given z (`gen_ph`).\n",
    "disc_scores_enc = bigbigan.discriminate(*bigbigan.enc_pairs_for_disc(enc_ph))\n",
    "disc_scores_gen = bigbigan.discriminate(*bigbigan.gen_pairs_for_disc(gen_ph))\n",
    "\n",
    "# Compute losses.\n",
    "losses = bigbigan.losses(enc_ph, gen_ph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e069f9-3af5-411c-816c-dbe1a914b128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage, misc\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "\n",
    "stimulus_ids = ['1443537.022563', '1621127.019020', '1677366.018182', '1846331.017038', '1858441.011077', '1943899.024131', '1976957.013223', '2071294.046212', \n",
    "                '2128385.020264', '2139199.010398', '2190790.015121', '2274259.024319', '2416519.012793', '2437136.012836', '2437971.005013', '2690373.007713', \n",
    "                '2797295.015411', '2824058.018729', '2882301.014188', '2916179.024850', '2950256.022949', '2951358.023759', '3064758.038750', '3122295.031279', \n",
    "                '3124170.013920', '3237416.058334', '3272010.011001', '3345837.012501', '3379051.008496', '3452741.024622', '3455488.028622', '3482252.022530', \n",
    "                '3495258.009895', '3584254.005040', '3626115.019498', '3710193.022225', '3716966.028524', '3761084.043533', '3767745.000109', '3941684.021672', \n",
    "                '3954393.010038', '4210120.009062', '4252077.010859', '4254777.016338', '4297750.025624', '4387400.016693', '4507155.021299', '4533802.019479', \n",
    "                '4554684.053399', '4572121.003262']\n",
    "\n",
    "features_root = Path('X:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\derivatives\\\\decoded_features')\n",
    "z_pred = np.load(features_root / 'bigbigan-resnet50__z_mean__sub-03__test-prediction__v4.npy')\n",
    "z_target = np.load(features_root / 'bigbigan-resnet50__z_mean__sub-03__test__v4.npy')\n",
    "\n",
    "root = 'X:\\\\Datasets\\\\Deep-Image-Reconstruction'\n",
    "stimulus_images = h5py.File(Path(root) / \"derivatives\" / \"stimulus_images.hdf5\", \"r\")\n",
    "\n",
    "x_stim = []\n",
    "for stimulus_id in stimulus_ids:\n",
    "    x = stimulus_images[stimulus_id]['data'][:]\n",
    "    x = ndimage.zoom(x, (128 / 500, 128 / 500, 1))\n",
    "    x = x / 256 * 2 - 1\n",
    "    x_stim.append(x)\n",
    "x_stim = np.stack(x_stim)\n",
    "\n",
    "x_target = np.concatenate([\n",
    "    sess.run(gen_samples, feed_dict={gen_ph: z[None]}) \n",
    "    for z in list(z_target)\n",
    "])\n",
    "\n",
    "x_pred = np.concatenate([\n",
    "    sess.run(gen_samples, feed_dict={gen_ph: z[None] / z.std()}) \n",
    "    for z in list(z_pred)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb051e2-b848-40d4-8f0a-ef1cdb44410b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "splits = 10\n",
    "cols = 50 // splits\n",
    "\n",
    "out_path = 'X:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\derivatives\\\\results'\n",
    "name = 'bigbigan_result03_v2'\n",
    "\n",
    "for i, (stim, target, pred) in enumerate(zip(np.split(x_stim, splits), np.split(x_target, splits), np.split(x_pred, splits))):\n",
    "    out = np.concatenate([stim, pred])\n",
    "    img = imgrid(image_to_uint8(out), cols=cols)\n",
    "    Image.fromarray(img).save(Path(out_path) / f'{name}_{i*cols}-{(i+1)*cols}.png')\n",
    "    imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f40b19-de34-4402-ae5a-b1a2f5609ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage, misc\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "\n",
    "stimulus_ids = {\n",
    "    'natural_test': ['1443537.022563', '1621127.019020', '1677366.018182', '1846331.017038', '1858441.011077', '1943899.024131', \n",
    "                     '1976957.013223', '2071294.046212', '2128385.020264', '2139199.010398', '2190790.015121', '2274259.024319', \n",
    "                     '2416519.012793', '2437136.012836', '2437971.005013', '2690373.007713', '2797295.015411', '2824058.018729', \n",
    "                     '2882301.014188', '2916179.024850', '2950256.022949', '2951358.023759', '3064758.038750', '3122295.031279', \n",
    "                     '3124170.013920', '3237416.058334', '3272010.011001', '3345837.012501', '3379051.008496', '3452741.024622', \n",
    "                     '3455488.028622', '3482252.022530', '3495258.009895', '3584254.005040', '3626115.019498', '3710193.022225', \n",
    "                     '3716966.028524', '3761084.043533', '3767745.000109', '3941684.021672', '3954393.010038', '4210120.009062', \n",
    "                     '4252077.010859', '4254777.016338', '4297750.025624', '4387400.016693', '4507155.021299', '4533802.019479', \n",
    "                     '4554684.053399', '4572121.003262'],\n",
    "    'imagery': ['1443537.022563', '1621127.019020', '1677366.018182', '1846331.017038', '1858441.011077', '1943899.024131', \n",
    "                '1976957.013223', '2071294.046212', '2128385.020264', '2139199.010398', '2190790.015121', '2274259.024319', \n",
    "                '2416519.012793', '2437136.012836', '2437971.005013', '2690373.007713', '2797295.015411', '2824058.018729', \n",
    "                '2882301.014188', '2916179.024850', '2950256.022949', '2951358.023759', '3064758.038750', '3122295.031279', \n",
    "                '3124170.013920', '3237416.058334'],\n",
    "}\n",
    "\n",
    "subject = 'sub-03'\n",
    "version = 3\n",
    "features_root = Path('X:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\derivatives\\\\decoded_features')\n",
    "\n",
    "z_target = np.load(features_root / 'bigbigan-resnet50__z_mean__sub-03__test__v4.npy')\n",
    "\n",
    "z_test_pred = np.load(features_root / 'bigbigan-resnet50' / 'z_mean' / subject / f'natural_test__variational__v{version}.npy')\n",
    "z_imagery_pred = np.load(features_root / 'bigbigan-resnet50' / 'z_mean' / subject / f'imagery__variational__v{version}.npy')\n",
    "\n",
    "\n",
    "root = 'X:\\\\Datasets\\\\Deep-Image-Reconstruction'\n",
    "stimulus_images = h5py.File(Path(root) / \"derivatives\" / \"stimulus_images.hdf5\", \"r\")\n",
    "\n",
    "def make_images(z_pred, stimulus_ids):\n",
    "    x_stim = []\n",
    "    for stimulus_id in stimulus_ids:\n",
    "        x = stimulus_images[stimulus_id]['data'][:]\n",
    "        x = ndimage.zoom(x, (128 / 500, 128 / 500, 1))\n",
    "        x = x / 256 * 2 - 1\n",
    "        x_stim.append(x)\n",
    "    x_stim = np.stack(x_stim)\n",
    "\n",
    "    x_target = np.concatenate([\n",
    "        sess.run(gen_samples, feed_dict={gen_ph: z[None]}) \n",
    "        for z in list(z_target)\n",
    "    ])\n",
    "\n",
    "    num_samples = 20\n",
    "    z_pred_mean = z_pred[:, 0]\n",
    "    z_pred_std = z_pred[:, 1]\n",
    "    sample = np.random.randn(z_pred.shape[0], num_samples, z_pred.shape[2])\n",
    "    z_pred = z_pred_mean[:, None] + z_pred_std[:, None] * sample\n",
    "\n",
    "    x_pred = np.stack([\n",
    "        np.concatenate([\n",
    "            sess.run(gen_samples, feed_dict={gen_ph: z[None]}) \n",
    "            for z in list(z_stim)\n",
    "        ])\n",
    "        for z_stim in list(z_pred)\n",
    "    ])\n",
    "    \n",
    "    return x_stim, x_target, x_pred\n",
    "\n",
    "x_test_stim, x_test_target, x_test_pred = make_images(z_test_pred, stimulus_ids['natural_test'])\n",
    "x_imagery_stim, x_imagery_target, x_imagery_pred = make_images(z_imagery_pred, stimulus_ids['imagery'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca4eae6-4f6c-4c71-babe-d03dbac6e5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "cols = 5\n",
    "\n",
    "out_path = Path('X:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\derivatives\\\\results')\n",
    "out_path = out_path / 'bigbigan-resnet50' / 'variational_encoder' / subject\n",
    "out_path.mkdir(exist_ok=True, parents=True)\n",
    "name = f'bigbigan-resnet50_variational_result_v{version}-0'\n",
    "\n",
    "groups = [('natural_test', x_test_stim, x_test_target, x_test_pred),\n",
    "          ('imagery', x_imagery_stim, x_imagery_target, x_imagery_pred)]\n",
    "\n",
    "for session, x_stim, x_target, x_pred in groups:\n",
    "    save_path = out_path / session\n",
    "    save_path.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    for i, (stim, target, pred) in enumerate(zip(list(x_stim), list(x_target), list(x_pred))):\n",
    "        out = np.concatenate([stim[None], target[None], pred[:18]])\n",
    "\n",
    "        img = imgrid(image_to_uint8(out), cols=cols)\n",
    "        Image.fromarray(img).save(Path(save_path) / f'{name}_id-{i}.png')\n",
    "        imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4a340b-548f-46d4-9d03-330819b30508",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z_pred = np.load('X:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\derivatives\\\\bigbigan-resnet50-test-prediction.npy')\n",
    "feed_dict = {gen_ph: z_pred[32:48] * 4}\n",
    "_out_samples = sess.run(gen_samples, feed_dict=feed_dict)\n",
    "print('samples shape:', _out_samples.shape)\n",
    "imshow(imgrid(image_to_uint8(_out_samples), cols=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c6bcd9-6438-4c40-a3a8-fe927f3a3595",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_test = np.load('X:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\derivatives\\\\bigbigan-resnet50-test.npy')\n",
    "feed_dict = {gen_ph: z_test[16:32]}\n",
    "_out_samples = sess.run(gen_samples, feed_dict=feed_dict)\n",
    "print('samples shape:', _out_samples.shape)\n",
    "imshow(imgrid(image_to_uint8(_out_samples), cols=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-density",
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = {gen_ph: np.random.randn(1, 120)}\n",
    "_out_samples = sess.run(gen_samples, feed_dict=feed_dict)\n",
    "print('samples shape:', _out_samples.shape)\n",
    "imshow(imgrid(image_to_uint8(_out_samples), cols=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e91742c-cdc3-4c8e-8962-0fff3e8aaa94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_path = Path('D:\\\\Datasets\\\\NSD')\n",
    "derivatives_path = dataset_path / 'derivatives' / 'stimulus_embeddings'\n",
    "stimulu_path = dataset_path / 'nsddata_stimuli' / 'stimuli' / 'nsd' / 'nsd_stimuli.hdf5'\n",
    "stimulus_images = h5py.File(stimulu_path, 'r')['imgBrick']\n",
    "\n",
    "from torchvision import transforms as T\n",
    "normalize = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "preprocess = T.Compose([T.Resize(256), T.ToTensor(),])\n",
    "\n",
    "with h5py.File(derivatives_path / f\"{model_name}-embeddings.hdf5\", \"a\") as f:\n",
    "    N = stimulus_images.shape[0]\n",
    "\n",
    "    for stimulus_id in tqdm(range(N)):\n",
    "        \n",
    "        image_data = stimulus_images[stimulus_id]\n",
    "        image = Image.fromarray(image_data)\n",
    "        x = preprocess(image).unsqueeze(0) * 2. - 1.\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        \n",
    "        out_recons, out_features = sess.run([recon_x, enc_features], feed_dict={enc_ph: x})\n",
    "        features = {'reconstruction': out_recons, **out_features}\n",
    "        \n",
    "        for feature_name, feature in features.items():\n",
    "            f.require_dataset(feature_name, (N, *feature.shape), feature.dtype)\n",
    "            f[feature_name][stimulus_id] = feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cad3dd-5a2c-4a8a-b865-56100614fbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "import h5py\n",
    "\n",
    "derivatives_path = Path('X:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\derivatives\\\\')\n",
    "\n",
    "from pathlib import Path\n",
    "root = 'X:\\\\Datasets\\\\Deep-Image-Reconstruction'\n",
    "stimulus_images = h5py.File(Path(root) / \"derivatives\" / \"stimulus_images.hdf5\", \"r\")\n",
    "\n",
    "from torchvision import transforms as T\n",
    "normalize = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "preprocess = T.Compose([T.Resize(256), T.ToTensor(),])\n",
    "\n",
    "with h5py.File(derivatives_path / f\"{model_name}-features.hdf5\", \"a\") as f:\n",
    "    for stimulus_id, stimulus_image in tqdm(stimulus_images.items()):\n",
    "\n",
    "        image_data = stimulus_image['data'][:]\n",
    "        image = Image.fromarray(image_data)\n",
    "        x = preprocess(image).unsqueeze(0) * 2. - 1.\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        print(x.shape, x.min(), x.max())\n",
    "        \n",
    "        out_recons, out_features = sess.run([recon_x, enc_features], feed_dict={enc_ph: x})\n",
    "        \n",
    "        #print(out_recons.shape)\n",
    "        #print([(k, v.shape) for k, v in out_features.items()])\n",
    "        \n",
    "        features = {'reconstruction': out_recons, **out_features}\n",
    "\n",
    "        if stimulus_id not in f:\n",
    "            stimulus = f.create_group(stimulus_id)\n",
    "        else:\n",
    "            stimulus = f[stimulus_id]\n",
    "\n",
    "        for node_name, feature in features.items():\n",
    "            feature = feature[0]\n",
    "            if node_name in stimulus:\n",
    "                stimulus[node_name][:] = feature\n",
    "            else:\n",
    "                stimulus[node_name] = feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122638fc-b041-4d9c-a1ee-3abfbdb91a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_images = h5py.File(Path(root) / \"derivatives\" / \"stimulus_images.hdf5\", \"r\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840511aa-25c3-49a2-8166-fd07c26b54b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "stimulus_images = h5py.File(Path(root) / \"derivatives\" / \"stimulus_images.hdf5\", \"r\")\n",
    "reconstructions = h5py.File(derivatives_path / f\"{model_name}-features.hdf5\", \"r\")\n",
    "\n",
    "@interact(stimulus_id=list(stimulus_images.keys()))\n",
    "def compare(stimulus_id):\n",
    "    original = stimulus_images[stimulus_id]['data'][:]\n",
    "    reconstruction = reconstructions[stimulus_id]['reconstruction'][:]\n",
    "    print(original.shape, reconstruction.shape)\n",
    "    \n",
    "    print(original.max(), original.min())\n",
    "    print(reconstruction.max(), reconstruction.min())\n",
    "    plt.imshow(original)\n",
    "    plt.show()\n",
    "    plt.imshow(reconstruction * 0.5 + 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-research",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "batch_size = 16\n",
    "dataloader = DataLoader(things_dataset, batch_size=batch_size)\n",
    "out_path = Path(\"X:\\\\Results\\\\Neurophysical-Data-Decoding\\\\BigBiGAN-Inversions\\\\resnet50_1\\\\\")\n",
    "image_path = out_path / \"images\"\n",
    "latent_path = out_path / \"latents\"\n",
    "image_path.mkdir(exist_ok=True, parents=True)\n",
    "latent_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "save_features = ['z_sample', 'z_mean', 'z_stdev', 'default']\n",
    "for i, batch in enumerate(dataloader):\n",
    "    data = batch['data']\n",
    "    data = torch.movedim(data, 1, -1)\n",
    "    data = data.numpy()\n",
    "    data = data * 2. - 1.\n",
    "    print(data.shape, data.min(), data.max())\n",
    "    break\n",
    "    \n",
    "    out_recons, out_features = sess.run([recon_x, enc_features], feed_dict={enc_ph: data})\n",
    "    \n",
    "    inputs_and_recons = interleave(data, out_recons)\n",
    "    out = imgrid(image_to_uint8(inputs_and_recons), cols=8)\n",
    "    image = Image.fromarray(out)\n",
    "    \n",
    "    name = f\"{i * batch_size}-{(i + 1) * batch_size - 1}\"\n",
    "    image.save(image_path / f\"{name}.png\")\n",
    "    \n",
    "    latents = np.stack([out_features[feature] for feature in save_features], axis=1)\n",
    "    np.save(latent_path / f\"{name}.npy\", latents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "latents_path = Path(\"X:\\\\Results\\\\Neurophysical-Data-Decoding\\\\BigBiGan-Inversions\\\\resnet50_1\\\\latents\\\\\")\n",
    "\n",
    "latent_file_paths = list(latents_path.iterdir())\n",
    "latent_file_paths.sort(key=lambda file_path: int(file_path.stem.split(\"-\")[0]) )\n",
    "latents = [np.load(latent_file_path) for latent_file_path in latent_file_paths]\n",
    "latents = np.concatenate(latents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = Path(\"X:\\\\Datasets\\\\EEG\\\\Things-supplementary\\\\Latents\\\\bigbigan-resnet50\\\\\")\n",
    "for i, feature in enumerate(['z_sample', 'z_mean', 'z_stdev']):\n",
    "    latent = latents[:, i]\n",
    "    np.save(out_path / f\"{feature}.npy\", latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-export",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BigGAN-deep models\n",
    "# module_path = 'https://tfhub.dev/deepmind/biggan-deep-128/1'  # 128x128 BigGAN-deep\n",
    "module_path = 'https://tfhub.dev/deepmind/biggan-deep-256/1'  # 256x256 BigGAN-deep\n",
    "# module_path = 'https://tfhub.dev/deepmind/biggan-deep-512/1'  # 512x512 BigGAN-deep\n",
    "\n",
    "# BigGAN (original) models\n",
    "# module_path = 'https://tfhub.dev/deepmind/biggan-128/2'  # 128x128 BigGAN\n",
    "# module_path = 'https://tfhub.dev/deepmind/biggan-256/2'  # 256x256 BigGAN\n",
    "# module_path = 'https://tfhub.dev/deepmind/biggan-512/2'  # 512x512 BigGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import os\n",
    "import io\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "from scipy.stats import truncnorm\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_vector_path = Path(\"X:\\\\Datasets\\\\EEG\\\\Things-supplementary\\\\ImageNet-Classification\\\\resetnet152\\\\concept_averages\\\\one_hot.csv\")\n",
    "concept_imagenet_classes = np.loadtxt(class_vector_path, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-decision",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_biggan import (BigGAN, one_hot_from_names, truncated_noise_sample,\n",
    "                                       save_as_images, display_in_terminal)\n",
    "from pathlib import Path\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "model = BigGAN.from_pretrained('biggan-deep-256')\n",
    "\n",
    "# Prepare a input\n",
    "truncation = 0.4\n",
    "#class_vector = one_hot_from_names(['soap bubble', 'coffee', 'mushroom'], batch_size=3)\n",
    "class_vector = concept_imagenet_classes[[8, 8, 8]]\n",
    "noise_vector = truncated_noise_sample(truncation=truncation, batch_size=3)\n",
    "\n",
    "# All in tensors\n",
    "noise_vector = torch.from_numpy(noise_vector)\n",
    "class_vector = torch.from_numpy(class_vector).float()\n",
    "\n",
    "# If you have a GPU, put everything on cuda\n",
    "noise_vector = noise_vector.to('cuda')\n",
    "class_vector = class_vector.to('cuda')\n",
    "model.to('cuda')\n",
    "\n",
    "# Generate an image\n",
    "with torch.no_grad():\n",
    "    output = model(noise_vector, class_vector, truncation)\n",
    "\n",
    "# If you have a GPU put back on CPU\n",
    "output = output.to('cpu')\n",
    "\n",
    "# Save results as png images\n",
    "#save_as_images(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b796c881-8160-4d1f-8e94-4323623f1c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BigGAN.from_pretrained('biggan-128')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacf68f7-85ba-4d13-8764-76a826503328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BigGAN-deep 128 module.\n",
    "module = hub.Module('https://tfhub.dev/deepmind/biggan-deep-128/1')\n",
    "\n",
    "# Sample random noise (z) and ImageNet label (y) inputs.\n",
    "batch_size = 8\n",
    "truncation = 0.5  # scalar truncation value in [0.0, 1.0]\n",
    "z = truncation * tf.random.truncated_normal([batch_size, 128])  # noise sample\n",
    "y_index = tf.random.uniform([batch_size], maxval=1000, dtype=tf.int32)\n",
    "y = tf.one_hot(y_index, 1000)  # one-hot ImageNet label\n",
    "\n",
    "# Call BigGAN on a dict of the inputs to generate a batch of images with shape\n",
    "# [8, 128, 128, 3] and range [-1, 1].\n",
    "samples = module(dict(y=y, z=z, truncation=truncation), signature=\"image_feature_vector\", as_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43157591-a9ef-4957-ad39-7872a5ce0f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = 'https://tfhub.dev/deepmind/biggan-deep-128/1' "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
