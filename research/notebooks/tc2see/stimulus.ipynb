{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c90a4407-62aa-487a-8866-f263ccb29afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cefir\\anaconda3\\envs\\Neurophysiological-Data-Decoding\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Cefir\\anaconda3\\envs\\Neurophysiological-Data-Decoding\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "C:\\Users\\Cefir\\anaconda3\\envs\\Neurophysiological-Data-Decoding\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchio as tio\n",
    "import h5py\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "dir2 = os.path.abspath('../..')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: \n",
    "    sys.path.append(dir1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "961b6184-aa22-4e51-bc45-dbec67178e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path('X:\\\\Datasets\\\\2021 TC2See fMRI Data\\\\')\n",
    "project_path = dataset_path / 'project'\n",
    "derivatives_path = dataset_path / 'derivatives'\n",
    "\n",
    "ssd_dataset_path = Path('C:\\\\Datasets\\\\2021 TC2See fMRI Data\\\\')\n",
    "ssd_derivatives_path = ssd_dataset_path / 'derivatives'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20dd095-3f9e-4498-bb51-78f424e1557c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create h5 file for stimulus images\n",
    "from PIL import Image\n",
    "\n",
    "stimulus_images_path = Path('G:\\\\Github Repositories\\\\bird_data\\\\docs\\\\cropped')\n",
    "\n",
    "with h5py.File(derivatives_path / 'stimulus-images.hdf5', 'w') as f:\n",
    "    for image_file_path in stimulus_images_path.iterdir():\n",
    "        stimulus_name = image_file_path.stem\n",
    "        \n",
    "        class_id, image_id = stimulus_name.split('.')\n",
    "        class_id = int(class_id)\n",
    "        \n",
    "        bird_name = image_id[:-2]\n",
    "        bird_id = int(image_id[-1])\n",
    "        \n",
    "        with Image.open(image_file_path) as image:\n",
    "            data = np.array(image)\n",
    "        f[f'{stimulus_name}/data'] = data\n",
    "        f[stimulus_name].attrs['class_id'] = class_id\n",
    "        f[stimulus_name].attrs['bird_id'] = bird_id\n",
    "        \n",
    "        print(stimulus_name, bird_class_id, bird_name, bird_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ef90600-77ba-428c-b851-8cd6eee5d747",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "stimulus_images = h5py.File(derivatives_path / 'stimulus-images.hdf5', \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e3d920b-ad61-44dc-b193-09a5d283d4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RN50', 'RN101', 'RN50x4', 'RN50x16', 'ViT-B/32', 'ViT-B/16']\n"
     ]
    }
   ],
   "source": [
    "# Load a CLIP model\n",
    "import clip\n",
    "\n",
    "print(clip.available_models())\n",
    "model_name = 'ViT-B/32'\n",
    "model, preprocess = clip.load(model_name, device=device)\n",
    "model = model.visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ee09d4d-ddef-4c3a-b953-ba04fec191a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "045b86dcd0eb472589205d9b49458227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='module_name', options=('', 'conv1', 'ln_pre', 'transformer', 'tranâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature visualizer\n",
    "\n",
    "from PIL import Image\n",
    "from functools import partial\n",
    "\n",
    "def vis_features(x):\n",
    "    if not isinstance(x, torch.Tensor):\n",
    "        print(type(x))\n",
    "        return\n",
    "    x = x.float().cpu()\n",
    "    print(x.shape, x.dtype)\n",
    "    if len(x.shape) != 4:\n",
    "        return\n",
    "    N, C, W, H = x.shape\n",
    "    \n",
    "    print(x.mean(), x.std())\n",
    "\n",
    "    @interact(i=(0, N-1), c=(0, C-1))\n",
    "    def plot_feature_map(i, c):\n",
    "        fig = plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(x[i, c].cpu(), cmap=\"gray\")\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "modules = dict(model.named_modules())\n",
    "@interact(module_name=modules.keys(), stimulus_id=list(stimulus_images.keys()))\n",
    "def select_module(module_name, stimulus_id):\n",
    "    image_data = stimulus_images[stimulus_id]['data'][:]\n",
    "    image = Image.fromarray(image_data)\n",
    "    x = preprocess(image).unsqueeze(0).to(device).to(torch.float16)\n",
    "    \n",
    "    features = {}\n",
    "    def forward_hook(module_name, module, x_in, x_out):\n",
    "        features[module_name] = x_out.clone()\n",
    "    \n",
    "    module = modules[module_name]\n",
    "    hook_handle = module.register_forward_hook(partial(forward_hook, module_name))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model(x)\n",
    "    \n",
    "    vis_features(features[module_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "917b4e6c-858d-43d6-8400-c2e6623eb74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features to save\n",
    "\n",
    "save_modules = {\n",
    "    '': 'embedding'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2cbddf2-bfea-4311-8eb8-1cd29ecf8efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_modules = [f'transformer.resblocks.{i}' for i in range(12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bb13a99-c1f0-4cc6-80b9-e09c31b7cbd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7367aec2ac394a2e88b08e789afcf48d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature extraction\n",
    "\n",
    "from functools import partial\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "from functools import partial\n",
    "from typing import Sequence, Dict\n",
    "\n",
    "modules = dict(model.named_modules())\n",
    "\n",
    "with h5py.File(derivatives_path / f\"{model_name.replace('/', '=')}-features.hdf5\", \"a\") as f:\n",
    "    for stimulus_id, stimulus_image in tqdm(stimulus_images.items()):\n",
    "        image_data = stimulus_image['data'][:]\n",
    "        image = Image.fromarray(image_data)\n",
    "        x = preprocess(image).unsqueeze(0).to(device).to(torch.float16)\n",
    "\n",
    "        features = {}\n",
    "        def forward_hook(module_name, module, x_in, x_out):\n",
    "            features[module_name] = x_out.clone()\n",
    "        \n",
    "        hook_handles = []\n",
    "        if isinstance(save_modules, Sequence):\n",
    "            for module_name in save_modules:\n",
    "                module = modules[module_name]\n",
    "                hook_handle = module.register_forward_hook(partial(forward_hook, module_name))\n",
    "                hook_handles.append(hook_handle)\n",
    "        elif isinstance(save_modules, Dict):\n",
    "            for module_name, feature_name in save_modules.items():\n",
    "                module = modules[module_name]\n",
    "                hook_handle = module.register_forward_hook(partial(forward_hook, feature_name))\n",
    "                hook_handles.append(hook_handle)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model(x)\n",
    "            \n",
    "        for hook_handle in hook_handles:\n",
    "            hook_handle.remove()\n",
    "\n",
    "        if stimulus_id not in f:\n",
    "            stimulus = f.create_group(stimulus_id)\n",
    "        else:\n",
    "            stimulus = f[stimulus_id]\n",
    "\n",
    "        for node_name, feature in features.items():\n",
    "            if feature.shape[0] == 1:\n",
    "                feature = feature[0]\n",
    "            feature = feature.cpu()\n",
    "            if node_name in stimulus:\n",
    "                stimulus[node_name][:] = feature\n",
    "            else:\n",
    "                stimulus[node_name] = feature"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Neurophysiological-Data-Decoding",
   "language": "python",
   "name": "neurophysiological-data-decoding"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
